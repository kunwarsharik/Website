{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CVS_8jun2020.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNzgJolMdfD9"
      },
      "source": [
        "# blink detection\n",
        "# angle detection\n",
        "# iris tracking\n",
        "# 2020 rule\n",
        "# distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V08MQ1Khwc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "40da3b3e-7109-4bf2-f48e-af0274cb116a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpKvVzj-vCfn"
      },
      "source": [
        "# for n,i in enumerate(points):\n",
        "#     if n==31:\n",
        "#         cv2.putText(frame, str(n) , (i[0],i[1]), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0, 0), 2, cv2.LINE_AA)#3 size h 2 thickness\n",
        "# plt.imshow(frame)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB6cxE8Nd3iI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49b8830d-db65-4350-c249-f08ae05a9d82"
      },
      "source": [
        "#blepblink \n",
        "import cv2, numpy as np, glob, os,shutil, keras, matplotlib.pyplot as plt,tensorflow as tf,matplotlib.mlab as mplt, sys\n",
        "from PIL import Image\n",
        "from matplotlib import style\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Dropout,ZeroPadding2D\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split as tt\n",
        "import scipy.io.wavfile\n",
        "from math import sqrt\n",
        "import librosa\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve,f1_score,average_precision_score,confusion_matrix\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.preprocessing import StandardScaler as sd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import subprocess\n",
        "from sklearn.decomposition import PCA\n",
        "from IPython.display import Audio\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from imutils import face_utils\n",
        "import dlib,math\n",
        "\n",
        "\n",
        "detector= dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('./drive/My Drive/Copy of shape_predictor_68_face_landmarks.dat')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJAA_Lf-eLzY"
      },
      "source": [
        "drop=0.8\n",
        "learning_rate=.0001\n",
        "epoch=50\n",
        "count=0\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(32, (2,2), input_shape=(50,50,1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "model.add(Convolution2D(64, (2,2), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(32, (2,2), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "model.add(Convolution2D(64, (2,2), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(Convolution2D(32, (2,2), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "model.add(Convolution2D(64, (2,2), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(32, (2,2), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "model.add(Convolution2D(64, (2,2), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(32, (2,2), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "model.add(Convolution2D(64, 2, activation='relu',padding='same'))\n",
        "#model.add(ZeroPadding2D((1, 1)))\n",
        "model.add(MaxPooling2D(pool_size=2,padding='same'))\n",
        "#model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "#model.add(Dropout(0.30))\n",
        "#   model.add(Dense(512, activation='relu'))\n",
        "#   model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(drop))\n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))\n",
        "model.load_weights(\"./drive/My Drive/colour.hdf5\")\n",
        "adam=optimizers.Adam(lr=learning_rate)\n",
        "model.compile(optimizer=adam,loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sf7XBbjgI0K"
      },
      "source": [
        "def point(gray):\n",
        "    shape1=np.array([])\n",
        "    rects1=detector(gray,0)\n",
        "    for rect in rects1:\n",
        "        shape = predictor(gray,rect)\n",
        "        shape1 = face_utils.shape_to_np(shape)\n",
        "    if(shape1.any()==0):\n",
        "        return []\n",
        "    else:\n",
        "        return shape1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aydru1gheXyR"
      },
      "source": [
        "def eyes(gray,shape1):\n",
        "    fe1=shape1[45][0] - shape1[42][0]#eye lft ke liye\n",
        "    x1=shape1[42][0]\n",
        "    x1=x1-2\n",
        "    x2= shape1[45][0] \n",
        "    x2=x2+2\n",
        "    y1=shape1[43][1]\n",
        "    y1=y1-18\n",
        "    y2=shape1[46][1]\n",
        "    y2=y2+12\n",
        "    if(x1<0):\n",
        "        x1=0\n",
        "    if(y1<0):\n",
        "        y1=0\n",
        "    if(x2>frame.shape[1]):\n",
        "        x2=frame.shape[1]\n",
        "    if(y2>frame.shape[0]):\n",
        "        y2=frame.shape[0]   \n",
        "\n",
        "    x_1=gray[y1:y2, x1:x2]\n",
        "\n",
        "    fe2=shape1[39][0] - shape1[36][0]# fe2 eye 2 ke liye\n",
        "    x1=shape1[36][0]\n",
        "    x1=x1-2\n",
        "    x2= shape1[39][0] \n",
        "    x2=x2+2\n",
        "    y1=shape1[37][1]\n",
        "    y1=y1-18\n",
        "    y2=shape1[40][1]\n",
        "    y2=y2+12\n",
        "    if(x1<0):\n",
        "        x1=0\n",
        "    if(y1<0):\n",
        "        y1=0\n",
        "    if(x2>frame.shape[1]):\n",
        "        x2=frame.shape[1]\n",
        "    if(y2>frame.shape[0]):\n",
        "        y2=frame.shape[0] \n",
        "    x_2=gray[y1:y2, x1:x2]\n",
        "\n",
        "    return x_1,x_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb52wjqpuzuY"
      },
      "source": [
        "def distance_init(D,W,points):\n",
        "    P=abs(points[35][0]-points[31][0])\n",
        "    return (P*D)/W"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGIKrMx8rfMD"
      },
      "source": [
        "#angle\n",
        "def angle(frame,points,v=0):\n",
        "    size=frame.shape\n",
        "    image_points = np.array([(points[30][0], points[30][1]),(points[8][0], points[8][1]),\n",
        "                            (points[36][0], points[36][1]),(points[45][0], points[45][1]),\n",
        "                            (points[48][0], points[48][1]),(points[54][0], points[54][1])], dtype=\"double\")#nose tip,chin,lip left right,eye left's left, right's right\n",
        "    model_points = np.array([(0.0, 0.0, 0.0),(0.0, -330.0, -65.0),(-225.0, 170.0, -135.0),(225.0, 170.0, -135.0),(-150.0, -150.0, -125.0),(150.0, -150.0, -125.0)])\n",
        "    # Nose tip, Chin , eye left corner ,Right eye right corner, Left Mouth corner ,Right mouth corner\n",
        "    focal_length = size[1]\n",
        "    center = (size[1]/2, size[0]/2)\n",
        "    camera_matrix = np.array([[focal_length, 0, center[0]],[0, focal_length, center[1]],[0, 0, 1]], dtype = \"double\")\n",
        "    #print (\"Camera Matrix :\",camera_matrix)\n",
        "    dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n",
        "    (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.cv2.SOLVEPNP_ITERATIVE)\n",
        "    if v==1:\n",
        "        (nose_end_point2D, jacobian) = cv2.projectPoints(np.array([(0.0, 0.0, 1000.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
        "        for p in image_points:\n",
        "            cv2.circle(frame, (int(p[0]), int(p[1])), 3, (0,0,255), -1)\n",
        "        p1 = ( int(image_points[0][0]), int(image_points[0][1]))\n",
        "        p2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))\n",
        "        cv2.line(frame, p1, p2, (255,0,0), 2)\n",
        "        return frame\n",
        "    else:\n",
        "        one=rotation_vector[0][0]*180/3.14\n",
        "        sec=rotation_vector[1][0]*180/3.14\n",
        "        thd= rotation_vector[2][0]*180/3.14\n",
        "        return one,sec,thd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsBUnqbtks01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "24ffc934-6d21-4111-9d6e-eca4d8bc99a3"
      },
      "source": [
        "!wget https://images-na.ssl-images-amazon.com/images/I/51svmvAZdNL._SX355_.jpg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-08 20:14:26--  https://images-na.ssl-images-amazon.com/images/I/51svmvAZdNL._SX355_.jpg\n",
            "Resolving images-na.ssl-images-amazon.com (images-na.ssl-images-amazon.com)... 151.101.1.16, 151.101.65.16, 151.101.129.16, ...\n",
            "Connecting to images-na.ssl-images-amazon.com (images-na.ssl-images-amazon.com)|151.101.1.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23748 (23K) [image/jpeg]\n",
            "Saving to: ‘51svmvAZdNL._SX355_.jpg’\n",
            "\n",
            "\r51svmvAZdNL._SX355_   0%[                    ]       0  --.-KB/s               \r51svmvAZdNL._SX355_ 100%[===================>]  23.19K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-06-08 20:14:26 (1.82 MB/s) - ‘51svmvAZdNL._SX355_.jpg’ saved [23748/23748]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grsq4I4Vik-u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e51deb8d-594e-449e-c175-ce3288d647cd"
      },
      "source": [
        "!wget https://images.indianexpress.com/2018/07/delhi-boy-fb.jpg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-08 20:05:35--  https://images.indianexpress.com/2018/07/delhi-boy-fb.jpg\n",
            "Resolving images.indianexpress.com (images.indianexpress.com)... 23.5.10.125\n",
            "Connecting to images.indianexpress.com (images.indianexpress.com)|23.5.10.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64937 (63K) [image/jpeg]\n",
            "Saving to: ‘delhi-boy-fb.jpg’\n",
            "\n",
            "\rdelhi-boy-fb.jpg      0%[                    ]       0  --.-KB/s               \rdelhi-boy-fb.jpg    100%[===================>]  63.42K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-06-08 20:05:36 (617 KB/s) - ‘delhi-boy-fb.jpg’ saved [64937/64937]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A80xqfAReUMj"
      },
      "source": [
        "#main\n",
        "points=0\n",
        "frame=cv2.imread(\"delhi-boy-fb.jpg\")#51svmvAZdNL._SX355_.jpg\")\n",
        "gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
        "points=point(gray)\n",
        "if len(points)==0:\n",
        "    print(\"0\")\n",
        "else:\n",
        "   le,re = eyes(gray,points)\n",
        "   # left right eye"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvJu9IbUkalf"
      },
      "source": [
        "# distance\n",
        "#F=PD/W\n",
        "#D=WF/P\n",
        "# W actual width of object, we place it D distance apart, P pixel width of our object, F focal length of our camera. camera ki seedh me ho\n",
        "d,w=input(\"enter the your distance and nose width in centimeters\")\n",
        "F=distance_init(d,w,points)\n",
        "P=abs(points[35][0]-points[31][0])\n",
        "D=(W*F)/P\n",
        "print(\"Distance is \",D,\"cms\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukr6U0EmnEHE"
      },
      "source": [
        "#iris movement https://github.com/antoinelame/GazeTracking"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq9XhYRq_FLd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "26115540-ef57-4e17-a8ea-c708564ffa20"
      },
      "source": [
        "!git clone https://github.com/antoinelame/GazeTracking.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'GazeTracking'...\n",
            "remote: Enumerating objects: 85, done.\u001b[K\n",
            "remote: Total 85 (delta 0), reused 0 (delta 0), pack-reused 85\u001b[K\n",
            "Unpacking objects: 100% (85/85), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k0qhVUI_TtN"
      },
      "source": [
        "os.listdir(\"GazeTracking\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzNZQu66_E8Z"
      },
      "source": [
        "from GazeTracking.gaze_tracking.gaze_tracking import GazeTracking"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL9lI9jdCPN4"
      },
      "source": [
        "gaze = GazeTracking()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKkJS58zApJP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ecd37a52-cc4b-4b12-fe78-96c7e011399c"
      },
      "source": [
        "gaze.refresh(frame)\n",
        "gaze.pupil_left_coords(),gaze.pupil_right_coords()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(345, 343)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeW42bwC8wXQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebbf0d6c-e1fa-4876-e924-62da49a8ef52"
      },
      "source": [
        "angle(frame,points)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-183.45465526913463, 16.110813390269513, -20.169831920909612)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTY9IhlE45IN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}