{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gun_noted on 22_11_2020.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViYADNv6GVL_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9a55b35e-ce79-439b-d0bd-6e36340d981e"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    1% |▎                               | 10kB 14.2MB/s eta 0:00:01\r\u001b[K    2% |▋                               | 20kB 2.3MB/s eta 0:00:01\r\u001b[K    3% |█                               | 30kB 3.2MB/s eta 0:00:01\r\u001b[K    4% |█▎                              | 40kB 2.1MB/s eta 0:00:01\r\u001b[K    5% |█▋                              | 51kB 2.6MB/s eta 0:00:01\r\u001b[K    6% |██                              | 61kB 3.1MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 71kB 3.5MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 81kB 4.0MB/s eta 0:00:01\r\u001b[K    9% |███                             | 92kB 4.4MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 102kB 3.4MB/s eta 0:00:01\r\u001b[K    11% |███▋                            | 112kB 3.5MB/s eta 0:00:01\r\u001b[K    12% |████                            | 122kB 4.8MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 133kB 4.8MB/s eta 0:00:01\r\u001b[K    14% |████▋                           | 143kB 8.7MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 153kB 8.8MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 163kB 8.7MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 174kB 8.9MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 184kB 8.9MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 194kB 8.8MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 204kB 30.0MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 215kB 10.4MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 225kB 10.4MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 235kB 10.5MB/s eta 0:00:01\r\u001b[K    24% |████████                        | 245kB 10.5MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 256kB 10.5MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 266kB 10.3MB/s eta 0:00:01\r\u001b[K    27% |█████████                       | 276kB 10.4MB/s eta 0:00:01\r\u001b[K    29% |█████████▎                      | 286kB 10.4MB/s eta 0:00:01\r\u001b[K    30% |█████████▋                      | 296kB 10.5MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 307kB 10.9MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 317kB 37.9MB/s eta 0:00:01\r\u001b[K    33% |██████████▋                     | 327kB 38.4MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 337kB 38.7MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 348kB 35.8MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 358kB 35.4MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 368kB 37.8MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 378kB 36.5MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 389kB 36.9MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 399kB 12.4MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 409kB 12.1MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 419kB 12.0MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 430kB 12.0MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 440kB 12.1MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 450kB 12.1MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 460kB 11.9MB/s eta 0:00:01\r\u001b[K    47% |███████████████▎                | 471kB 12.0MB/s eta 0:00:01\r\u001b[K    48% |███████████████▋                | 481kB 12.1MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 491kB 12.1MB/s eta 0:00:01\r\u001b[K    50% |████████████████▎               | 501kB 34.5MB/s eta 0:00:01\r\u001b[K    51% |████████████████▋               | 512kB 34.4MB/s eta 0:00:01\r\u001b[K    52% |█████████████████               | 522kB 34.7MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 532kB 35.1MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▋              | 542kB 11.1MB/s eta 0:00:01\r\u001b[K    55% |██████████████████              | 552kB 11.1MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▎             | 563kB 11.2MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 573kB 11.1MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 583kB 11.1MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▎            | 593kB 11.1MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▋            | 604kB 11.2MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 614kB 11.4MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▎           | 624kB 11.4MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 634kB 11.4MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 645kB 37.6MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▎          | 655kB 41.4MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 665kB 34.6MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 675kB 35.2MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▎         | 686kB 35.3MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▋         | 696kB 35.6MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 706kB 35.1MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 716kB 35.4MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 727kB 35.9MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 737kB 35.4MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 747kB 35.7MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 757kB 35.7MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 768kB 45.2MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 778kB 44.2MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 788kB 44.4MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 798kB 44.8MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 808kB 45.2MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 819kB 43.5MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 829kB 44.3MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▏    | 839kB 44.9MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▌    | 849kB 45.0MB/s eta 0:00:01\r\u001b[K    87% |███████████████████████████▉    | 860kB 38.6MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▏   | 870kB 37.5MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▌   | 880kB 38.0MB/s eta 0:00:01\r\u001b[K    90% |████████████████████████████▉   | 890kB 36.7MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▏  | 901kB 35.8MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▌  | 911kB 35.8MB/s eta 0:00:01\r\u001b[K    93% |█████████████████████████████▉  | 921kB 36.7MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▏ | 931kB 36.1MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▌ | 942kB 36.3MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▉ | 952kB 35.8MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 962kB 41.7MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 972kB 41.8MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 983kB 42.1MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 993kB 16.0MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyJ7UWm-GlAJ"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':'1dDnroGFtb8V6-zSK4y46dK06zZXOY2fk'}) \n",
        "downloaded.GetContentFile('gun200.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy6o7W3ZGm-r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3efbcaf5-0bcd-4f3d-c668-9ee1af035e60"
      },
      "source": [
        "import cv2, numpy as np, glob, os,shutil, keras, matplotlib.pyplot as plt,tensorflow as tf,matplotlib.mlab as mplt, sys\n",
        "from matplotlib import style\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Dropout,ZeroPadding2D\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split as tt\n",
        "import scipy.io.wavfile\n",
        "from math import sqrt\n",
        "import librosa\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve,f1_score,average_precision_score,confusion_matrix\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.preprocessing import StandardScaler as sd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.decomposition import PCA\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE723tHsGqw3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 25738
        },
        "outputId": "c7cef9c9-d07d-4804-9fba-9e521d0d155d"
      },
      "source": [
        "!unzip 'gun200.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  gun200.zip\n",
            "   creating: gun200/\n",
            "   creating: gun200/gunaud/\n",
            "   creating: gun200/gunaud/0/\n",
            "  inflating: gun200/gunaud/0/0.mp3   \n",
            "  inflating: gun200/gunaud/0/2.mp3   \n",
            "  inflating: gun200/gunaud/0/3.mp3   \n",
            "  inflating: gun200/gunaud/0/4.mp3   \n",
            "  inflating: gun200/gunaud/0/5.mp3   \n",
            "   creating: gun200/gunaud/1/\n",
            "  inflating: gun200/gunaud/1/0.mp3   \n",
            "  inflating: gun200/gunaud/1/1.mp3   \n",
            "  inflating: gun200/gunaud/1/2.mp3   \n",
            "  inflating: gun200/gunaud/1/3.mp3   \n",
            "  inflating: gun200/gunaud/1/4.mp3   \n",
            "  inflating: gun200/gunaud/1/5.mp3   \n",
            "   creating: gun200/gunaud/2/\n",
            "  inflating: gun200/gunaud/2/0.mp3   \n",
            "  inflating: gun200/gunaud/2/1.mp3   \n",
            "  inflating: gun200/gunaud/2/2.mp3   \n",
            "  inflating: gun200/gunaud/2/3.mp3   \n",
            "  inflating: gun200/gunaud/2/5.mp3   \n",
            "  inflating: gun200/gunaud/2/6.mp3   \n",
            "  inflating: gun200/gunaud/2/7.mp3   \n",
            "  inflating: gun200/gunaud/2/8.mp3   \n",
            "  inflating: gun200/gunaud/2/9.mp3   \n",
            "  inflating: gun200/gunaud/2/10.mp3  \n",
            "  inflating: gun200/gunaud/2/11.mp3  \n",
            "  inflating: gun200/gunaud/2/12.mp3  \n",
            "  inflating: gun200/gunaud/2/13.mp3  \n",
            "  inflating: gun200/gunaud/2/14.mp3  \n",
            "  inflating: gun200/gunaud/2/15.mp3  \n",
            "  inflating: gun200/gunaud/2/16.mp3  \n",
            "  inflating: gun200/gunaud/2/17.mp3  \n",
            "  inflating: gun200/gunaud/2/18.mp3  \n",
            "  inflating: gun200/gunaud/2/19.mp3  \n",
            "   creating: gun200/gunaud/3/\n",
            "  inflating: gun200/gunaud/3/0.mp3   \n",
            "  inflating: gun200/gunaud/3/1.mp3   \n",
            "  inflating: gun200/gunaud/3/2.mp3   \n",
            "  inflating: gun200/gunaud/3/3.mp3   \n",
            "  inflating: gun200/gunaud/3/4.mp3   \n",
            "   creating: gun200/gunaud/4/\n",
            "  inflating: gun200/gunaud/4/0.mp3   \n",
            "  inflating: gun200/gunaud/4/1.mp3   \n",
            "  inflating: gun200/gunaud/4/2.mp3   \n",
            "  inflating: gun200/gunaud/4/3.mp3   \n",
            "  inflating: gun200/gunaud/4/4.mp3   \n",
            "  inflating: gun200/gunaud/4/5.mp3   \n",
            "  inflating: gun200/gunaud/4/6.mp3   \n",
            "  inflating: gun200/gunaud/4/7.mp3   \n",
            "   creating: gun200/gunaud/5/\n",
            "  inflating: gun200/gunaud/5/0.mp3   \n",
            "  inflating: gun200/gunaud/5/1.mp3   \n",
            "  inflating: gun200/gunaud/5/2.mp3   \n",
            "  inflating: gun200/gunaud/5/3.mp3   \n",
            "  inflating: gun200/gunaud/5/4.mp3   \n",
            "  inflating: gun200/gunaud/5/5.mp3   \n",
            "  inflating: gun200/gunaud/5/6.mp3   \n",
            "  inflating: gun200/gunaud/5/7.mp3   \n",
            "  inflating: gun200/gunaud/5/8.mp3   \n",
            "  inflating: gun200/gunaud/5/9.mp3   \n",
            "  inflating: gun200/gunaud/5/10.mp3  \n",
            "  inflating: gun200/gunaud/5/11.mp3  \n",
            "   creating: gun200/gunaud/6/\n",
            "  inflating: gun200/gunaud/6/0.mp3   \n",
            "  inflating: gun200/gunaud/6/1.mp3   \n",
            "  inflating: gun200/gunaud/6/2.mp3   \n",
            "  inflating: gun200/gunaud/6/3.mp3   \n",
            "  inflating: gun200/gunaud/6/4.mp3   \n",
            "  inflating: gun200/gunaud/6/5.mp3   \n",
            "  inflating: gun200/gunaud/6/6.mp3   \n",
            "  inflating: gun200/gunaud/6/7.mp3   \n",
            "  inflating: gun200/gunaud/6/8.mp3   \n",
            "  inflating: gun200/gunaud/6/9.mp3   \n",
            "  inflating: gun200/gunaud/6/10.mp3  \n",
            "  inflating: gun200/gunaud/6/11.mp3  \n",
            "  inflating: gun200/gunaud/6/12.mp3  \n",
            "  inflating: gun200/gunaud/6/13.mp3  \n",
            "   creating: gun200/gunaud/7/\n",
            "  inflating: gun200/gunaud/7/0.mp3   \n",
            "   creating: gun200/gunaud/8/\n",
            "  inflating: gun200/gunaud/8/0.mp3   \n",
            "  inflating: gun200/gunaud/8/1.mp3   \n",
            "  inflating: gun200/gunaud/8/2.mp3   \n",
            "  inflating: gun200/gunaud/8/3.mp3   \n",
            "   creating: gun200/gunaud/9/\n",
            "  inflating: gun200/gunaud/9/0.mp3   \n",
            "   creating: gun200/gunaud/10/\n",
            "  inflating: gun200/gunaud/10/0.mp3  \n",
            "  inflating: gun200/gunaud/10/1.mp3  \n",
            "  inflating: gun200/gunaud/10/2.mp3  \n",
            "   creating: gun200/gunaud/11/\n",
            "  inflating: gun200/gunaud/11/0.mp3  \n",
            "  inflating: gun200/gunaud/11/1.mp3  \n",
            "   creating: gun200/gunaud/12/\n",
            "  inflating: gun200/gunaud/12/0.mp3  \n",
            "   creating: gun200/gunaud/13/\n",
            "  inflating: gun200/gunaud/13/0.mp3  \n",
            "  inflating: gun200/gunaud/13/1.mp3  \n",
            "  inflating: gun200/gunaud/13/2.mp3  \n",
            "  inflating: gun200/gunaud/13/3.mp3  \n",
            "  inflating: gun200/gunaud/13/4.mp3  \n",
            "  inflating: gun200/gunaud/13/5.mp3  \n",
            "  inflating: gun200/gunaud/13/6.mp3  \n",
            "  inflating: gun200/gunaud/13/7.mp3  \n",
            "   creating: gun200/gunaud/14/\n",
            "  inflating: gun200/gunaud/14/1.mp3  \n",
            "  inflating: gun200/gunaud/14/2.mp3  \n",
            "   creating: gun200/gunaud/15/\n",
            "  inflating: gun200/gunaud/15/0.mp3  \n",
            "  inflating: gun200/gunaud/15/1.mp3  \n",
            "  inflating: gun200/gunaud/15/2.mp3  \n",
            "  inflating: gun200/gunaud/15/3.mp3  \n",
            "  inflating: gun200/gunaud/15/4.mp3  \n",
            "  inflating: gun200/gunaud/15/5.mp3  \n",
            "  inflating: gun200/gunaud/15/6.mp3  \n",
            "  inflating: gun200/gunaud/15/7.mp3  \n",
            "  inflating: gun200/gunaud/15/8.mp3  \n",
            "   creating: gun200/gunaud/16/\n",
            "  inflating: gun200/gunaud/16/1.mp3  \n",
            "  inflating: gun200/gunaud/16/2.mp3  \n",
            "  inflating: gun200/gunaud/16/3.mp3  \n",
            "  inflating: gun200/gunaud/16/4.mp3  \n",
            "  inflating: gun200/gunaud/16/5.mp3  \n",
            "  inflating: gun200/gunaud/16/6.mp3  \n",
            "  inflating: gun200/gunaud/16/7.mp3  \n",
            "  inflating: gun200/gunaud/16/8.mp3  \n",
            "  inflating: gun200/gunaud/16/9.mp3  \n",
            "  inflating: gun200/gunaud/16/10.mp3  \n",
            "  inflating: gun200/gunaud/16/11.mp3  \n",
            "  inflating: gun200/gunaud/16/12.mp3  \n",
            "  inflating: gun200/gunaud/16/13.mp3  \n",
            "  inflating: gun200/gunaud/16/14.mp3  \n",
            "  inflating: gun200/gunaud/16/15.mp3  \n",
            "  inflating: gun200/gunaud/16/16.mp3  \n",
            "  inflating: gun200/gunaud/16/17.mp3  \n",
            "  inflating: gun200/gunaud/16/18.mp3  \n",
            "  inflating: gun200/gunaud/16/19.mp3  \n",
            "  inflating: gun200/gunaud/16/20.mp3  \n",
            "  inflating: gun200/gunaud/16/21.mp3  \n",
            "  inflating: gun200/gunaud/16/22.mp3  \n",
            "  inflating: gun200/gunaud/16/23.mp3  \n",
            "   creating: gun200/gunaud/18/\n",
            "  inflating: gun200/gunaud/18/0.mp3  \n",
            "   creating: gun200/gunaud/19/\n",
            "  inflating: gun200/gunaud/19/0.mp3  \n",
            "  inflating: gun200/gunaud/19/1.mp3  \n",
            "  inflating: gun200/gunaud/19/2.mp3  \n",
            "  inflating: gun200/gunaud/19/3.mp3  \n",
            "  inflating: gun200/gunaud/19/4.mp3  \n",
            "  inflating: gun200/gunaud/19/5.mp3  \n",
            "  inflating: gun200/gunaud/19/6.mp3  \n",
            "  inflating: gun200/gunaud/19/7.mp3  \n",
            "  inflating: gun200/gunaud/19/8.mp3  \n",
            "  inflating: gun200/gunaud/19/9.mp3  \n",
            "  inflating: gun200/gunaud/19/10.mp3  \n",
            "  inflating: gun200/gunaud/19/11.mp3  \n",
            "  inflating: gun200/gunaud/19/12.mp3  \n",
            "  inflating: gun200/gunaud/19/13.mp3  \n",
            "  inflating: gun200/gunaud/19/14.mp3  \n",
            "  inflating: gun200/gunaud/19/15.mp3  \n",
            "  inflating: gun200/gunaud/19/16.mp3  \n",
            "  inflating: gun200/gunaud/19/17.mp3  \n",
            "  inflating: gun200/gunaud/19/18.mp3  \n",
            "  inflating: gun200/gunaud/19/19.mp3  \n",
            "  inflating: gun200/gunaud/19/20.mp3  \n",
            "  inflating: gun200/gunaud/19/21.mp3  \n",
            "  inflating: gun200/gunaud/19/22.mp3  \n",
            "  inflating: gun200/gunaud/19/23.mp3  \n",
            "  inflating: gun200/gunaud/19/24.mp3  \n",
            "  inflating: gun200/gunaud/19/25.mp3  \n",
            "  inflating: gun200/gunaud/19/26.mp3  \n",
            "  inflating: gun200/gunaud/19/27.mp3  \n",
            "  inflating: gun200/gunaud/19/28.mp3  \n",
            "  inflating: gun200/gunaud/19/29.mp3  \n",
            "  inflating: gun200/gunaud/19/30.mp3  \n",
            "  inflating: gun200/gunaud/19/31.mp3  \n",
            "  inflating: gun200/gunaud/19/32.mp3  \n",
            "  inflating: gun200/gunaud/19/33.mp3  \n",
            "  inflating: gun200/gunaud/19/34.mp3  \n",
            "  inflating: gun200/gunaud/19/35.mp3  \n",
            "  inflating: gun200/gunaud/19/36.mp3  \n",
            "  inflating: gun200/gunaud/19/37.mp3  \n",
            "  inflating: gun200/gunaud/19/38.mp3  \n",
            "  inflating: gun200/gunaud/19/39.mp3  \n",
            "  inflating: gun200/gunaud/19/40.mp3  \n",
            "  inflating: gun200/gunaud/19/41.mp3  \n",
            "  inflating: gun200/gunaud/19/42.mp3  \n",
            "  inflating: gun200/gunaud/19/43.mp3  \n",
            "  inflating: gun200/gunaud/19/44.mp3  \n",
            "  inflating: gun200/gunaud/19/45.mp3  \n",
            "   creating: gun200/gunaud/21/\n",
            "  inflating: gun200/gunaud/21/0.mp3  \n",
            "   creating: gun200/gunaud/22/\n",
            "  inflating: gun200/gunaud/22/0.mp3  \n",
            "   creating: gun200/gunaud/23/\n",
            "  inflating: gun200/gunaud/23/0.mp3  \n",
            "  inflating: gun200/gunaud/23/1.mp3  \n",
            "  inflating: gun200/gunaud/23/2.mp3  \n",
            "  inflating: gun200/gunaud/23/3.mp3  \n",
            "  inflating: gun200/gunaud/23/4.mp3  \n",
            "  inflating: gun200/gunaud/23/5.mp3  \n",
            "  inflating: gun200/gunaud/23/6.mp3  \n",
            "  inflating: gun200/gunaud/23/7.mp3  \n",
            "  inflating: gun200/gunaud/23/8.mp3  \n",
            "  inflating: gun200/gunaud/23/9.mp3  \n",
            "  inflating: gun200/gunaud/23/10.mp3  \n",
            "  inflating: gun200/gunaud/23/11.mp3  \n",
            "  inflating: gun200/gunaud/23/12.mp3  \n",
            "  inflating: gun200/gunaud/23/13.mp3  \n",
            "   creating: gun200/gunaud/24/\n",
            "  inflating: gun200/gunaud/24/0.mp3  \n",
            "  inflating: gun200/gunaud/24/1.mp3  \n",
            "  inflating: gun200/gunaud/24/2.mp3  \n",
            "  inflating: gun200/gunaud/24/3.mp3  \n",
            "  inflating: gun200/gunaud/24/4.mp3  \n",
            "  inflating: gun200/gunaud/24/5.mp3  \n",
            "  inflating: gun200/gunaud/24/6.mp3  \n",
            "  inflating: gun200/gunaud/24/7.mp3  \n",
            "  inflating: gun200/gunaud/24/8.mp3  \n",
            "  inflating: gun200/gunaud/24/9.mp3  \n",
            "  inflating: gun200/gunaud/24/10.mp3  \n",
            "  inflating: gun200/gunaud/24/11.mp3  \n",
            "  inflating: gun200/gunaud/24/12.mp3  \n",
            "  inflating: gun200/gunaud/24/13.mp3  \n",
            "   creating: gun200/gunaud/25/\n",
            "  inflating: gun200/gunaud/25/0.mp3  \n",
            "  inflating: gun200/gunaud/25/1.mp3  \n",
            "  inflating: gun200/gunaud/25/2.mp3  \n",
            "  inflating: gun200/gunaud/25/3.mp3  \n",
            "   creating: gun200/gunaud/26/\n",
            "  inflating: gun200/gunaud/26/0.mp3  \n",
            "   creating: gun200/gunaud/27/\n",
            "  inflating: gun200/gunaud/27/0.mp3  \n",
            "  inflating: gun200/gunaud/27/1.mp3  \n",
            "  inflating: gun200/gunaud/27/2.mp3  \n",
            "  inflating: gun200/gunaud/27/3.mp3  \n",
            "  inflating: gun200/gunaud/27/4.mp3  \n",
            "  inflating: gun200/gunaud/27/5.mp3  \n",
            "  inflating: gun200/gunaud/27/6.mp3  \n",
            "  inflating: gun200/gunaud/27/7.mp3  \n",
            "  inflating: gun200/gunaud/27/8.mp3  \n",
            "  inflating: gun200/gunaud/27/9.mp3  \n",
            "  inflating: gun200/gunaud/27/10.mp3  \n",
            "  inflating: gun200/gunaud/27/11.mp3  \n",
            "  inflating: gun200/gunaud/27/12.mp3  \n",
            "   creating: gun200/gunaud/28/\n",
            "  inflating: gun200/gunaud/28/0.mp3  \n",
            "  inflating: gun200/gunaud/28/1.mp3  \n",
            "  inflating: gun200/gunaud/28/2.mp3  \n",
            "  inflating: gun200/gunaud/28/3.mp3  \n",
            "  inflating: gun200/gunaud/28/4.mp3  \n",
            "  inflating: gun200/gunaud/28/6.mp3  \n",
            "   creating: gun200/gunaud/29/\n",
            "  inflating: gun200/gunaud/29/0.mp3  \n",
            "  inflating: gun200/gunaud/29/1.mp3  \n",
            "   creating: gun200/gunaud/30/\n",
            "  inflating: gun200/gunaud/30/0.mp3  \n",
            "  inflating: gun200/gunaud/30/1.mp3  \n",
            "  inflating: gun200/gunaud/30/2.mp3  \n",
            "  inflating: gun200/gunaud/30/3.mp3  \n",
            "  inflating: gun200/gunaud/30/4.mp3  \n",
            "  inflating: gun200/gunaud/30/5.mp3  \n",
            "  inflating: gun200/gunaud/30/6.mp3  \n",
            "  inflating: gun200/gunaud/30/7.mp3  \n",
            "  inflating: gun200/gunaud/30/8.mp3  \n",
            "  inflating: gun200/gunaud/30/9.mp3  \n",
            "  inflating: gun200/gunaud/30/10.mp3  \n",
            "  inflating: gun200/gunaud/30/11.mp3  \n",
            "  inflating: gun200/gunaud/30/12.mp3  \n",
            "  inflating: gun200/gunaud/30/13.mp3  \n",
            "  inflating: gun200/gunaud/30/14.mp3  \n",
            "  inflating: gun200/gunaud/30/15.mp3  \n",
            "  inflating: gun200/gunaud/30/16.mp3  \n",
            "  inflating: gun200/gunaud/30/17.mp3  \n",
            "  inflating: gun200/gunaud/30/18.mp3  \n",
            "  inflating: gun200/gunaud/30/19.mp3  \n",
            "   creating: gun200/gunaud/31/\n",
            "  inflating: gun200/gunaud/31/0.mp3  \n",
            "  inflating: gun200/gunaud/31/1.mp3  \n",
            "  inflating: gun200/gunaud/31/2.mp3  \n",
            "  inflating: gun200/gunaud/31/3.mp3  \n",
            "  inflating: gun200/gunaud/31/4.mp3  \n",
            "  inflating: gun200/gunaud/31/5.mp3  \n",
            "  inflating: gun200/gunaud/31/6.mp3  \n",
            "  inflating: gun200/gunaud/31/7.mp3  \n",
            "  inflating: gun200/gunaud/31/8.mp3  \n",
            "  inflating: gun200/gunaud/31/9.mp3  \n",
            "  inflating: gun200/gunaud/31/10.mp3  \n",
            "  inflating: gun200/gunaud/31/11.mp3  \n",
            "  inflating: gun200/gunaud/31/12.mp3  \n",
            "  inflating: gun200/gunaud/31/13.mp3  \n",
            "  inflating: gun200/gunaud/31/14.mp3  \n",
            "  inflating: gun200/gunaud/31/15.mp3  \n",
            "  inflating: gun200/gunaud/31/16.mp3  \n",
            "  inflating: gun200/gunaud/31/17.mp3  \n",
            "   creating: gun200/gunaud/32/\n",
            "  inflating: gun200/gunaud/32/0.mp3  \n",
            "  inflating: gun200/gunaud/32/1.mp3  \n",
            "  inflating: gun200/gunaud/32/2.mp3  \n",
            "  inflating: gun200/gunaud/32/3.mp3  \n",
            "  inflating: gun200/gunaud/32/4.mp3  \n",
            "  inflating: gun200/gunaud/32/5.mp3  \n",
            "  inflating: gun200/gunaud/32/6.mp3  \n",
            "   creating: gun200/gunaud/33/\n",
            "  inflating: gun200/gunaud/33/0.mp3  \n",
            "  inflating: gun200/gunaud/33/1.mp3  \n",
            "  inflating: gun200/gunaud/33/2.mp3  \n",
            "  inflating: gun200/gunaud/33/3.mp3  \n",
            "  inflating: gun200/gunaud/33/4.mp3  \n",
            "  inflating: gun200/gunaud/33/5.mp3  \n",
            "  inflating: gun200/gunaud/33/6.mp3  \n",
            "  inflating: gun200/gunaud/33/8.mp3  \n",
            "   creating: gun200/gunaud/34/\n",
            "  inflating: gun200/gunaud/34/0.mp3  \n",
            "   creating: gun200/gunaud/35/\n",
            "  inflating: gun200/gunaud/35/0.mp3  \n",
            "  inflating: gun200/gunaud/35/1.mp3  \n",
            "  inflating: gun200/gunaud/35/2.mp3  \n",
            "  inflating: gun200/gunaud/35/3.mp3  \n",
            "  inflating: gun200/gunaud/35/4.mp3  \n",
            "  inflating: gun200/gunaud/35/5.mp3  \n",
            "  inflating: gun200/gunaud/35/6.mp3  \n",
            "  inflating: gun200/gunaud/35/7.mp3  \n",
            "  inflating: gun200/gunaud/35/8.mp3  \n",
            "  inflating: gun200/gunaud/35/9.mp3  \n",
            "  inflating: gun200/gunaud/35/10.mp3  \n",
            "  inflating: gun200/gunaud/35/11.mp3  \n",
            "   creating: gun200/gunaud/36/\n",
            "  inflating: gun200/gunaud/36/0.mp3  \n",
            "  inflating: gun200/gunaud/36/1.mp3  \n",
            "  inflating: gun200/gunaud/36/2.mp3  \n",
            "  inflating: gun200/gunaud/36/3.mp3  \n",
            "  inflating: gun200/gunaud/36/4.mp3  \n",
            "  inflating: gun200/gunaud/36/5.mp3  \n",
            "  inflating: gun200/gunaud/36/6.mp3  \n",
            "  inflating: gun200/gunaud/36/8.mp3  \n",
            "  inflating: gun200/gunaud/36/9.mp3  \n",
            "   creating: gun200/gunaud/37/\n",
            "  inflating: gun200/gunaud/37/0.mp3  \n",
            "  inflating: gun200/gunaud/37/1.mp3  \n",
            "  inflating: gun200/gunaud/37/2.mp3  \n",
            "  inflating: gun200/gunaud/37/3.mp3  \n",
            "  inflating: gun200/gunaud/37/4.mp3  \n",
            "  inflating: gun200/gunaud/37/5.mp3  \n",
            "  inflating: gun200/gunaud/37/6.mp3  \n",
            "  inflating: gun200/gunaud/37/7.mp3  \n",
            "  inflating: gun200/gunaud/37/8.mp3  \n",
            "  inflating: gun200/gunaud/37/9.mp3  \n",
            "  inflating: gun200/gunaud/37/10.mp3  \n",
            "  inflating: gun200/gunaud/37/11.mp3  \n",
            "  inflating: gun200/gunaud/37/12.mp3  \n",
            "  inflating: gun200/gunaud/37/13.mp3  \n",
            "   creating: gun200/gunaud/38/\n",
            "  inflating: gun200/gunaud/38/0.mp3  \n",
            "  inflating: gun200/gunaud/38/1.mp3  \n",
            "  inflating: gun200/gunaud/38/2.mp3  \n",
            "  inflating: gun200/gunaud/38/3.mp3  \n",
            "  inflating: gun200/gunaud/38/4.mp3  \n",
            "  inflating: gun200/gunaud/38/5.mp3  \n",
            "  inflating: gun200/gunaud/38/6.mp3  \n",
            "  inflating: gun200/gunaud/38/7.mp3  \n",
            "   creating: gun200/gunaud/39/\n",
            "  inflating: gun200/gunaud/39/0.mp3  \n",
            "  inflating: gun200/gunaud/39/1.mp3  \n",
            "  inflating: gun200/gunaud/39/2.mp3  \n",
            "  inflating: gun200/gunaud/39/3.mp3  \n",
            "  inflating: gun200/gunaud/39/4.mp3  \n",
            "  inflating: gun200/gunaud/39/5.mp3  \n",
            "  inflating: gun200/gunaud/39/6.mp3  \n",
            "  inflating: gun200/gunaud/39/7.mp3  \n",
            "  inflating: gun200/gunaud/39/8.mp3  \n",
            "   creating: gun200/gunaud/41/\n",
            "  inflating: gun200/gunaud/41/0.mp3  \n",
            "  inflating: gun200/gunaud/41/1.mp3  \n",
            "  inflating: gun200/gunaud/41/2.mp3  \n",
            "  inflating: gun200/gunaud/41/3.mp3  \n",
            "  inflating: gun200/gunaud/41/4.mp3  \n",
            "  inflating: gun200/gunaud/41/5.mp3  \n",
            "  inflating: gun200/gunaud/41/6.mp3  \n",
            "   creating: gun200/gunaud/42/\n",
            "  inflating: gun200/gunaud/42/0.mp3  \n",
            "  inflating: gun200/gunaud/42/1.mp3  \n",
            "  inflating: gun200/gunaud/42/2.mp3  \n",
            "  inflating: gun200/gunaud/42/3.mp3  \n",
            "  inflating: gun200/gunaud/42/4.mp3  \n",
            "  inflating: gun200/gunaud/42/5.mp3  \n",
            "  inflating: gun200/gunaud/42/6.mp3  \n",
            "  inflating: gun200/gunaud/42/7.mp3  \n",
            "  inflating: gun200/gunaud/42/8.mp3  \n",
            "  inflating: gun200/gunaud/42/9.mp3  \n",
            "  inflating: gun200/gunaud/42/10.mp3  \n",
            "  inflating: gun200/gunaud/42/11.mp3  \n",
            "   creating: gun200/gunaud/43/\n",
            "  inflating: gun200/gunaud/43/0.mp3  \n",
            "  inflating: gun200/gunaud/43/1.mp3  \n",
            "  inflating: gun200/gunaud/43/2.mp3  \n",
            "  inflating: gun200/gunaud/43/3.mp3  \n",
            "  inflating: gun200/gunaud/43/4.mp3  \n",
            "  inflating: gun200/gunaud/43/5.mp3  \n",
            "  inflating: gun200/gunaud/43/6.mp3  \n",
            "  inflating: gun200/gunaud/43/7.mp3  \n",
            "  inflating: gun200/gunaud/43/8.mp3  \n",
            "   creating: gun200/gunaud/44/\n",
            "  inflating: gun200/gunaud/44/0.mp3  \n",
            "  inflating: gun200/gunaud/44/1.mp3  \n",
            "  inflating: gun200/gunaud/44/2.mp3  \n",
            "  inflating: gun200/gunaud/44/3.mp3  \n",
            "  inflating: gun200/gunaud/44/4.mp3  \n",
            "  inflating: gun200/gunaud/44/5.mp3  \n",
            "  inflating: gun200/gunaud/44/6.mp3  \n",
            "  inflating: gun200/gunaud/44/7.mp3  \n",
            "  inflating: gun200/gunaud/44/8.mp3  \n",
            "  inflating: gun200/gunaud/44/9.mp3  \n",
            "   creating: gun200/gunaud/45/\n",
            "  inflating: gun200/gunaud/45/0.mp3  \n",
            "  inflating: gun200/gunaud/45/1.mp3  \n",
            "   creating: gun200/gunaud/46/\n",
            "  inflating: gun200/gunaud/46/0.mp3  \n",
            "  inflating: gun200/gunaud/46/1.mp3  \n",
            "  inflating: gun200/gunaud/46/2.mp3  \n",
            "  inflating: gun200/gunaud/46/3.mp3  \n",
            "   creating: gun200/gunaud/47/\n",
            "  inflating: gun200/gunaud/47/1.mp3  \n",
            "   creating: gun200/gunaud/48/\n",
            "  inflating: gun200/gunaud/48/0.mp3  \n",
            "  inflating: gun200/gunaud/48/1.mp3  \n",
            "  inflating: gun200/gunaud/48/2.mp3  \n",
            "  inflating: gun200/gunaud/48/3.mp3  \n",
            "   creating: gun200/gunaud/49/\n",
            "  inflating: gun200/gunaud/49/0.mp3  \n",
            "  inflating: gun200/gunaud/49/1.mp3  \n",
            "  inflating: gun200/gunaud/49/2.mp3  \n",
            "  inflating: gun200/gunaud/49/3.mp3  \n",
            "  inflating: gun200/gunaud/49/4.mp3  \n",
            "  inflating: gun200/gunaud/49/5.mp3  \n",
            "  inflating: gun200/gunaud/49/6.mp3  \n",
            "  inflating: gun200/gunaud/49/7.mp3  \n",
            "  inflating: gun200/gunaud/49/8.mp3  \n",
            "  inflating: gun200/gunaud/49/9.mp3  \n",
            "  inflating: gun200/gunaud/49/10.mp3  \n",
            "  inflating: gun200/gunaud/49/11.mp3  \n",
            "   creating: gun200/gunaud/50/\n",
            "  inflating: gun200/gunaud/50/0.mp3  \n",
            "  inflating: gun200/gunaud/50/1.mp3  \n",
            "  inflating: gun200/gunaud/50/2.mp3  \n",
            "  inflating: gun200/gunaud/50/3.mp3  \n",
            "  inflating: gun200/gunaud/50/5.mp3  \n",
            "   creating: gun200/gunaud/52./\n",
            "  inflating: gun200/gunaud/52./52.0.mp3  \n",
            "  inflating: gun200/gunaud/52./52.1.mp3  \n",
            "  inflating: gun200/gunaud/52./52.2.mp3  \n",
            "  inflating: gun200/gunaud/52./52.3.mp3  \n",
            "  inflating: gun200/gunaud/52./52.4.mp3  \n",
            "  inflating: gun200/gunaud/52./52.5.mp3  \n",
            "  inflating: gun200/gunaud/52./52.6.mp3  \n",
            "  inflating: gun200/gunaud/52./52.7.mp3  \n",
            "  inflating: gun200/gunaud/52./52.8.mp3  \n",
            "  inflating: gun200/gunaud/52./52.9.mp3  \n",
            "  inflating: gun200/gunaud/52./52.10.mp3  \n",
            "  inflating: gun200/gunaud/52./52.11.mp3  \n",
            "  inflating: gun200/gunaud/52./52.12.mp3  \n",
            "  inflating: gun200/gunaud/52./52.13.mp3  \n",
            "  inflating: gun200/gunaud/52./52.14.mp3  \n",
            "  inflating: gun200/gunaud/52./52.15.mp3  \n",
            "  inflating: gun200/gunaud/52./52.16.mp3  \n",
            "  inflating: gun200/gunaud/52./52.17.mp3  \n",
            "   creating: gun200/gunaud/53./\n",
            "  inflating: gun200/gunaud/53./53.0.mp3  \n",
            "  inflating: gun200/gunaud/53./53.1.mp3  \n",
            "  inflating: gun200/gunaud/53./53.2.mp3  \n",
            "  inflating: gun200/gunaud/53./53.3.mp3  \n",
            "   creating: gun200/gunaud/54./\n",
            "  inflating: gun200/gunaud/54./54.0.mp3  \n",
            "  inflating: gun200/gunaud/54./54.1.mp3  \n",
            "  inflating: gun200/gunaud/54./54.2.mp3  \n",
            "  inflating: gun200/gunaud/54./54.3.mp3  \n",
            "  inflating: gun200/gunaud/54./54.4.mp3  \n",
            "  inflating: gun200/gunaud/54./54.5.mp3  \n",
            "   creating: gun200/gunaud/55./\n",
            "  inflating: gun200/gunaud/55./55.0.mp3  \n",
            "   creating: gun200/gunaud/56./\n",
            "  inflating: gun200/gunaud/56./56.3.mp3  \n",
            "   creating: gun200/gunaud/57./\n",
            "  inflating: gun200/gunaud/57./57.0.mp3  \n",
            "  inflating: gun200/gunaud/57./57.1.mp3  \n",
            "  inflating: gun200/gunaud/57./57.2.mp3  \n",
            "  inflating: gun200/gunaud/57./57.3.mp3  \n",
            "  inflating: gun200/gunaud/57./57.4.mp3  \n",
            "  inflating: gun200/gunaud/57./57.5.mp3  \n",
            "  inflating: gun200/gunaud/57./57.6.mp3  \n",
            "  inflating: gun200/gunaud/57./57.7.mp3  \n",
            "   creating: gun200/gunaud/58./\n",
            "  inflating: gun200/gunaud/58./58.0.mp3  \n",
            "  inflating: gun200/gunaud/58./58.1.mp3  \n",
            "  inflating: gun200/gunaud/58./58.2.mp3  \n",
            "  inflating: gun200/gunaud/58./58.3.mp3  \n",
            "   creating: gun200/gunaud/59./\n",
            "  inflating: gun200/gunaud/59./59.0.mp3  \n",
            "  inflating: gun200/gunaud/59./59.1.mp3  \n",
            "  inflating: gun200/gunaud/59./59.2.mp3  \n",
            "  inflating: gun200/gunaud/59./59.3.mp3  \n",
            "  inflating: gun200/gunaud/59./59.4.mp3  \n",
            "   creating: gun200/gunaud/60./\n",
            "  inflating: gun200/gunaud/60./60.0.mp3  \n",
            "  inflating: gun200/gunaud/60./60.1.mp3  \n",
            "  inflating: gun200/gunaud/60./60.2.mp3  \n",
            "  inflating: gun200/gunaud/60./60.3.mp3  \n",
            "   creating: gun200/gunaud/61./\n",
            "  inflating: gun200/gunaud/61./61.0.mp3  \n",
            "  inflating: gun200/gunaud/61./61.1.mp3  \n",
            "  inflating: gun200/gunaud/61./61.2.mp3  \n",
            "  inflating: gun200/gunaud/61./61.3.mp3  \n",
            "  inflating: gun200/gunaud/61./61.4.mp3  \n",
            "  inflating: gun200/gunaud/61./61.5.mp3  \n",
            "  inflating: gun200/gunaud/61./61.6.mp3  \n",
            "  inflating: gun200/gunaud/61./61.7.mp3  \n",
            "  inflating: gun200/gunaud/61./61.8.mp3  \n",
            "   creating: gun200/gunaud/62./\n",
            "  inflating: gun200/gunaud/62./62.0.mp3  \n",
            "  inflating: gun200/gunaud/62./62.1.mp3  \n",
            "   creating: gun200/gunaud/63./\n",
            "  inflating: gun200/gunaud/63./63.0.mp3  \n",
            "  inflating: gun200/gunaud/63./63.1.mp3  \n",
            "  inflating: gun200/gunaud/63./63.2.mp3  \n",
            "  inflating: gun200/gunaud/63./63.3.mp3  \n",
            "  inflating: gun200/gunaud/63./63.4.mp3  \n",
            "  inflating: gun200/gunaud/63./63.5.mp3  \n",
            "  inflating: gun200/gunaud/63./63.6.mp3  \n",
            "  inflating: gun200/gunaud/63./63.7.mp3  \n",
            "  inflating: gun200/gunaud/63./63.8.mp3  \n",
            "  inflating: gun200/gunaud/63./63.9.mp3  \n",
            "  inflating: gun200/gunaud/63./63.10.mp3  \n",
            "  inflating: gun200/gunaud/63./63.11.mp3  \n",
            "  inflating: gun200/gunaud/63./63.12.mp3  \n",
            "  inflating: gun200/gunaud/63./63.13.mp3  \n",
            "  inflating: gun200/gunaud/63./63.14.mp3  \n",
            "  inflating: gun200/gunaud/63./63.15.mp3  \n",
            "   creating: gun200/gunaud/64./\n",
            "  inflating: gun200/gunaud/64./64.0.mp3  \n",
            "  inflating: gun200/gunaud/64./64.1.mp3  \n",
            "  inflating: gun200/gunaud/64./64.2.mp3  \n",
            "  inflating: gun200/gunaud/64./64.3.mp3  \n",
            "  inflating: gun200/gunaud/64./64.4.mp3  \n",
            "  inflating: gun200/gunaud/64./64.5.mp3  \n",
            "  inflating: gun200/gunaud/64./64.6.mp3  \n",
            "  inflating: gun200/gunaud/64./64.7.mp3  \n",
            "  inflating: gun200/gunaud/64./64.8.mp3  \n",
            "  inflating: gun200/gunaud/64./64.9.mp3  \n",
            "  inflating: gun200/gunaud/64./64.10.mp3  \n",
            "  inflating: gun200/gunaud/64./64.12.mp3  \n",
            "  inflating: gun200/gunaud/64./64.13.mp3  \n",
            "  inflating: gun200/gunaud/64./64.14.mp3  \n",
            "   creating: gun200/gunaud/65./\n",
            "  inflating: gun200/gunaud/65./65.0.mp3  \n",
            "  inflating: gun200/gunaud/65./65.1.mp3  \n",
            "  inflating: gun200/gunaud/65./65.2.mp3  \n",
            "  inflating: gun200/gunaud/65./65.3.mp3  \n",
            "  inflating: gun200/gunaud/65./65.4.mp3  \n",
            "   creating: gun200/gunaud/66./\n",
            "  inflating: gun200/gunaud/66./66.0.mp3  \n",
            "  inflating: gun200/gunaud/66./66.1.mp3  \n",
            "  inflating: gun200/gunaud/66./66.2.mp3  \n",
            "  inflating: gun200/gunaud/66./66.3.mp3  \n",
            "   creating: gun200/gunaud/67./\n",
            "  inflating: gun200/gunaud/67./67.0.mp3  \n",
            "  inflating: gun200/gunaud/67./67.1.mp3  \n",
            "  inflating: gun200/gunaud/67./67.2.mp3  \n",
            "  inflating: gun200/gunaud/67./67.3.mp3  \n",
            "  inflating: gun200/gunaud/67./67.4.mp3  \n",
            "  inflating: gun200/gunaud/67./67.5.mp3  \n",
            "  inflating: gun200/gunaud/67./67.6.mp3  \n",
            "   creating: gun200/gunaud/68./\n",
            "  inflating: gun200/gunaud/68./68.0.mp3  \n",
            "  inflating: gun200/gunaud/68./68.1.mp3  \n",
            "  inflating: gun200/gunaud/68./68.2.mp3  \n",
            "  inflating: gun200/gunaud/68./68.3.mp3  \n",
            "  inflating: gun200/gunaud/68./68.4.mp3  \n",
            "  inflating: gun200/gunaud/68./68.5.mp3  \n",
            "  inflating: gun200/gunaud/68./68.6.mp3  \n",
            "   creating: gun200/gunaud/69./\n",
            "  inflating: gun200/gunaud/69./69.0.mp3  \n",
            "  inflating: gun200/gunaud/69./69.1.mp3  \n",
            "  inflating: gun200/gunaud/69./69.2.mp3  \n",
            "  inflating: gun200/gunaud/69./69.3.mp3  \n",
            "  inflating: gun200/gunaud/69./69.4.mp3  \n",
            "  inflating: gun200/gunaud/69./69.5.mp3  \n",
            "  inflating: gun200/gunaud/69./69.6.mp3  \n",
            "  inflating: gun200/gunaud/69./69.7.mp3  \n",
            "  inflating: gun200/gunaud/69./69.8.mp3  \n",
            "   creating: gun200/gunaud/70./\n",
            "  inflating: gun200/gunaud/70./70.0.mp3  \n",
            "  inflating: gun200/gunaud/70./70.1.mp3  \n",
            "  inflating: gun200/gunaud/70./70.2.mp3  \n",
            "  inflating: gun200/gunaud/70./70.3.mp3  \n",
            "  inflating: gun200/gunaud/70./70.4.mp3  \n",
            "  inflating: gun200/gunaud/70./70.5.mp3  \n",
            "  inflating: gun200/gunaud/70./70.6.mp3  \n",
            "  inflating: gun200/gunaud/70./70.7.mp3  \n",
            "  inflating: gun200/gunaud/70./70.8.mp3  \n",
            "  inflating: gun200/gunaud/70./70.9.mp3  \n",
            "  inflating: gun200/gunaud/70./70.10.mp3  \n",
            "  inflating: gun200/gunaud/70./70.11.mp3  \n",
            "  inflating: gun200/gunaud/70./70.12.mp3  \n",
            "   creating: gun200/gunaud/71./\n",
            "  inflating: gun200/gunaud/71./71.0.mp3  \n",
            "  inflating: gun200/gunaud/71./71.1.mp3  \n",
            "  inflating: gun200/gunaud/71./71.2.mp3  \n",
            "  inflating: gun200/gunaud/71./71.3.mp3  \n",
            "  inflating: gun200/gunaud/71./71.4.mp3  \n",
            "  inflating: gun200/gunaud/71./71.5.mp3  \n",
            "  inflating: gun200/gunaud/71./71.6.mp3  \n",
            "  inflating: gun200/gunaud/71./71.7.mp3  \n",
            "  inflating: gun200/gunaud/71./71.8.mp3  \n",
            "  inflating: gun200/gunaud/71./71.9.mp3  \n",
            "  inflating: gun200/gunaud/71./71.10.mp3  \n",
            "   creating: gun200/gunaud/72./\n",
            "  inflating: gun200/gunaud/72./72.0.mp3  \n",
            "  inflating: gun200/gunaud/72./72.1.mp3  \n",
            "  inflating: gun200/gunaud/72./72.2.mp3  \n",
            "  inflating: gun200/gunaud/72./72.3.mp3  \n",
            "  inflating: gun200/gunaud/72./72.4.mp3  \n",
            "   creating: gun200/gunaud/73./\n",
            "  inflating: gun200/gunaud/73./73.0.mp3  \n",
            "  inflating: gun200/gunaud/73./73.1.mp3  \n",
            "  inflating: gun200/gunaud/73./73.2.mp3  \n",
            "  inflating: gun200/gunaud/73./73.3.mp3  \n",
            "  inflating: gun200/gunaud/73./73.4.mp3  \n",
            "   creating: gun200/gunaud/74./\n",
            "  inflating: gun200/gunaud/74./74.0.mp3  \n",
            "  inflating: gun200/gunaud/74./74.1.mp3  \n",
            "  inflating: gun200/gunaud/74./74.2.mp3  \n",
            "  inflating: gun200/gunaud/74./74.3.mp3  \n",
            "  inflating: gun200/gunaud/74./74.4.mp3  \n",
            "  inflating: gun200/gunaud/74./74.5.mp3  \n",
            "  inflating: gun200/gunaud/74./74.6.mp3  \n",
            "  inflating: gun200/gunaud/74./74.7.mp3  \n",
            "  inflating: gun200/gunaud/74./74.8.mp3  \n",
            "  inflating: gun200/gunaud/74./74.9.mp3  \n",
            "  inflating: gun200/gunaud/74./74.10.mp3  \n",
            "  inflating: gun200/gunaud/74./74.11.mp3  \n",
            "  inflating: gun200/gunaud/74./74.12.mp3  \n",
            "  inflating: gun200/gunaud/74./74.13.mp3  \n",
            "  inflating: gun200/gunaud/74./74.14.mp3  \n",
            "  inflating: gun200/gunaud/74./74.15.mp3  \n",
            "  inflating: gun200/gunaud/74./74.16.mp3  \n",
            "  inflating: gun200/gunaud/74./74.17.mp3  \n",
            "  inflating: gun200/gunaud/74./74.18.mp3  \n",
            "  inflating: gun200/gunaud/74./74.20.mp3  \n",
            "  inflating: gun200/gunaud/74./74.21.mp3  \n",
            "   creating: gun200/gunaud/76./\n",
            "  inflating: gun200/gunaud/76./76.0.mp3  \n",
            "  inflating: gun200/gunaud/76./76.1.mp3  \n",
            "  inflating: gun200/gunaud/76./76.2.mp3  \n",
            "  inflating: gun200/gunaud/76./76.3.mp3  \n",
            "  inflating: gun200/gunaud/76./76.4.mp3  \n",
            "  inflating: gun200/gunaud/76./76.5.mp3  \n",
            "  inflating: gun200/gunaud/76./76.6.mp3  \n",
            "  inflating: gun200/gunaud/76./76.7.mp3  \n",
            "  inflating: gun200/gunaud/76./76.8.mp3  \n",
            "  inflating: gun200/gunaud/76./76.9.mp3  \n",
            "  inflating: gun200/gunaud/76./76.10.mp3  \n",
            "  inflating: gun200/gunaud/76./76.11.mp3  \n",
            "  inflating: gun200/gunaud/76./76.12.mp3  \n",
            "  inflating: gun200/gunaud/76./76.13.mp3  \n",
            "  inflating: gun200/gunaud/76./76.14.mp3  \n",
            "  inflating: gun200/gunaud/76./76.16.mp3  \n",
            "  inflating: gun200/gunaud/76./76.17.mp3  \n",
            "  inflating: gun200/gunaud/76./76.18.mp3  \n",
            "  inflating: gun200/gunaud/76./76.19.mp3  \n",
            "  inflating: gun200/gunaud/76./76.20.mp3  \n",
            "  inflating: gun200/gunaud/76./76.21.mp3  \n",
            "  inflating: gun200/gunaud/76./76.23.mp3  \n",
            "   creating: gun200/gunaud/77./\n",
            "  inflating: gun200/gunaud/77./77.0.mp3  \n",
            "  inflating: gun200/gunaud/77./77.1.mp3  \n",
            "  inflating: gun200/gunaud/77./77.2.mp3  \n",
            "  inflating: gun200/gunaud/77./77.3.mp3  \n",
            "   creating: gun200/gunaud/78./\n",
            "  inflating: gun200/gunaud/78./78.0.mp3  \n",
            "  inflating: gun200/gunaud/78./78.1.mp3  \n",
            "  inflating: gun200/gunaud/78./78.2.mp3  \n",
            "  inflating: gun200/gunaud/78./78.3.mp3  \n",
            "  inflating: gun200/gunaud/78./78.4.mp3  \n",
            "  inflating: gun200/gunaud/78./78.5.mp3  \n",
            "   creating: gun200/gunaud/79./\n",
            "  inflating: gun200/gunaud/79./79.0.mp3  \n",
            "  inflating: gun200/gunaud/79./79.1.mp3  \n",
            "  inflating: gun200/gunaud/79./79.2.mp3  \n",
            "  inflating: gun200/gunaud/79./79.3.mp3  \n",
            "   creating: gun200/gunaud/81./\n",
            "  inflating: gun200/gunaud/81./81.0.mp3  \n",
            "  inflating: gun200/gunaud/81./81.1.mp3  \n",
            "  inflating: gun200/gunaud/81./81.2.mp3  \n",
            "   creating: gun200/gunaud/84./\n",
            "  inflating: gun200/gunaud/84./84.0.mp3  \n",
            "  inflating: gun200/gunaud/84./84.1.mp3  \n",
            "  inflating: gun200/gunaud/84./84.2.mp3  \n",
            "  inflating: gun200/gunaud/84./84.3.mp3  \n",
            "  inflating: gun200/gunaud/84./84.4.mp3  \n",
            "  inflating: gun200/gunaud/84./84.5.mp3  \n",
            "  inflating: gun200/gunaud/84./84.6.mp3  \n",
            "  inflating: gun200/gunaud/84./84.7.mp3  \n",
            "  inflating: gun200/gunaud/84./84.8.mp3  \n",
            "  inflating: gun200/gunaud/84./84.9.mp3  \n",
            "  inflating: gun200/gunaud/84./84.10.mp3  \n",
            "  inflating: gun200/gunaud/84./84.11.mp3  \n",
            "  inflating: gun200/gunaud/84./84.12.mp3  \n",
            "  inflating: gun200/gunaud/84./84.13.mp3  \n",
            "   creating: gun200/gunaud/85./\n",
            "  inflating: gun200/gunaud/85./85.0.mp3  \n",
            "  inflating: gun200/gunaud/85./85.1.mp3  \n",
            "  inflating: gun200/gunaud/85./85.2.mp3  \n",
            "  inflating: gun200/gunaud/85./85.3.mp3  \n",
            "  inflating: gun200/gunaud/85./85.4.mp3  \n",
            "  inflating: gun200/gunaud/85./85.5.mp3  \n",
            "  inflating: gun200/gunaud/85./85.6.mp3  \n",
            "   creating: gun200/gunaud/86./\n",
            "  inflating: gun200/gunaud/86./86.0.mp3  \n",
            "  inflating: gun200/gunaud/86./86.1.mp3  \n",
            "   creating: gun200/gunaud/87./\n",
            "  inflating: gun200/gunaud/87./87.0.mp3  \n",
            "  inflating: gun200/gunaud/87./87.1.mp3  \n",
            "   creating: gun200/gunaud/90./\n",
            "  inflating: gun200/gunaud/90./90.0.mp3  \n",
            "  inflating: gun200/gunaud/90./90.1.mp3  \n",
            "  inflating: gun200/gunaud/90./90.2.mp3  \n",
            "  inflating: gun200/gunaud/90./90.3.mp3  \n",
            "  inflating: gun200/gunaud/90./90.5.mp3  \n",
            "   creating: gun200/rifleaud/\n",
            "   creating: gun200/rifleaud/0/\n",
            "  inflating: gun200/rifleaud/0/0.mp3  \n",
            "  inflating: gun200/rifleaud/0/1.mp3  \n",
            "   creating: gun200/rifleaud/1/\n",
            "  inflating: gun200/rifleaud/1/0.mp3  \n",
            "  inflating: gun200/rifleaud/1/1.mp3  \n",
            "  inflating: gun200/rifleaud/1/2.mp3  \n",
            "  inflating: gun200/rifleaud/1/3.mp3  \n",
            "  inflating: gun200/rifleaud/1/4.mp3  \n",
            "  inflating: gun200/rifleaud/1/5.mp3  \n",
            "  inflating: gun200/rifleaud/1/6.mp3  \n",
            "  inflating: gun200/rifleaud/1/7.mp3  \n",
            "  inflating: gun200/rifleaud/1/8.mp3  \n",
            "  inflating: gun200/rifleaud/1/9.mp3  \n",
            "   creating: gun200/rifleaud/2/\n",
            "  inflating: gun200/rifleaud/2/0.mp3  \n",
            "   creating: gun200/rifleaud/3/\n",
            "  inflating: gun200/rifleaud/3/1.mp3  \n",
            "   creating: gun200/rifleaud/4/\n",
            "  inflating: gun200/rifleaud/4/0.mp3  \n",
            "  inflating: gun200/rifleaud/4/1.mp3  \n",
            "  inflating: gun200/rifleaud/4/2.mp3  \n",
            "  inflating: gun200/rifleaud/4/4.mp3  \n",
            "  inflating: gun200/rifleaud/4/5.mp3  \n",
            "  inflating: gun200/rifleaud/4/8.mp3  \n",
            "  inflating: gun200/rifleaud/4/9.mp3  \n",
            "  inflating: gun200/rifleaud/4/10.mp3  \n",
            "  inflating: gun200/rifleaud/4/11.mp3  \n",
            "  inflating: gun200/rifleaud/4/12.mp3  \n",
            "   creating: gun200/rifleaud/5/\n",
            "  inflating: gun200/rifleaud/5/0.mp3  \n",
            "   creating: gun200/rifleaud/6/\n",
            "  inflating: gun200/rifleaud/6/0.mp3  \n",
            "  inflating: gun200/rifleaud/6/1.mp3  \n",
            "  inflating: gun200/rifleaud/6/2.mp3  \n",
            "  inflating: gun200/rifleaud/6/3.mp3  \n",
            "   creating: gun200/rifleaud/7/\n",
            "  inflating: gun200/rifleaud/7/0.mp3  \n",
            "  inflating: gun200/rifleaud/7/1.mp3  \n",
            "  inflating: gun200/rifleaud/7/2.mp3  \n",
            "   creating: gun200/rifleaud/8/\n",
            "  inflating: gun200/rifleaud/8/0.mp3  \n",
            "  inflating: gun200/rifleaud/8/1.mp3  \n",
            "  inflating: gun200/rifleaud/8/2.mp3  \n",
            "  inflating: gun200/rifleaud/8/3.mp3  \n",
            "  inflating: gun200/rifleaud/8/4.mp3  \n",
            "  inflating: gun200/rifleaud/8/5.mp3  \n",
            "  inflating: gun200/rifleaud/8/6.mp3  \n",
            "  inflating: gun200/rifleaud/8/7.mp3  \n",
            "   creating: gun200/rifleaud/9/\n",
            "  inflating: gun200/rifleaud/9/0.mp3  \n",
            "  inflating: gun200/rifleaud/9/1.mp3  \n",
            "  inflating: gun200/rifleaud/9/2.mp3  \n",
            "  inflating: gun200/rifleaud/9/3.mp3  \n",
            "  inflating: gun200/rifleaud/9/4.mp3  \n",
            "   creating: gun200/rifleaud/10/\n",
            "  inflating: gun200/rifleaud/10/0.mp3  \n",
            "  inflating: gun200/rifleaud/10/1.mp3  \n",
            "  inflating: gun200/rifleaud/10/2.mp3  \n",
            "  inflating: gun200/rifleaud/10/3.mp3  \n",
            "  inflating: gun200/rifleaud/10/4.mp3  \n",
            "   creating: gun200/rifleaud/11/\n",
            "  inflating: gun200/rifleaud/11/0.mp3  \n",
            "  inflating: gun200/rifleaud/11/1.mp3  \n",
            "  inflating: gun200/rifleaud/11/2.mp3  \n",
            "  inflating: gun200/rifleaud/11/3.mp3  \n",
            "  inflating: gun200/rifleaud/11/4.mp3  \n",
            "  inflating: gun200/rifleaud/11/5.mp3  \n",
            "   creating: gun200/rifleaud/12/\n",
            "  inflating: gun200/rifleaud/12/0.mp3  \n",
            "  inflating: gun200/rifleaud/12/1.mp3  \n",
            "  inflating: gun200/rifleaud/12/2.mp3  \n",
            "  inflating: gun200/rifleaud/12/3.mp3  \n",
            "  inflating: gun200/rifleaud/12/4.mp3  \n",
            "  inflating: gun200/rifleaud/12/5.mp3  \n",
            "  inflating: gun200/rifleaud/12/6.mp3  \n",
            "  inflating: gun200/rifleaud/12/7.mp3  \n",
            "  inflating: gun200/rifleaud/12/8.mp3  \n",
            "  inflating: gun200/rifleaud/12/9.mp3  \n",
            "   creating: gun200/rifleaud/13/\n",
            "  inflating: gun200/rifleaud/13/0.mp3  \n",
            "  inflating: gun200/rifleaud/13/1.mp3  \n",
            "   creating: gun200/rifleaud/14/\n",
            "  inflating: gun200/rifleaud/14/0.mp3  \n",
            "  inflating: gun200/rifleaud/14/1.mp3  \n",
            "  inflating: gun200/rifleaud/14/2.mp3  \n",
            "  inflating: gun200/rifleaud/14/3.mp3  \n",
            "  inflating: gun200/rifleaud/14/4.mp3  \n",
            "  inflating: gun200/rifleaud/14/5.mp3  \n",
            "  inflating: gun200/rifleaud/14/6.mp3  \n",
            "  inflating: gun200/rifleaud/14/7.mp3  \n",
            "  inflating: gun200/rifleaud/14/8.mp3  \n",
            "  inflating: gun200/rifleaud/14/9.mp3  \n",
            "  inflating: gun200/rifleaud/14/10.mp3  \n",
            "  inflating: gun200/rifleaud/14/11.mp3  \n",
            "   creating: gun200/rifleaud/15/\n",
            "  inflating: gun200/rifleaud/15/0.mp3  \n",
            "  inflating: gun200/rifleaud/15/1.mp3  \n",
            "  inflating: gun200/rifleaud/15/2.mp3  \n",
            "  inflating: gun200/rifleaud/15/3.mp3  \n",
            "  inflating: gun200/rifleaud/15/4.mp3  \n",
            "  inflating: gun200/rifleaud/15/5.mp3  \n",
            "  inflating: gun200/rifleaud/15/6.mp3  \n",
            "  inflating: gun200/rifleaud/15/7.mp3  \n",
            "  inflating: gun200/rifleaud/15/8.mp3  \n",
            "   creating: gun200/rifleaud/17/\n",
            "  inflating: gun200/rifleaud/17/0.mp3  \n",
            "  inflating: gun200/rifleaud/17/1.mp3  \n",
            "  inflating: gun200/rifleaud/17/2.mp3  \n",
            "  inflating: gun200/rifleaud/17/3.mp3  \n",
            "  inflating: gun200/rifleaud/17/4.mp3  \n",
            "  inflating: gun200/rifleaud/17/5.mp3  \n",
            "  inflating: gun200/rifleaud/17/6.mp3  \n",
            "  inflating: gun200/rifleaud/17/7.mp3  \n",
            "   creating: gun200/rifleaud/18/\n",
            "  inflating: gun200/rifleaud/18/0.mp3  \n",
            "  inflating: gun200/rifleaud/18/1.mp3  \n",
            "  inflating: gun200/rifleaud/18/2.mp3  \n",
            "  inflating: gun200/rifleaud/18/3.mp3  \n",
            "  inflating: gun200/rifleaud/18/4.mp3  \n",
            "  inflating: gun200/rifleaud/18/5.mp3  \n",
            "  inflating: gun200/rifleaud/18/6.mp3  \n",
            "  inflating: gun200/rifleaud/18/7.mp3  \n",
            "  inflating: gun200/rifleaud/18/8.mp3  \n",
            "  inflating: gun200/rifleaud/18/9.mp3  \n",
            "  inflating: gun200/rifleaud/18/10.mp3  \n",
            "  inflating: gun200/rifleaud/18/11.mp3  \n",
            "  inflating: gun200/rifleaud/18/12.mp3  \n",
            "   creating: gun200/rifleaud/19/\n",
            "  inflating: gun200/rifleaud/19/0.mp3  \n",
            "  inflating: gun200/rifleaud/19/1.mp3  \n",
            "  inflating: gun200/rifleaud/19/2.mp3  \n",
            "   creating: gun200/rifleaud/20/\n",
            "  inflating: gun200/rifleaud/20/0.mp3  \n",
            "  inflating: gun200/rifleaud/20/1.mp3  \n",
            "  inflating: gun200/rifleaud/20/2.mp3  \n",
            "  inflating: gun200/rifleaud/20/3.mp3  \n",
            "  inflating: gun200/rifleaud/20/4.mp3  \n",
            "  inflating: gun200/rifleaud/20/5.mp3  \n",
            "  inflating: gun200/rifleaud/20/6.mp3  \n",
            "  inflating: gun200/rifleaud/20/7.mp3  \n",
            "  inflating: gun200/rifleaud/20/8.mp3  \n",
            "  inflating: gun200/rifleaud/20/9.mp3  \n",
            "  inflating: gun200/rifleaud/20/10.mp3  \n",
            "  inflating: gun200/rifleaud/20/12.mp3  \n",
            "  inflating: gun200/rifleaud/20/14.mp3  \n",
            "  inflating: gun200/rifleaud/20/15.mp3  \n",
            "  inflating: gun200/rifleaud/20/16.mp3  \n",
            "  inflating: gun200/rifleaud/20/18.mp3  \n",
            "  inflating: gun200/rifleaud/20/20.mp3  \n",
            "  inflating: gun200/rifleaud/20/21.mp3  \n",
            "  inflating: gun200/rifleaud/20/22.mp3  \n",
            "  inflating: gun200/rifleaud/20/23.mp3  \n",
            "  inflating: gun200/rifleaud/20/24.mp3  \n",
            "  inflating: gun200/rifleaud/20/25.mp3  \n",
            "  inflating: gun200/rifleaud/20/26.mp3  \n",
            "  inflating: gun200/rifleaud/20/27.mp3  \n",
            "   creating: gun200/rifleaud/21/\n",
            "  inflating: gun200/rifleaud/21/0.mp3  \n",
            "  inflating: gun200/rifleaud/21/1.mp3  \n",
            "  inflating: gun200/rifleaud/21/2.mp3  \n",
            "   creating: gun200/rifleaud/22/\n",
            "  inflating: gun200/rifleaud/22/1.mp3  \n",
            "  inflating: gun200/rifleaud/22/2.mp3  \n",
            "   creating: gun200/rifleaud/23/\n",
            "  inflating: gun200/rifleaud/23/0.mp3  \n",
            "  inflating: gun200/rifleaud/23/1.mp3  \n",
            "  inflating: gun200/rifleaud/23/2.mp3  \n",
            "   creating: gun200/rifleaud/24/\n",
            "   creating: gun200/rifleaud/25/\n",
            "  inflating: gun200/rifleaud/25/0.mp3  \n",
            "  inflating: gun200/rifleaud/25/1.mp3  \n",
            "  inflating: gun200/rifleaud/25/2.mp3  \n",
            "  inflating: gun200/rifleaud/25/3.mp3  \n",
            "  inflating: gun200/rifleaud/25/4.mp3  \n",
            "  inflating: gun200/rifleaud/25/5.mp3  \n",
            "  inflating: gun200/rifleaud/25/6.mp3  \n",
            "  inflating: gun200/rifleaud/25/7.mp3  \n",
            "  inflating: gun200/rifleaud/25/8.mp3  \n",
            "  inflating: gun200/rifleaud/25/9.mp3  \n",
            "  inflating: gun200/rifleaud/25/10.mp3  \n",
            "  inflating: gun200/rifleaud/25/11.mp3  \n",
            "  inflating: gun200/rifleaud/25/12.mp3  \n",
            "  inflating: gun200/rifleaud/25/13.mp3  \n",
            "  inflating: gun200/rifleaud/25/14.mp3  \n",
            "  inflating: gun200/rifleaud/25/15.mp3  \n",
            "  inflating: gun200/rifleaud/25/16.mp3  \n",
            "  inflating: gun200/rifleaud/25/17.mp3  \n",
            "  inflating: gun200/rifleaud/25/18.mp3  \n",
            "  inflating: gun200/rifleaud/25/19.mp3  \n",
            "  inflating: gun200/rifleaud/25/20.mp3  \n",
            "   creating: gun200/rifleaud/26/\n",
            "  inflating: gun200/rifleaud/26/0.mp3  \n",
            "  inflating: gun200/rifleaud/26/1.mp3  \n",
            "   creating: gun200/rifleaud/28/\n",
            "  inflating: gun200/rifleaud/28/0.mp3  \n",
            "  inflating: gun200/rifleaud/28/1.mp3  \n",
            "  inflating: gun200/rifleaud/28/2.mp3  \n",
            "  inflating: gun200/rifleaud/28/3.mp3  \n",
            "  inflating: gun200/rifleaud/28/4.mp3  \n",
            "  inflating: gun200/rifleaud/28/5.mp3  \n",
            "  inflating: gun200/rifleaud/28/6.mp3  \n",
            "  inflating: gun200/rifleaud/28/7.mp3  \n",
            "  inflating: gun200/rifleaud/28/8.mp3  \n",
            "  inflating: gun200/rifleaud/28/9.mp3  \n",
            "  inflating: gun200/rifleaud/28/10.mp3  \n",
            "  inflating: gun200/rifleaud/28/11.mp3  \n",
            "  inflating: gun200/rifleaud/28/12.mp3  \n",
            "  inflating: gun200/rifleaud/28/13.mp3  \n",
            "  inflating: gun200/rifleaud/28/14.mp3  \n",
            "  inflating: gun200/rifleaud/28/15.mp3  \n",
            "  inflating: gun200/rifleaud/28/16.mp3  \n",
            "  inflating: gun200/rifleaud/28/17.mp3  \n",
            "  inflating: gun200/rifleaud/28/18.mp3  \n",
            "  inflating: gun200/rifleaud/28/19.mp3  \n",
            "  inflating: gun200/rifleaud/28/20.mp3  \n",
            "  inflating: gun200/rifleaud/28/21.mp3  \n",
            "  inflating: gun200/rifleaud/28/22.mp3  \n",
            "  inflating: gun200/rifleaud/28/23.mp3  \n",
            "  inflating: gun200/rifleaud/28/24.mp3  \n",
            "  inflating: gun200/rifleaud/28/25.mp3  \n",
            "  inflating: gun200/rifleaud/28/26.mp3  \n",
            "  inflating: gun200/rifleaud/28/27.mp3  \n",
            "  inflating: gun200/rifleaud/28/28.mp3  \n",
            "  inflating: gun200/rifleaud/28/29.mp3  \n",
            "  inflating: gun200/rifleaud/28/30.mp3  \n",
            "  inflating: gun200/rifleaud/28/31.mp3  \n",
            "  inflating: gun200/rifleaud/28/32.mp3  \n",
            "  inflating: gun200/rifleaud/28/33.mp3  \n",
            "  inflating: gun200/rifleaud/28/34.mp3  \n",
            "  inflating: gun200/rifleaud/28/35.mp3  \n",
            "  inflating: gun200/rifleaud/28/36.mp3  \n",
            "  inflating: gun200/rifleaud/28/37.mp3  \n",
            "  inflating: gun200/rifleaud/28/38.mp3  \n",
            "  inflating: gun200/rifleaud/28/39.mp3  \n",
            "  inflating: gun200/rifleaud/28/40.mp3  \n",
            "  inflating: gun200/rifleaud/28/41.mp3  \n",
            "   creating: gun200/rifleaud/29/\n",
            "  inflating: gun200/rifleaud/29/0.mp3  \n",
            "  inflating: gun200/rifleaud/29/1.mp3  \n",
            "   creating: gun200/rifleaud/30/\n",
            "  inflating: gun200/rifleaud/30/0.mp3  \n",
            "  inflating: gun200/rifleaud/30/1.mp3  \n",
            "  inflating: gun200/rifleaud/30/2.mp3  \n",
            "  inflating: gun200/rifleaud/30/3.mp3  \n",
            "  inflating: gun200/rifleaud/30/4.mp3  \n",
            "  inflating: gun200/rifleaud/30/5.mp3  \n",
            "  inflating: gun200/rifleaud/30/7.mp3  \n",
            "  inflating: gun200/rifleaud/30/8.mp3  \n",
            "  inflating: gun200/rifleaud/30/9.mp3  \n",
            "  inflating: gun200/rifleaud/30/10.mp3  \n",
            "  inflating: gun200/rifleaud/30/11.mp3  \n",
            "  inflating: gun200/rifleaud/30/12.mp3  \n",
            "  inflating: gun200/rifleaud/30/13.mp3  \n",
            "  inflating: gun200/rifleaud/30/14.mp3  \n",
            "  inflating: gun200/rifleaud/30/15.mp3  \n",
            "  inflating: gun200/rifleaud/30/16.mp3  \n",
            "  inflating: gun200/rifleaud/30/17.mp3  \n",
            "  inflating: gun200/rifleaud/30/18.mp3  \n",
            "  inflating: gun200/rifleaud/30/19.mp3  \n",
            "  inflating: gun200/rifleaud/30/20.mp3  \n",
            "  inflating: gun200/rifleaud/30/21.mp3  \n",
            "   creating: gun200/rifleaud/31/\n",
            "  inflating: gun200/rifleaud/31/0.mp3  \n",
            "  inflating: gun200/rifleaud/31/1.mp3  \n",
            "  inflating: gun200/rifleaud/31/2.mp3  \n",
            "   creating: gun200/rifleaud/32/\n",
            "  inflating: gun200/rifleaud/32/0.mp3  \n",
            "  inflating: gun200/rifleaud/32/1.mp3  \n",
            "  inflating: gun200/rifleaud/32/2.mp3  \n",
            "  inflating: gun200/rifleaud/32/3.mp3  \n",
            "  inflating: gun200/rifleaud/32/4.mp3  \n",
            "  inflating: gun200/rifleaud/32/5.mp3  \n",
            "  inflating: gun200/rifleaud/32/6.mp3  \n",
            "  inflating: gun200/rifleaud/32/7.mp3  \n",
            "  inflating: gun200/rifleaud/32/8.mp3  \n",
            "   creating: gun200/rifleaud/33/\n",
            "  inflating: gun200/rifleaud/33/0.mp3  \n",
            "  inflating: gun200/rifleaud/33/1.mp3  \n",
            "  inflating: gun200/rifleaud/33/2.mp3  \n",
            "  inflating: gun200/rifleaud/33/3.mp3  \n",
            "  inflating: gun200/rifleaud/33/4.mp3  \n",
            "  inflating: gun200/rifleaud/33/5.mp3  \n",
            "  inflating: gun200/rifleaud/33/6.mp3  \n",
            "  inflating: gun200/rifleaud/33/7.mp3  \n",
            "  inflating: gun200/rifleaud/33/8.mp3  \n",
            "  inflating: gun200/rifleaud/33/9.mp3  \n",
            "  inflating: gun200/rifleaud/33/10.mp3  \n",
            "  inflating: gun200/rifleaud/33/11.mp3  \n",
            "  inflating: gun200/rifleaud/33/12.mp3  \n",
            "  inflating: gun200/rifleaud/33/13.mp3  \n",
            "  inflating: gun200/rifleaud/33/14.mp3  \n",
            "  inflating: gun200/rifleaud/33/15.mp3  \n",
            "  inflating: gun200/rifleaud/33/16.mp3  \n",
            "  inflating: gun200/rifleaud/33/17.mp3  \n",
            "  inflating: gun200/rifleaud/33/18.mp3  \n",
            "  inflating: gun200/rifleaud/33/19.mp3  \n",
            "  inflating: gun200/rifleaud/33/20.mp3  \n",
            "  inflating: gun200/rifleaud/33/21.mp3  \n",
            "  inflating: gun200/rifleaud/33/22.mp3  \n",
            "   creating: gun200/rifleaud/34/\n",
            "  inflating: gun200/rifleaud/34/0.mp3  \n",
            "  inflating: gun200/rifleaud/34/1.mp3  \n",
            "  inflating: gun200/rifleaud/34/2.mp3  \n",
            "  inflating: gun200/rifleaud/34/3.mp3  \n",
            "  inflating: gun200/rifleaud/34/4.mp3  \n",
            "  inflating: gun200/rifleaud/34/6.mp3  \n",
            "  inflating: gun200/rifleaud/34/7.mp3  \n",
            "   creating: gun200/rifleaud/35/\n",
            "  inflating: gun200/rifleaud/35/0.mp3  \n",
            "  inflating: gun200/rifleaud/35/1.mp3  \n",
            "  inflating: gun200/rifleaud/35/2.mp3  \n",
            "  inflating: gun200/rifleaud/35/3.mp3  \n",
            "  inflating: gun200/rifleaud/35/4.mp3  \n",
            "  inflating: gun200/rifleaud/35/5.mp3  \n",
            "  inflating: gun200/rifleaud/35/6.mp3  \n",
            "  inflating: gun200/rifleaud/35/7.mp3  \n",
            "  inflating: gun200/rifleaud/35/8.mp3  \n",
            "  inflating: gun200/rifleaud/35/9.mp3  \n",
            "  inflating: gun200/rifleaud/35/10.mp3  \n",
            "  inflating: gun200/rifleaud/35/11.mp3  \n",
            "  inflating: gun200/rifleaud/35/12.mp3  \n",
            "  inflating: gun200/rifleaud/35/13.mp3  \n",
            "  inflating: gun200/rifleaud/35/14.mp3  \n",
            "  inflating: gun200/rifleaud/35/15.mp3  \n",
            "  inflating: gun200/rifleaud/35/16.mp3  \n",
            "  inflating: gun200/rifleaud/35/17.mp3  \n",
            "  inflating: gun200/rifleaud/35/18.mp3  \n",
            "  inflating: gun200/rifleaud/35/19.mp3  \n",
            "  inflating: gun200/rifleaud/35/20.mp3  \n",
            "   creating: gun200/rifleaud/36/\n",
            "  inflating: gun200/rifleaud/36/0.mp3  \n",
            "  inflating: gun200/rifleaud/36/1.mp3  \n",
            "   creating: gun200/rifleaud/38/\n",
            "  inflating: gun200/rifleaud/38/0.mp3  \n",
            "  inflating: gun200/rifleaud/38/1.mp3  \n",
            "  inflating: gun200/rifleaud/38/2.mp3  \n",
            "  inflating: gun200/rifleaud/38/3.mp3  \n",
            "  inflating: gun200/rifleaud/38/4.mp3  \n",
            "  inflating: gun200/rifleaud/38/5.mp3  \n",
            "  inflating: gun200/rifleaud/38/6.mp3  \n",
            "  inflating: gun200/rifleaud/38/7.mp3  \n",
            "  inflating: gun200/rifleaud/38/8.mp3  \n",
            "   creating: gun200/rifleaud/39/\n",
            "  inflating: gun200/rifleaud/39/0.mp3  \n",
            "  inflating: gun200/rifleaud/39/1.mp3  \n",
            "  inflating: gun200/rifleaud/39/2.mp3  \n",
            "  inflating: gun200/rifleaud/39/3.mp3  \n",
            "  inflating: gun200/rifleaud/39/4.mp3  \n",
            "  inflating: gun200/rifleaud/39/5.mp3  \n",
            "  inflating: gun200/rifleaud/39/6.mp3  \n",
            "  inflating: gun200/rifleaud/39/7.mp3  \n",
            "  inflating: gun200/rifleaud/39/8.mp3  \n",
            "  inflating: gun200/rifleaud/39/9.mp3  \n",
            "  inflating: gun200/rifleaud/39/10.mp3  \n",
            "  inflating: gun200/rifleaud/39/11.mp3  \n",
            "  inflating: gun200/rifleaud/39/12.mp3  \n",
            "  inflating: gun200/rifleaud/39/13.mp3  \n",
            "  inflating: gun200/rifleaud/39/14.mp3  \n",
            "  inflating: gun200/rifleaud/39/15.mp3  \n",
            "   creating: gun200/rifleaud/40/\n",
            "  inflating: gun200/rifleaud/40/0.mp3  \n",
            "  inflating: gun200/rifleaud/40/1.mp3  \n",
            "  inflating: gun200/rifleaud/40/2.mp3  \n",
            "  inflating: gun200/rifleaud/40/3.mp3  \n",
            "  inflating: gun200/rifleaud/40/4.mp3  \n",
            "  inflating: gun200/rifleaud/40/5.mp3  \n",
            "  inflating: gun200/rifleaud/40/6.mp3  \n",
            "  inflating: gun200/rifleaud/40/7.mp3  \n",
            "  inflating: gun200/rifleaud/40/8.mp3  \n",
            "  inflating: gun200/rifleaud/40/9.mp3  \n",
            "  inflating: gun200/rifleaud/40/10.mp3  \n",
            "  inflating: gun200/rifleaud/40/11.mp3  \n",
            "  inflating: gun200/rifleaud/40/12.mp3  \n",
            "  inflating: gun200/rifleaud/40/13.mp3  \n",
            "  inflating: gun200/rifleaud/40/14.mp3  \n",
            "  inflating: gun200/rifleaud/40/15.mp3  \n",
            "  inflating: gun200/rifleaud/40/16.mp3  \n",
            "  inflating: gun200/rifleaud/40/17.mp3  \n",
            "  inflating: gun200/rifleaud/40/18.mp3  \n",
            "  inflating: gun200/rifleaud/40/19.mp3  \n",
            "  inflating: gun200/rifleaud/40/20.mp3  \n",
            "  inflating: gun200/rifleaud/40/21.mp3  \n",
            "  inflating: gun200/rifleaud/40/22.mp3  \n",
            "  inflating: gun200/rifleaud/40/23.mp3  \n",
            "  inflating: gun200/rifleaud/40/24.mp3  \n",
            "  inflating: gun200/rifleaud/40/25.mp3  \n",
            "   creating: gun200/rifleaud/41/\n",
            "  inflating: gun200/rifleaud/41/0.mp3  \n",
            "   creating: gun200/rifleaud/42/\n",
            "  inflating: gun200/rifleaud/42/0.mp3  \n",
            "  inflating: gun200/rifleaud/42/1.mp3  \n",
            "  inflating: gun200/rifleaud/42/2.mp3  \n",
            "  inflating: gun200/rifleaud/42/3.mp3  \n",
            "  inflating: gun200/rifleaud/42/4.mp3  \n",
            "  inflating: gun200/rifleaud/42/5.mp3  \n",
            "  inflating: gun200/rifleaud/42/6.mp3  \n",
            "  inflating: gun200/rifleaud/42/7.mp3  \n",
            "  inflating: gun200/rifleaud/42/8.mp3  \n",
            "  inflating: gun200/rifleaud/42/10.mp3  \n",
            "  inflating: gun200/rifleaud/42/11.mp3  \n",
            "  inflating: gun200/rifleaud/42/12.mp3  \n",
            "  inflating: gun200/rifleaud/42/13.mp3  \n",
            "  inflating: gun200/rifleaud/42/14.mp3  \n",
            "  inflating: gun200/rifleaud/42/15.mp3  \n",
            "  inflating: gun200/rifleaud/42/16.mp3  \n",
            "  inflating: gun200/rifleaud/42/17.mp3  \n",
            "  inflating: gun200/rifleaud/42/18.mp3  \n",
            "  inflating: gun200/rifleaud/42/19.mp3  \n",
            "   creating: gun200/rifleaud/43/\n",
            "  inflating: gun200/rifleaud/43/0.mp3  \n",
            "  inflating: gun200/rifleaud/43/1.mp3  \n",
            "  inflating: gun200/rifleaud/43/2.mp3  \n",
            "  inflating: gun200/rifleaud/43/3.mp3  \n",
            "  inflating: gun200/rifleaud/43/4.mp3  \n",
            "  inflating: gun200/rifleaud/43/5.mp3  \n",
            "  inflating: gun200/rifleaud/43/6.mp3  \n",
            "  inflating: gun200/rifleaud/43/7.mp3  \n",
            "   creating: gun200/rifleaud/44/\n",
            "  inflating: gun200/rifleaud/44/0.mp3  \n",
            "  inflating: gun200/rifleaud/44/1.mp3  \n",
            "  inflating: gun200/rifleaud/44/2.mp3  \n",
            "  inflating: gun200/rifleaud/44/3.mp3  \n",
            "  inflating: gun200/rifleaud/44/4.mp3  \n",
            "  inflating: gun200/rifleaud/44/5.mp3  \n",
            "  inflating: gun200/rifleaud/44/6.mp3  \n",
            "  inflating: gun200/rifleaud/44/7.mp3  \n",
            "   creating: gun200/rifleaud/46/\n",
            "  inflating: gun200/rifleaud/46/0.mp3  \n",
            "   creating: gun200/rifleaud/48/\n",
            "  inflating: gun200/rifleaud/48/0.mp3  \n",
            "  inflating: gun200/rifleaud/48/1.mp3  \n",
            "  inflating: gun200/rifleaud/48/2.mp3  \n",
            "  inflating: gun200/rifleaud/48/3.mp3  \n",
            "  inflating: gun200/rifleaud/48/4.mp3  \n",
            "  inflating: gun200/rifleaud/48/5.mp3  \n",
            "  inflating: gun200/rifleaud/48/6.mp3  \n",
            "  inflating: gun200/rifleaud/48/7.mp3  \n",
            "  inflating: gun200/rifleaud/48/8.mp3  \n",
            "  inflating: gun200/rifleaud/48/9.mp3  \n",
            "  inflating: gun200/rifleaud/48/10.mp3  \n",
            "  inflating: gun200/rifleaud/48/11.mp3  \n",
            "  inflating: gun200/rifleaud/48/12.mp3  \n",
            "  inflating: gun200/rifleaud/48/13.mp3  \n",
            "  inflating: gun200/rifleaud/48/14.mp3  \n",
            "   creating: gun200/rifleaud/51./\n",
            "  inflating: gun200/rifleaud/51./51.0.mp3  \n",
            "  inflating: gun200/rifleaud/51./51.1.mp3  \n",
            "  inflating: gun200/rifleaud/51./51.2.mp3  \n",
            "  inflating: gun200/rifleaud/51./51.3.mp3  \n",
            "  inflating: gun200/rifleaud/51./51.4.mp3  \n",
            "  inflating: gun200/rifleaud/51./51.5.mp3  \n",
            "  inflating: gun200/rifleaud/51./51.7.mp3  \n",
            "  inflating: gun200/rifleaud/51./51.8.mp3  \n",
            "  inflating: gun200/rifleaud/51./51.9.mp3  \n",
            "  inflating: gun200/rifleaud/51./51.10.mp3  \n",
            "  inflating: gun200/rifleaud/51./51.11.mp3  \n",
            "  inflating: gun200/rifleaud/51./51.12.mp3  \n",
            "  inflating: gun200/rifleaud/51./51.13.mp3  \n",
            "  inflating: gun200/rifleaud/51./51.14.mp3  \n",
            "   creating: gun200/rifleaud/52./\n",
            "  inflating: gun200/rifleaud/52./52.5.mp3  \n",
            "  inflating: gun200/rifleaud/52./52.8.mp3  \n",
            "  inflating: gun200/rifleaud/52./52.14.mp3  \n",
            "   creating: gun200/rifleaud/53./\n",
            "  inflating: gun200/rifleaud/53./53.0.mp3  \n",
            "  inflating: gun200/rifleaud/53./53.1.mp3  \n",
            "  inflating: gun200/rifleaud/53./53.2.mp3  \n",
            "   creating: gun200/rifleaud/54./\n",
            "  inflating: gun200/rifleaud/54./54.0.mp3  \n",
            "  inflating: gun200/rifleaud/54./54.1.mp3  \n",
            "  inflating: gun200/rifleaud/54./54.2.mp3  \n",
            "  inflating: gun200/rifleaud/54./54.3.mp3  \n",
            "  inflating: gun200/rifleaud/54./54.4.mp3  \n",
            "  inflating: gun200/rifleaud/54./54.5.mp3  \n",
            "  inflating: gun200/rifleaud/54./54.6.mp3  \n",
            "  inflating: gun200/rifleaud/54./54.7.mp3  \n",
            "  inflating: gun200/rifleaud/54./54.8.mp3  \n",
            "   creating: gun200/rifleaud/55./\n",
            "  inflating: gun200/rifleaud/55./55.0.mp3  \n",
            "  inflating: gun200/rifleaud/55./55.1.mp3  \n",
            "  inflating: gun200/rifleaud/55./55.2.mp3  \n",
            "  inflating: gun200/rifleaud/55./55.3.mp3  \n",
            "  inflating: gun200/rifleaud/55./55.4.mp3  \n",
            "  inflating: gun200/rifleaud/55./55.5.mp3  \n",
            "  inflating: gun200/rifleaud/55./55.6.mp3  \n",
            "  inflating: gun200/rifleaud/55./55.7.mp3  \n",
            "   creating: gun200/rifleaud/56./\n",
            "  inflating: gun200/rifleaud/56./56.0.mp3  \n",
            "  inflating: gun200/rifleaud/56./56.1.mp3  \n",
            "  inflating: gun200/rifleaud/56./56.2.mp3  \n",
            "  inflating: gun200/rifleaud/56./56.3.mp3  \n",
            "  inflating: gun200/rifleaud/56./56.4.mp3  \n",
            "   creating: gun200/rifleaud/57./\n",
            "  inflating: gun200/rifleaud/57./57.0.mp3  \n",
            "  inflating: gun200/rifleaud/57./57.1.mp3  \n",
            "  inflating: gun200/rifleaud/57./57.2.mp3  \n",
            "  inflating: gun200/rifleaud/57./57.3.mp3  \n",
            "  inflating: gun200/rifleaud/57./57.4.mp3  \n",
            "  inflating: gun200/rifleaud/57./57.5.mp3  \n",
            "  inflating: gun200/rifleaud/57./57.6.mp3  \n",
            "  inflating: gun200/rifleaud/57./57.7.mp3  \n",
            "   creating: gun200/rifleaud/58./\n",
            "  inflating: gun200/rifleaud/58./58.0.mp3  \n",
            "  inflating: gun200/rifleaud/58./58.1.mp3  \n",
            "  inflating: gun200/rifleaud/58./58.2.mp3  \n",
            "  inflating: gun200/rifleaud/58./58.3.mp3  \n",
            "  inflating: gun200/rifleaud/58./58.4.mp3  \n",
            "  inflating: gun200/rifleaud/58./58.5.mp3  \n",
            "  inflating: gun200/rifleaud/58./58.6.mp3  \n",
            "  inflating: gun200/rifleaud/58./58.7.mp3  \n",
            "  inflating: gun200/rifleaud/58./58.8.mp3  \n",
            "  inflating: gun200/rifleaud/58./58.9.mp3  \n",
            "   creating: gun200/rifleaud/59./\n",
            "  inflating: gun200/rifleaud/59./59.0.mp3  \n",
            "  inflating: gun200/rifleaud/59./59.1.mp3  \n",
            "  inflating: gun200/rifleaud/59./59.2.mp3  \n",
            "  inflating: gun200/rifleaud/59./59.3.mp3  \n",
            "  inflating: gun200/rifleaud/59./59.4.mp3  \n",
            "   creating: gun200/rifleaud/60./\n",
            "  inflating: gun200/rifleaud/60./60.0.mp3  \n",
            "  inflating: gun200/rifleaud/60./60.1.mp3  \n",
            "  inflating: gun200/rifleaud/60./60.2.mp3  \n",
            "  inflating: gun200/rifleaud/60./60.3.mp3  \n",
            "  inflating: gun200/rifleaud/60./60.4.mp3  \n",
            "  inflating: gun200/rifleaud/60./60.5.mp3  \n",
            "  inflating: gun200/rifleaud/60./60.6.mp3  \n",
            "  inflating: gun200/rifleaud/60./60.7.mp3  \n",
            "  inflating: gun200/rifleaud/60./60.8.mp3  \n",
            "  inflating: gun200/rifleaud/60./60.9.mp3  \n",
            "  inflating: gun200/rifleaud/60./60.10.mp3  \n",
            "  inflating: gun200/rifleaud/60./60.11.mp3  \n",
            "   creating: gun200/rifleaud/61./\n",
            "  inflating: gun200/rifleaud/61./61.0.mp3  \n",
            "   creating: gun200/rifleaud/62./\n",
            "  inflating: gun200/rifleaud/62./62.0.mp3  \n",
            "  inflating: gun200/rifleaud/62./62.1.mp3  \n",
            "  inflating: gun200/rifleaud/62./62.2.mp3  \n",
            "  inflating: gun200/rifleaud/62./62.3.mp3  \n",
            "  inflating: gun200/rifleaud/62./62.4.mp3  \n",
            "  inflating: gun200/rifleaud/62./62.5.mp3  \n",
            "  inflating: gun200/rifleaud/62./62.6.mp3  \n",
            "  inflating: gun200/rifleaud/62./62.7.mp3  \n",
            "  inflating: gun200/rifleaud/62./62.8.mp3  \n",
            "  inflating: gun200/rifleaud/62./62.9.mp3  \n",
            "  inflating: gun200/rifleaud/62./62.10.mp3  \n",
            "  inflating: gun200/rifleaud/62./62.11.mp3  \n",
            "   creating: gun200/rifleaud/63./\n",
            "  inflating: gun200/rifleaud/63./63.0.mp3  \n",
            "  inflating: gun200/rifleaud/63./63.1.mp3  \n",
            "  inflating: gun200/rifleaud/63./63.2.mp3  \n",
            "   creating: gun200/rifleaud/64./\n",
            "  inflating: gun200/rifleaud/64./64.0.mp3  \n",
            "  inflating: gun200/rifleaud/64./64.1.mp3  \n",
            "  inflating: gun200/rifleaud/64./64.2.mp3  \n",
            "  inflating: gun200/rifleaud/64./64.3.mp3  \n",
            "  inflating: gun200/rifleaud/64./64.4.mp3  \n",
            "  inflating: gun200/rifleaud/64./64.5.mp3  \n",
            "  inflating: gun200/rifleaud/64./64.6.mp3  \n",
            "  inflating: gun200/rifleaud/64./64.7.mp3  \n",
            "  inflating: gun200/rifleaud/64./64.8.mp3  \n",
            "  inflating: gun200/rifleaud/64./64.9.mp3  \n",
            "  inflating: gun200/rifleaud/64./64.10.mp3  \n",
            "   creating: gun200/rifleaud/65./\n",
            "  inflating: gun200/rifleaud/65./65.0.mp3  \n",
            "  inflating: gun200/rifleaud/65./65.1.mp3  \n",
            "  inflating: gun200/rifleaud/65./65.2.mp3  \n",
            "  inflating: gun200/rifleaud/65./65.3.mp3  \n",
            "  inflating: gun200/rifleaud/65./65.4.mp3  \n",
            "  inflating: gun200/rifleaud/65./65.5.mp3  \n",
            "   creating: gun200/rifleaud/66./\n",
            "  inflating: gun200/rifleaud/66./66.0.mp3  \n",
            "  inflating: gun200/rifleaud/66./66.1.mp3  \n",
            "  inflating: gun200/rifleaud/66./66.2.mp3  \n",
            "  inflating: gun200/rifleaud/66./66.3.mp3  \n",
            "  inflating: gun200/rifleaud/66./66.4.mp3  \n",
            "  inflating: gun200/rifleaud/66./66.5.mp3  \n",
            "  inflating: gun200/rifleaud/66./66.6.mp3  \n",
            "   creating: gun200/rifleaud/68./\n",
            "  inflating: gun200/rifleaud/68./68.0.mp3  \n",
            "  inflating: gun200/rifleaud/68./68.1.mp3  \n",
            "  inflating: gun200/rifleaud/68./68.2.mp3  \n",
            "  inflating: gun200/rifleaud/68./68.3.mp3  \n",
            "  inflating: gun200/rifleaud/68./68.4.mp3  \n",
            "  inflating: gun200/rifleaud/68./68.5.mp3  \n",
            "  inflating: gun200/rifleaud/68./68.6.mp3  \n",
            "  inflating: gun200/rifleaud/68./68.7.mp3  \n",
            "  inflating: gun200/rifleaud/68./68.8.mp3  \n",
            "  inflating: gun200/rifleaud/68./68.9.mp3  \n",
            "  inflating: gun200/rifleaud/68./68.10.mp3  \n",
            "  inflating: gun200/rifleaud/68./68.11.mp3  \n",
            "  inflating: gun200/rifleaud/68./68.12.mp3  \n",
            "  inflating: gun200/rifleaud/68./68.13.mp3  \n",
            "  inflating: gun200/rifleaud/68./68.14.mp3  \n",
            "  inflating: gun200/rifleaud/68./68.15.mp3  \n",
            "  inflating: gun200/rifleaud/68./68.16.mp3  \n",
            "   creating: gun200/rifleaud/69./\n",
            "  inflating: gun200/rifleaud/69./69.0.mp3  \n",
            "  inflating: gun200/rifleaud/69./69.1.mp3  \n",
            "  inflating: gun200/rifleaud/69./69.2.mp3  \n",
            "   creating: gun200/rifleaud/70./\n",
            "  inflating: gun200/rifleaud/70./70.0.mp3  \n",
            "  inflating: gun200/rifleaud/70./70.1.mp3  \n",
            "  inflating: gun200/rifleaud/70./70.2.mp3  \n",
            "  inflating: gun200/rifleaud/70./70.3.mp3  \n",
            "  inflating: gun200/rifleaud/70./70.4.mp3  \n",
            "  inflating: gun200/rifleaud/70./70.5.mp3  \n",
            "  inflating: gun200/rifleaud/70./70.6.mp3  \n",
            "  inflating: gun200/rifleaud/70./70.7.mp3  \n",
            "  inflating: gun200/rifleaud/70./70.8.mp3  \n",
            "   creating: gun200/rifleaud/71./\n",
            "  inflating: gun200/rifleaud/71./71.0.mp3  \n",
            "  inflating: gun200/rifleaud/71./71.1.mp3  \n",
            "   creating: gun200/rifleaud/73./\n",
            "  inflating: gun200/rifleaud/73./73.1.mp3  \n",
            "   creating: gun200/rifleaud/74./\n",
            "  inflating: gun200/rifleaud/74./74.0.mp3  \n",
            "  inflating: gun200/rifleaud/74./74.1.mp3  \n",
            "  inflating: gun200/rifleaud/74./74.2.mp3  \n",
            "   creating: gun200/rifleaud/75./\n",
            "  inflating: gun200/rifleaud/75./75.0.mp3  \n",
            "  inflating: gun200/rifleaud/75./75.1.mp3  \n",
            "  inflating: gun200/rifleaud/75./75.2.mp3  \n",
            "  inflating: gun200/rifleaud/75./75.3.mp3  \n",
            "  inflating: gun200/rifleaud/75./75.4.mp3  \n",
            "  inflating: gun200/rifleaud/75./75.5.mp3  \n",
            "  inflating: gun200/rifleaud/75./75.6.mp3  \n",
            "  inflating: gun200/rifleaud/75./75.7.mp3  \n",
            "  inflating: gun200/rifleaud/75./75.8.mp3  \n",
            "  inflating: gun200/rifleaud/75./75.9.mp3  \n",
            "  inflating: gun200/rifleaud/75./75.10.mp3  \n",
            "   creating: gun200/rifleaud/76./\n",
            "  inflating: gun200/rifleaud/76./76.0.mp3  \n",
            "  inflating: gun200/rifleaud/76./76.1.mp3  \n",
            "  inflating: gun200/rifleaud/76./76.2.mp3  \n",
            "  inflating: gun200/rifleaud/76./76.3.mp3  \n",
            "  inflating: gun200/rifleaud/76./76.4.mp3  \n",
            "   creating: gun200/rifleaud/77./\n",
            "  inflating: gun200/rifleaud/77./77.1.mp3  \n",
            "  inflating: gun200/rifleaud/77./77.2.mp3  \n",
            "  inflating: gun200/rifleaud/77./77.3.mp3  \n",
            "  inflating: gun200/rifleaud/77./77.4.mp3  \n",
            "  inflating: gun200/rifleaud/77./77.5.mp3  \n",
            "   creating: gun200/rifleaud/78./\n",
            "  inflating: gun200/rifleaud/78./78.0.mp3  \n",
            "  inflating: gun200/rifleaud/78./78.1.mp3  \n",
            "  inflating: gun200/rifleaud/78./78.2.mp3  \n",
            "  inflating: gun200/rifleaud/78./78.3.mp3  \n",
            "   creating: gun200/rifleaud/79./\n",
            "  inflating: gun200/rifleaud/79./79.0.mp3  \n",
            "  inflating: gun200/rifleaud/79./79.1.mp3  \n",
            "  inflating: gun200/rifleaud/79./79.2.mp3  \n",
            "  inflating: gun200/rifleaud/79./79.3.mp3  \n",
            "   creating: gun200/rifleaud/80./\n",
            "  inflating: gun200/rifleaud/80./80.0.mp3  \n",
            "  inflating: gun200/rifleaud/80./80.1.mp3  \n",
            "  inflating: gun200/rifleaud/80./80.2.mp3  \n",
            "  inflating: gun200/rifleaud/80./80.3.mp3  \n",
            "  inflating: gun200/rifleaud/80./80.4.mp3  \n",
            "  inflating: gun200/rifleaud/80./80.5.mp3  \n",
            "  inflating: gun200/rifleaud/80./80.6.mp3  \n",
            "  inflating: gun200/rifleaud/80./80.7.mp3  \n",
            "  inflating: gun200/rifleaud/80./80.8.mp3  \n",
            "  inflating: gun200/rifleaud/80./80.9.mp3  \n",
            "  inflating: gun200/rifleaud/80./80.10.mp3  \n",
            "  inflating: gun200/rifleaud/80./80.11.mp3  \n",
            "  inflating: gun200/rifleaud/80./80.12.mp3  \n",
            "  inflating: gun200/rifleaud/80./80.13.mp3  \n",
            "   creating: gun200/rifleaud/81./\n",
            "  inflating: gun200/rifleaud/81./81.0.mp3  \n",
            "  inflating: gun200/rifleaud/81./81.1.mp3  \n",
            "  inflating: gun200/rifleaud/81./81.2.mp3  \n",
            "  inflating: gun200/rifleaud/81./81.3.mp3  \n",
            "  inflating: gun200/rifleaud/81./81.4.mp3  \n",
            "  inflating: gun200/rifleaud/81./81.5.mp3  \n",
            "   creating: gun200/rifleaud/82./\n",
            "  inflating: gun200/rifleaud/82./82.0.mp3  \n",
            "  inflating: gun200/rifleaud/82./82.2.mp3  \n",
            "   creating: gun200/rifleaud/84./\n",
            "  inflating: gun200/rifleaud/84./84.0.mp3  \n",
            "  inflating: gun200/rifleaud/84./84.1.mp3  \n",
            "  inflating: gun200/rifleaud/84./84.2.mp3  \n",
            "  inflating: gun200/rifleaud/84./84.3.mp3  \n",
            "  inflating: gun200/rifleaud/84./84.4.mp3  \n",
            "  inflating: gun200/rifleaud/84./84.5.mp3  \n",
            "  inflating: gun200/rifleaud/84./84.6.mp3  \n",
            "   creating: gun200/rifleaud/85./\n",
            "  inflating: gun200/rifleaud/85./85.0.mp3  \n",
            "  inflating: gun200/rifleaud/85./85.1.mp3  \n",
            "  inflating: gun200/rifleaud/85./85.2.mp3  \n",
            "  inflating: gun200/rifleaud/85./85.3.mp3  \n",
            "  inflating: gun200/rifleaud/85./85.4.mp3  \n",
            "  inflating: gun200/rifleaud/85./85.5.mp3  \n",
            "  inflating: gun200/rifleaud/85./85.6.mp3  \n",
            "  inflating: gun200/rifleaud/85./85.7.mp3  \n",
            "   creating: gun200/rifleaud/87./\n",
            "  inflating: gun200/rifleaud/87./87.0.mp3  \n",
            "  inflating: gun200/rifleaud/87./87.1.mp3  \n",
            "  inflating: gun200/rifleaud/87./87.2.mp3  \n",
            "  inflating: gun200/rifleaud/87./87.3.mp3  \n",
            "   creating: gun200/rifleaud/88./\n",
            "  inflating: gun200/rifleaud/88./88.1.mp3  \n",
            "   creating: gun200/rifleaud/89./\n",
            "  inflating: gun200/rifleaud/89./89.0.mp3  \n",
            "  inflating: gun200/rifleaud/89./89.1.mp3  \n",
            "  inflating: gun200/rifleaud/89./89.2.mp3  \n",
            "  inflating: gun200/rifleaud/89./89.3.mp3  \n",
            "  inflating: gun200/rifleaud/89./89.4.mp3  \n",
            "  inflating: gun200/rifleaud/89./89.5.mp3  \n",
            "  inflating: gun200/rifleaud/89./89.6.mp3  \n",
            "   creating: gun200/rifleaud/90./\n",
            "  inflating: gun200/rifleaud/90./90.0.mp3  \n",
            "  inflating: gun200/rifleaud/90./90.1.mp3  \n",
            "  inflating: gun200/rifleaud/90./90.2.mp3  \n",
            "  inflating: gun200/rifleaud/90./90.3.mp3  \n",
            "  inflating: gun200/rifleaud/90./90.4.mp3  \n",
            "   creating: gun200/rifleaud/91./\n",
            "  inflating: gun200/rifleaud/91./91.0.mp3  \n",
            "  inflating: gun200/rifleaud/91./91.1.mp3  \n",
            "  inflating: gun200/rifleaud/91./91.2.mp3  \n",
            "  inflating: gun200/rifleaud/91./91.3.mp3  \n",
            "   creating: gun200/rifleaud/92./\n",
            "  inflating: gun200/rifleaud/92./92.0.mp3  \n",
            "  inflating: gun200/rifleaud/92./92.1.mp3  \n",
            "  inflating: gun200/rifleaud/92./92.2.mp3  \n",
            "  inflating: gun200/rifleaud/92./92.3.mp3  \n",
            "  inflating: gun200/rifleaud/92./92.4.mp3  \n",
            "   creating: gun200/rifleaud/93./\n",
            "  inflating: gun200/rifleaud/93./93.0.mp3  \n",
            "  inflating: gun200/rifleaud/93./93.1.mp3  \n",
            "  inflating: gun200/rifleaud/93./93.2.mp3  \n",
            "  inflating: gun200/rifleaud/93./93.3.mp3  \n",
            "  inflating: gun200/rifleaud/93./93.4.mp3  \n",
            "  inflating: gun200/rifleaud/93./93.5.mp3  \n",
            "  inflating: gun200/rifleaud/93./93.6.mp3  \n",
            "   creating: gun200/rifleaud/94./\n",
            "  inflating: gun200/rifleaud/94./94.0.mp3  \n",
            "  inflating: gun200/rifleaud/94./94.1.mp3  \n",
            "   creating: gun200/rifleaud/96./\n",
            "  inflating: gun200/rifleaud/96./96.0.mp3  \n",
            "  inflating: gun200/rifleaud/96./96.1.mp3  \n",
            "  inflating: gun200/rifleaud/96./96.2.mp3  \n",
            "  inflating: gun200/rifleaud/96./96.3.mp3  \n",
            "  inflating: gun200/rifleaud/96./96.4.mp3  \n",
            "  inflating: gun200/rifleaud/96./96.5.mp3  \n",
            "  inflating: gun200/rifleaud/96./96.6.mp3  \n",
            "  inflating: gun200/rifleaud/96./96.7.mp3  \n",
            "  inflating: gun200/rifleaud/96./96.8.mp3  \n",
            "  inflating: gun200/rifleaud/96./96.9.mp3  \n",
            "  inflating: gun200/rifleaud/96./96.10.mp3  \n",
            "   creating: gun200/rifleaud/97./\n",
            "  inflating: gun200/rifleaud/97./97.0.mp3  \n",
            "  inflating: gun200/rifleaud/97./97.1.mp3  \n",
            "  inflating: gun200/rifleaud/97./97.2.mp3  \n",
            "  inflating: gun200/rifleaud/97./97.3.mp3  \n",
            "  inflating: gun200/rifleaud/97./97.4.mp3  \n",
            "  inflating: gun200/rifleaud/97./97.5.mp3  \n",
            "  inflating: gun200/rifleaud/97./97.6.mp3  \n",
            "  inflating: gun200/rifleaud/97./97.7.mp3  \n",
            "  inflating: gun200/rifleaud/97./97.8.mp3  \n",
            "  inflating: gun200/rifleaud/97./97.9.mp3  \n",
            "   creating: gun200/rifleaud/98./\n",
            "  inflating: gun200/rifleaud/98./98.0.mp3  \n",
            "  inflating: gun200/rifleaud/98./98.1.mp3  \n",
            "   creating: gun200/rifleaud/99./\n",
            "  inflating: gun200/rifleaud/99./99.0.mp3  \n",
            "  inflating: gun200/rifleaud/99./99.1.mp3  \n",
            "  inflating: gun200/rifleaud/99./99.2.mp3  \n",
            "  inflating: gun200/rifleaud/99./99.3.mp3  \n",
            "  inflating: gun200/rifleaud/99./99.4.mp3  \n",
            "  inflating: gun200/rifleaud/99./99.5.mp3  \n",
            "  inflating: gun200/rifleaud/99./99.6.mp3  \n",
            "  inflating: gun200/rifleaud/99./99.7.mp3  \n",
            "   creating: gun200/rifleaud/100./\n",
            "  inflating: gun200/rifleaud/100./100.0.mp3  \n",
            "  inflating: gun200/rifleaud/100./100.1.mp3  \n",
            "  inflating: gun200/rifleaud/100./100.2.mp3  \n",
            "  inflating: gun200/rifleaud/100./100.3.mp3  \n",
            "  inflating: gun200/rifleaud/100./100.4.mp3  \n",
            "  inflating: gun200/rifleaud/100./100.5.mp3  \n",
            "  inflating: gun200/rifleaud/100./100.6.mp3  \n",
            "  inflating: gun200/rifleaud/100./100.7.mp3  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UYY2fpPG-2M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "a5475291-231e-4f29-c3c3-e8167ceb176b"
      },
      "source": [
        "gun=[]\n",
        "for i in range(91):\n",
        "  try:\n",
        "    if(i<51):\n",
        "      shots=os.listdir('gun200/gunaud/'+str(i)+\"/\")\n",
        "      for shot in shots:\n",
        "        gun.append(librosa.load('gun200/gunaud/'+str(i)+\"/\"+shot))\n",
        "    else:\n",
        "      shots=os.listdir('gun200/gunaud/'+str(i)+\"./\")\n",
        "      for shot in shots:\n",
        "        gun.append(librosa.load('gun200/gunaud/'+str(i)+\"./\"+shot))\n",
        "    \n",
        "  except:\n",
        "    print(i)\n",
        "    \n",
        "rifle=[]\n",
        "for i in range(101):\n",
        "  try:\n",
        "    if(i<51):\n",
        "      shots=os.listdir('gun200/rifleaud/'+str(i)+\"/\")\n",
        "      for shot in shots:\n",
        "        rifle.append(librosa.load('gun200/rifleaud/'+str(i)+\"/\"+shot))\n",
        "    else:\n",
        "      shots=os.listdir('gun200/rifleaud/'+str(i)+\"./\")\n",
        "      for shot in shots:\n",
        "        rifle.append(librosa.load('gun200/rifleaud/'+str(i)+\"./\"+shot))\n",
        "  except:\n",
        "    print(i)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17\n",
            "20\n",
            "40\n",
            "51\n",
            "75\n",
            "80\n",
            "82\n",
            "83\n",
            "88\n",
            "89\n",
            "16\n",
            "27\n",
            "37\n",
            "45\n",
            "47\n",
            "49\n",
            "50\n",
            "67\n",
            "72\n",
            "83\n",
            "86\n",
            "95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HthdkaZ1H6s1"
      },
      "source": [
        "gun_arr=[]\n",
        "label=[]#for handgun l is 0\n",
        "gl1=len(gun)\n",
        "for i in range(gl1):\n",
        "  if(gun[i][0].shape[0]==22200):\n",
        "    fx=np.concatenate((np.array([-1.0]*150),gun[i][0],np.array([-1.0]*150)),axis=0)\n",
        "    gun_arr.append(fx)\n",
        "  elif(gun[i][0].shape[0]==21624):\n",
        "    fx=np.concatenate((np.array([-1.0]*438),gun[i][0],np.array([-1.0]*438)),axis=0)\n",
        "    gun_arr.append(fx)\n",
        "        \n",
        "  label.append(0)\n",
        "rifle_arr=[]\n",
        "rl1 = len(rifle)\n",
        "for i in range(rl1):  \n",
        "  if(rifle[i][0].shape[0]==22200):\n",
        "    fx=np.concatenate((np.array([-1.0]*150),rifle[i][0],np.array([-1.0]*150)),axis=0)\n",
        "    rifle_arr.append(fx)\n",
        "  elif(rifle[i][0].shape[0]==21624):\n",
        "    fx=np.concatenate((np.array([-1.0]*438),rifle[i][0],np.array([-1.0]*438)),axis=0)\n",
        "    rifle_arr.append(fx)\n",
        "        \n",
        "  label.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNNS8OmLHyDm"
      },
      "source": [
        "from IPython.display import Audio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1cFcMvAHCZb"
      },
      "source": [
        "# got the gun and rifle\n",
        "audio = gun_arr[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEJyR1XkH0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "44277f2b-3587-4e51-fd52-347508932042"
      },
      "source": [
        "Audio(audio,rate=22500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "                <audio controls=\"controls\" >\n",
              "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ],
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TikXxa_cOnNv"
      },
      "source": [
        "#librosa.feature.chroma_stft(audio,sr=22500),librosa.feature.chroma_cqt(audio,sr=22500),\n",
        "def feautre_vc(audio):\n",
        "  return np.concatenate((librosa.feature.chroma_cens(audio,sr=22500),\n",
        "               librosa.feature.mfcc(audio,sr=22500,n_mfcc=44),librosa.feature.rms(audio), librosa.feature.rmse(audio), librosa.feature.spectral_centroid(audio,sr=22500),librosa.feature.melspectrogram(y=audio,sr=22500),\n",
        "               librosa.feature.spectral_bandwidth(audio,sr=22500),librosa.feature.spectral_contrast(audio,sr=22500),librosa.feature.spectral_flatness(audio),librosa.feature.spectral_rolloff(audio,sr=22500),\n",
        "               librosa.feature.poly_features(audio,sr=22500),librosa.feature.tonnetz(audio,sr=22500),librosa.feature.zero_crossing_rate(audio)),axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYUFPfhNqzVe"
      },
      "source": [
        "def take_pca(train,test):\n",
        "  \n",
        "  # capture shape\n",
        "  ts=test.shape\n",
        "  tr=train.shape\n",
        "  \n",
        "  # reshape\n",
        "  test= np.reshape(test,(len(test),-1))\n",
        "  train=np.reshape(train,(len(train),-1))\n",
        "  \n",
        "  # take pca\n",
        "  \n",
        "  pca=PCA()\n",
        "  pca.fit(train)\n",
        "  train_pca=pca.transform(train)\n",
        "  test_pca=pca.transform(test)\n",
        "  \n",
        "  print(\"shape before, train \",tr, \"test\",ts,\"after pca train \",train_pca.shape,\"test\", test_pca)\n",
        "  \n",
        "  return train_pca,test_pca\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlnRI4XHsykZ"
      },
      "source": [
        "def "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FODv0fUijWNS"
      },
      "source": [
        "def normalize(train,test):\n",
        "  ts=test.shape\n",
        "  tr=train.shape\n",
        "  \n",
        "  test= np.reshape(test,(len(test),-1))\n",
        "  train=np.reshape(train,(len(train),-1))\n",
        "  \n",
        "  s = sd()\n",
        "  s.fit(train)\n",
        "  train = s.transform(train)\n",
        "  test = s.transform(test)\n",
        "  \n",
        "  test= np.reshape(test,ts)\n",
        "  train=np.reshape(train,tr)\n",
        "  \n",
        "  return train, test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3trgO-aRRa8"
      },
      "source": [
        "#hop_length = 512\n",
        "\n",
        "gun_arr_l=[]\n",
        "label=[]#for handgun l is 0\n",
        "for i in range(gl1):\n",
        "  mfccg = feautre_vc(gun_arr[i])\n",
        "  gun_arr_l.append(mfccg)\n",
        "  label.append(0)\n",
        "\n",
        "rifle_arr_l=[]\n",
        "for i in range(rl1):\n",
        "  mfccr = feautre_vc(rifle_arr[i])\n",
        "  rifle_arr_l.append(mfccr)\n",
        "  label.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp5CtOlJRUGW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2410de27-7893-48ef-d86a-49f6fcfda465"
      },
      "source": [
        "train_mfcc=np.array(gun_arr_l+rifle_arr_l)\n",
        "#train_dmfcc=np.array(gd+rd)\n",
        "label=np.array(label)\n",
        "print(train_mfcc.shape)\n",
        "#print(train_dmfcc.shape)\n",
        "print(label.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1339, 206, 44)\n",
            "(1339,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83QFcTvjT3nr"
      },
      "source": [
        "train_mfcc=np.reshape(train_mfcc,(-1,train_mfcc.shape[1],44,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGfJX9E2Tn9j"
      },
      "source": [
        "n=5\n",
        "cv=StratifiedKFold(n_splits=n,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0vyQoKHP2yT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34377
        },
        "outputId": "156d3677-be06-4a4a-f0a6-779edeb54de8"
      },
      "source": [
        "roctemp2=[]\n",
        "f1s1=[]\n",
        "aps1=[]\n",
        "accs1=[]\n",
        "aucs1=[]\n",
        "X=train_mfcc\n",
        "y=label\n",
        "count=0\n",
        "for train1, test1 in cv.split(X,y):\n",
        "  train,val=X[train1], X[test1]\n",
        "  ytrain = keras.utils.to_categorical(y[train1])\n",
        "  yval= keras.utils.to_categorical(y[test1])\n",
        "  \n",
        "  #train,val=normalize(train,val)\n",
        "  epoch = 100\n",
        "  model = Sequential()\n",
        "  model.add(Convolution2D(32, (2,2), input_shape=(train_mfcc.shape[1],44,1), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "  model.add(Convolution2D(64, (2,2), activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "\n",
        "\n",
        "  model.add(Convolution2D(32, (2,2), activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "  model.add(Convolution2D(64, (2,2), activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "  model.add(Convolution2D(32, (2,2), activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "  model.add(Convolution2D(64, (2,2), activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  model.add(Convolution2D(32, (2,2), activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "  model.add(Convolution2D(64, 2, activation='relu',padding='same'))\n",
        "  #model.add(ZeroPadding2D((1, 1)))\n",
        "  model.add(MaxPooling2D(pool_size=2,padding='same'))\n",
        "  #model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(0.8))\n",
        "  model.add(Dense(2))\n",
        "  model.add(Activation('softmax'))\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  filepath=\"k1\"+str(count)+\".hdf5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "  callbacks_list = [checkpoint]\n",
        "\n",
        "  history=model.fit(train,ytrain, epochs=epoch,batch_size=None, verbose=1, validation_data=(val,yval) ,validation_split=None,callbacks=callbacks_list,  shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n",
        "  #model.save(dictm.get(mo)+\"sound.h5\")\n",
        "\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Convolution2D(32, (2,2), input_shape=(train_mfcc.shape[1],44,1), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "  model.add(Convolution2D(64, (2,2), activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "\n",
        "\n",
        "  model.add(Convolution2D(32, (2,2), activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "  model.add(Convolution2D(64, (2,2), activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "  model.add(Convolution2D(32, (2,2), activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "  model.add(Convolution2D(64, (2,2), activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  model.add(Convolution2D(32, (2,2), activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "  model.add(Convolution2D(64, 2, activation='relu',padding='same'))\n",
        "  #model.add(ZeroPadding2D((1, 1)))\n",
        "  model.add(MaxPooling2D(pool_size=2,padding='same'))\n",
        "  #model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(0.8))\n",
        "  model.add(Dense(2))\n",
        "  model.add(Activation('softmax'))\n",
        "  model.load_weights(\"k1\"+str(count)+\".hdf5\")\n",
        "  model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  score=model.evaluate(val,yval)\n",
        "  print(\" accuracy\", score[1]*100,\"%\")\n",
        "  accs1.append(score[1])\n",
        "\n",
        "  #print(dictm.get(mo),\" : \",score[1]*100)\n",
        "  probs=model.predict_proba(val)\n",
        "  ys=np.argmax(yval, axis=1)\n",
        "  auc = roc_auc_score(ys, probs[:,1])\n",
        "  aucs1.append(auc)\n",
        "  #yval2=keras.utils.to_categorical(yval)\n",
        "  fpr, tpr, thresholds = roc_curve(ys, probs[:,1])\n",
        "  # plt.plot([0.0, 1.0], [0.0, 1.0], linestyle='--')\n",
        "  # plt.plot(fpr, tpr, marker='.')\n",
        "  # plt.show()\n",
        "  f1 = f1_score(ys, model.predict_classes(val))\n",
        "  f1s1.append(f1)\n",
        "  ap = average_precision_score(ys, probs[:,1])\n",
        "  aps1.append(ap)\n",
        "  roctemp2.append([fpr, tpr, thresholds])\n",
        "  print(\"auc, f1, ap \" ,auc, f1, ap)\n",
        "  count+=1\n",
        "  # conf_mat=confusion_matrix(y, model.predict_classes(valf))\n",
        "  # print(conf_mat)\n",
        "  # precision, recall, thresholds = precision_recall_curve(y, probs[:,1])\n",
        "  # roctemp2.append([precision, recall, thresholds])\n",
        "  # plt.plot([1.0, 0.0], [0.0, 1.0], linestyle='--')\n",
        "  # plt.plot(recall, precision, marker='.')\n",
        "  # plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1070 samples, validate on 269 samples\n",
            "Epoch 1/100\n",
            "1070/1070 [==============================] - 9s 9ms/step - loss: 1.4919 - acc: 0.5150 - val_loss: 0.6867 - val_acc: 0.5613\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.56134, saving model to k10.hdf5\n",
            "Epoch 2/100\n",
            "1070/1070 [==============================] - 1s 982us/step - loss: 0.6992 - acc: 0.5327 - val_loss: 0.6983 - val_acc: 0.4944\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.56134\n",
            "Epoch 3/100\n",
            "1070/1070 [==============================] - 1s 903us/step - loss: 0.6898 - acc: 0.5477 - val_loss: 0.6840 - val_acc: 0.5316\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.56134\n",
            "Epoch 4/100\n",
            "1070/1070 [==============================] - 1s 918us/step - loss: 0.6939 - acc: 0.5393 - val_loss: 0.6851 - val_acc: 0.5093\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.56134\n",
            "Epoch 5/100\n",
            "1070/1070 [==============================] - 1s 900us/step - loss: 0.7123 - acc: 0.5187 - val_loss: 0.6839 - val_acc: 0.5874\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.56134 to 0.58736, saving model to k10.hdf5\n",
            "Epoch 6/100\n",
            "1070/1070 [==============================] - 1s 903us/step - loss: 0.6861 - acc: 0.5411 - val_loss: 0.6812 - val_acc: 0.5836\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.58736\n",
            "Epoch 7/100\n",
            "1070/1070 [==============================] - 1s 897us/step - loss: 0.6898 - acc: 0.5570 - val_loss: 0.6682 - val_acc: 0.6357\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.58736 to 0.63569, saving model to k10.hdf5\n",
            "Epoch 8/100\n",
            "1070/1070 [==============================] - 1s 900us/step - loss: 0.6650 - acc: 0.5953 - val_loss: 0.6633 - val_acc: 0.6022\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.63569\n",
            "Epoch 9/100\n",
            "1070/1070 [==============================] - 1s 887us/step - loss: 0.6572 - acc: 0.6252 - val_loss: 0.6647 - val_acc: 0.5911\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.63569\n",
            "Epoch 10/100\n",
            "1070/1070 [==============================] - 1s 882us/step - loss: 0.6413 - acc: 0.6355 - val_loss: 0.7486 - val_acc: 0.5613\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.63569\n",
            "Epoch 11/100\n",
            "1070/1070 [==============================] - 1s 889us/step - loss: 0.6518 - acc: 0.6196 - val_loss: 0.7151 - val_acc: 0.5874\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.63569\n",
            "Epoch 12/100\n",
            "1070/1070 [==============================] - 1s 886us/step - loss: 0.6382 - acc: 0.6654 - val_loss: 0.6497 - val_acc: 0.6208\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.63569\n",
            "Epoch 13/100\n",
            "1070/1070 [==============================] - 1s 912us/step - loss: 0.6298 - acc: 0.6570 - val_loss: 0.6390 - val_acc: 0.6357\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.63569 to 0.63569, saving model to k10.hdf5\n",
            "Epoch 14/100\n",
            "1070/1070 [==============================] - 1s 890us/step - loss: 0.6441 - acc: 0.6439 - val_loss: 0.6629 - val_acc: 0.5911\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.63569\n",
            "Epoch 15/100\n",
            "1070/1070 [==============================] - 1s 894us/step - loss: 0.5934 - acc: 0.7084 - val_loss: 0.6574 - val_acc: 0.6208\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.63569\n",
            "Epoch 16/100\n",
            "1070/1070 [==============================] - 1s 905us/step - loss: 0.5468 - acc: 0.7168 - val_loss: 0.5302 - val_acc: 0.7138\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.63569 to 0.71375, saving model to k10.hdf5\n",
            "Epoch 17/100\n",
            "1070/1070 [==============================] - 1s 888us/step - loss: 0.5055 - acc: 0.7589 - val_loss: 0.5682 - val_acc: 0.6989\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.71375\n",
            "Epoch 18/100\n",
            "1070/1070 [==============================] - 1s 904us/step - loss: 0.4368 - acc: 0.7981 - val_loss: 0.4009 - val_acc: 0.8253\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.71375 to 0.82528, saving model to k10.hdf5\n",
            "Epoch 19/100\n",
            "1070/1070 [==============================] - 1s 900us/step - loss: 0.4007 - acc: 0.8168 - val_loss: 0.4857 - val_acc: 0.7881\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.82528\n",
            "Epoch 20/100\n",
            "1070/1070 [==============================] - 1s 905us/step - loss: 0.3376 - acc: 0.8776 - val_loss: 0.5359 - val_acc: 0.7918\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.82528\n",
            "Epoch 21/100\n",
            "1070/1070 [==============================] - 1s 906us/step - loss: 0.3130 - acc: 0.8822 - val_loss: 0.5672 - val_acc: 0.7770\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.82528\n",
            "Epoch 22/100\n",
            "1070/1070 [==============================] - 1s 896us/step - loss: 0.2080 - acc: 0.9159 - val_loss: 0.3149 - val_acc: 0.8810\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.82528 to 0.88104, saving model to k10.hdf5\n",
            "Epoch 23/100\n",
            "1070/1070 [==============================] - 1s 892us/step - loss: 0.1930 - acc: 0.9280 - val_loss: 0.4905 - val_acc: 0.8141\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.88104\n",
            "Epoch 24/100\n",
            "1070/1070 [==============================] - 1s 889us/step - loss: 0.1568 - acc: 0.9430 - val_loss: 0.2967 - val_acc: 0.8773\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.88104\n",
            "Epoch 25/100\n",
            "1070/1070 [==============================] - 1s 896us/step - loss: 0.1387 - acc: 0.9477 - val_loss: 0.3435 - val_acc: 0.8885\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.88104 to 0.88848, saving model to k10.hdf5\n",
            "Epoch 26/100\n",
            "1070/1070 [==============================] - 1s 900us/step - loss: 0.1602 - acc: 0.9355 - val_loss: 0.5174 - val_acc: 0.8401\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.88848\n",
            "Epoch 27/100\n",
            "1070/1070 [==============================] - 1s 885us/step - loss: 0.1274 - acc: 0.9589 - val_loss: 0.3206 - val_acc: 0.8996\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.88848 to 0.89963, saving model to k10.hdf5\n",
            "Epoch 28/100\n",
            "1070/1070 [==============================] - 1s 891us/step - loss: 0.1151 - acc: 0.9533 - val_loss: 0.7703 - val_acc: 0.7658\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.89963\n",
            "Epoch 29/100\n",
            "1070/1070 [==============================] - 1s 887us/step - loss: 0.1534 - acc: 0.9346 - val_loss: 0.2264 - val_acc: 0.9442\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.89963 to 0.94424, saving model to k10.hdf5\n",
            "Epoch 30/100\n",
            "1070/1070 [==============================] - 1s 894us/step - loss: 0.1244 - acc: 0.9514 - val_loss: 0.2684 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.94424\n",
            "Epoch 31/100\n",
            "1070/1070 [==============================] - 1s 902us/step - loss: 0.0902 - acc: 0.9682 - val_loss: 0.2575 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.94424\n",
            "Epoch 32/100\n",
            "1070/1070 [==============================] - 1s 896us/step - loss: 0.0736 - acc: 0.9738 - val_loss: 0.2585 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.94424\n",
            "Epoch 33/100\n",
            "1070/1070 [==============================] - 1s 897us/step - loss: 0.0568 - acc: 0.9804 - val_loss: 0.4955 - val_acc: 0.8773\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.94424\n",
            "Epoch 34/100\n",
            "1070/1070 [==============================] - 1s 891us/step - loss: 0.0971 - acc: 0.9589 - val_loss: 0.3982 - val_acc: 0.8922\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.94424\n",
            "Epoch 35/100\n",
            "1070/1070 [==============================] - 1s 892us/step - loss: 0.0651 - acc: 0.9748 - val_loss: 0.7406 - val_acc: 0.8476\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.94424\n",
            "Epoch 36/100\n",
            "1070/1070 [==============================] - 1s 877us/step - loss: 0.1382 - acc: 0.9533 - val_loss: 0.2923 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.94424\n",
            "Epoch 37/100\n",
            "1070/1070 [==============================] - 1s 896us/step - loss: 0.0554 - acc: 0.9841 - val_loss: 0.3225 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.94424\n",
            "Epoch 38/100\n",
            "1070/1070 [==============================] - 1s 896us/step - loss: 0.0312 - acc: 0.9888 - val_loss: 0.3687 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.94424\n",
            "Epoch 39/100\n",
            "1070/1070 [==============================] - 1s 896us/step - loss: 0.0299 - acc: 0.9860 - val_loss: 0.3742 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.94424\n",
            "Epoch 40/100\n",
            "1070/1070 [==============================] - 1s 897us/step - loss: 0.0531 - acc: 0.9794 - val_loss: 0.4287 - val_acc: 0.9071\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.94424\n",
            "Epoch 41/100\n",
            "1070/1070 [==============================] - 1s 924us/step - loss: 0.0448 - acc: 0.9888 - val_loss: 0.3390 - val_acc: 0.9331\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.94424\n",
            "Epoch 42/100\n",
            "1070/1070 [==============================] - 1s 911us/step - loss: 0.1745 - acc: 0.9355 - val_loss: 0.3917 - val_acc: 0.8699\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.94424\n",
            "Epoch 43/100\n",
            "1070/1070 [==============================] - 1s 915us/step - loss: 0.1148 - acc: 0.9561 - val_loss: 0.2973 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.94424\n",
            "Epoch 44/100\n",
            "1070/1070 [==============================] - 1s 906us/step - loss: 0.0465 - acc: 0.9785 - val_loss: 0.3246 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.94424\n",
            "Epoch 45/100\n",
            "1070/1070 [==============================] - 1s 900us/step - loss: 0.0290 - acc: 0.9888 - val_loss: 0.2934 - val_acc: 0.9405\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.94424\n",
            "Epoch 46/100\n",
            "1070/1070 [==============================] - 1s 907us/step - loss: 0.0259 - acc: 0.9907 - val_loss: 0.3871 - val_acc: 0.9033\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.94424\n",
            "Epoch 47/100\n",
            "1070/1070 [==============================] - 1s 918us/step - loss: 0.0131 - acc: 0.9944 - val_loss: 0.2956 - val_acc: 0.9331\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.94424\n",
            "Epoch 48/100\n",
            "1070/1070 [==============================] - 1s 919us/step - loss: 0.0314 - acc: 0.9907 - val_loss: 0.5295 - val_acc: 0.8848\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.94424\n",
            "Epoch 49/100\n",
            "1070/1070 [==============================] - 1s 923us/step - loss: 0.0838 - acc: 0.9720 - val_loss: 0.2545 - val_acc: 0.9368\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.94424\n",
            "Epoch 50/100\n",
            "1070/1070 [==============================] - 1s 909us/step - loss: 0.0232 - acc: 0.9935 - val_loss: 0.2926 - val_acc: 0.9368\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.94424\n",
            "Epoch 51/100\n",
            "1070/1070 [==============================] - 1s 906us/step - loss: 0.0347 - acc: 0.9888 - val_loss: 0.2995 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00051: val_acc improved from 0.94424 to 0.94796, saving model to k10.hdf5\n",
            "Epoch 52/100\n",
            "1070/1070 [==============================] - 1s 898us/step - loss: 0.0186 - acc: 0.9916 - val_loss: 0.4129 - val_acc: 0.9294\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.94796\n",
            "Epoch 53/100\n",
            "1070/1070 [==============================] - 1s 904us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.4300 - val_acc: 0.9368\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.94796\n",
            "Epoch 54/100\n",
            "1070/1070 [==============================] - 1s 889us/step - loss: 8.6807e-04 - acc: 1.0000 - val_loss: 0.6608 - val_acc: 0.9033\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.94796\n",
            "Epoch 55/100\n",
            "1070/1070 [==============================] - 1s 913us/step - loss: 6.9696e-04 - acc: 1.0000 - val_loss: 0.5093 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.94796\n",
            "Epoch 56/100\n",
            "1070/1070 [==============================] - 1s 919us/step - loss: 0.0020 - acc: 0.9991 - val_loss: 0.5764 - val_acc: 0.9071\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.94796\n",
            "Epoch 57/100\n",
            "1070/1070 [==============================] - 1s 907us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.5153 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.94796\n",
            "Epoch 58/100\n",
            "1070/1070 [==============================] - 1s 899us/step - loss: 0.0799 - acc: 0.9841 - val_loss: 0.3614 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.94796\n",
            "Epoch 59/100\n",
            "1070/1070 [==============================] - 1s 911us/step - loss: 0.1556 - acc: 0.9402 - val_loss: 0.3097 - val_acc: 0.9071\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.94796\n",
            "Epoch 60/100\n",
            "1070/1070 [==============================] - 1s 924us/step - loss: 0.0806 - acc: 0.9682 - val_loss: 0.2893 - val_acc: 0.9257\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.94796\n",
            "Epoch 61/100\n",
            "1070/1070 [==============================] - 1s 905us/step - loss: 0.0322 - acc: 0.9841 - val_loss: 0.3563 - val_acc: 0.9331\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.94796\n",
            "Epoch 62/100\n",
            "1070/1070 [==============================] - 1s 915us/step - loss: 0.0355 - acc: 0.9869 - val_loss: 0.3654 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.94796\n",
            "Epoch 63/100\n",
            "1070/1070 [==============================] - 1s 914us/step - loss: 0.0195 - acc: 0.9925 - val_loss: 0.4903 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.94796\n",
            "Epoch 64/100\n",
            "1070/1070 [==============================] - 1s 917us/step - loss: 0.0053 - acc: 0.9991 - val_loss: 0.4016 - val_acc: 0.9405\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.94796\n",
            "Epoch 65/100\n",
            "1070/1070 [==============================] - 1s 909us/step - loss: 0.0143 - acc: 0.9981 - val_loss: 0.7237 - val_acc: 0.8996\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.94796\n",
            "Epoch 66/100\n",
            "1070/1070 [==============================] - 1s 914us/step - loss: 0.0588 - acc: 0.9748 - val_loss: 0.3327 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.94796\n",
            "Epoch 67/100\n",
            "1070/1070 [==============================] - 1s 913us/step - loss: 0.0172 - acc: 0.9944 - val_loss: 0.3450 - val_acc: 0.9442\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.94796\n",
            "Epoch 68/100\n",
            "1070/1070 [==============================] - 1s 916us/step - loss: 0.0421 - acc: 0.9879 - val_loss: 0.3192 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.94796\n",
            "Epoch 69/100\n",
            "1070/1070 [==============================] - 1s 907us/step - loss: 0.0516 - acc: 0.9869 - val_loss: 0.3436 - val_acc: 0.9219\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.94796\n",
            "Epoch 70/100\n",
            "1070/1070 [==============================] - 1s 914us/step - loss: 0.0150 - acc: 0.9953 - val_loss: 0.3266 - val_acc: 0.9331\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.94796\n",
            "Epoch 71/100\n",
            "1070/1070 [==============================] - 1s 904us/step - loss: 0.0166 - acc: 0.9935 - val_loss: 0.4171 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.94796\n",
            "Epoch 72/100\n",
            "1070/1070 [==============================] - 1s 918us/step - loss: 0.0107 - acc: 0.9972 - val_loss: 0.4936 - val_acc: 0.9145\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.94796\n",
            "Epoch 73/100\n",
            "1070/1070 [==============================] - 1s 919us/step - loss: 0.0263 - acc: 0.9916 - val_loss: 0.3299 - val_acc: 0.9405\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.94796\n",
            "Epoch 74/100\n",
            "1070/1070 [==============================] - 1s 909us/step - loss: 0.0400 - acc: 0.9841 - val_loss: 0.3349 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.94796\n",
            "Epoch 75/100\n",
            "1070/1070 [==============================] - 1s 917us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.3170 - val_acc: 0.9517\n",
            "\n",
            "Epoch 00075: val_acc improved from 0.94796 to 0.95167, saving model to k10.hdf5\n",
            "Epoch 76/100\n",
            "1070/1070 [==============================] - 1s 909us/step - loss: 0.0029 - acc: 0.9981 - val_loss: 0.3612 - val_acc: 0.9405\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.95167\n",
            "Epoch 77/100\n",
            "1070/1070 [==============================] - 1s 919us/step - loss: 3.7478e-04 - acc: 1.0000 - val_loss: 0.3699 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.95167\n",
            "Epoch 78/100\n",
            "1070/1070 [==============================] - 1s 916us/step - loss: 1.9425e-04 - acc: 1.0000 - val_loss: 0.3839 - val_acc: 0.9442\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.95167\n",
            "Epoch 79/100\n",
            "1070/1070 [==============================] - 1s 913us/step - loss: 1.3833e-04 - acc: 1.0000 - val_loss: 0.3920 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.95167\n",
            "Epoch 80/100\n",
            "1070/1070 [==============================] - 1s 901us/step - loss: 1.3073e-04 - acc: 1.0000 - val_loss: 0.3960 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.95167\n",
            "Epoch 81/100\n",
            "1070/1070 [==============================] - 1s 901us/step - loss: 1.4717e-04 - acc: 1.0000 - val_loss: 0.4046 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.95167\n",
            "Epoch 82/100\n",
            "1070/1070 [==============================] - 1s 906us/step - loss: 1.1200e-04 - acc: 1.0000 - val_loss: 0.4076 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.95167\n",
            "Epoch 83/100\n",
            "1070/1070 [==============================] - 1s 903us/step - loss: 9.2857e-05 - acc: 1.0000 - val_loss: 0.4128 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.95167\n",
            "Epoch 84/100\n",
            "1070/1070 [==============================] - 1s 912us/step - loss: 9.6231e-05 - acc: 1.0000 - val_loss: 0.4190 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.95167\n",
            "Epoch 85/100\n",
            "1070/1070 [==============================] - 1s 916us/step - loss: 8.5612e-05 - acc: 1.0000 - val_loss: 0.4250 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.95167\n",
            "Epoch 86/100\n",
            "1070/1070 [==============================] - 1s 910us/step - loss: 6.9587e-05 - acc: 1.0000 - val_loss: 0.4316 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.95167\n",
            "Epoch 87/100\n",
            "1070/1070 [==============================] - 1s 907us/step - loss: 8.6370e-05 - acc: 1.0000 - val_loss: 0.4328 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.95167\n",
            "Epoch 88/100\n",
            "1070/1070 [==============================] - 1s 919us/step - loss: 7.1441e-05 - acc: 1.0000 - val_loss: 0.4345 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.95167\n",
            "Epoch 89/100\n",
            "1070/1070 [==============================] - 1s 927us/step - loss: 4.7795e-05 - acc: 1.0000 - val_loss: 0.4337 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.95167\n",
            "Epoch 90/100\n",
            "1070/1070 [==============================] - 1s 909us/step - loss: 4.9925e-05 - acc: 1.0000 - val_loss: 0.4370 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.95167\n",
            "Epoch 91/100\n",
            "1070/1070 [==============================] - 1s 902us/step - loss: 7.2445e-05 - acc: 1.0000 - val_loss: 0.4409 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.95167\n",
            "Epoch 92/100\n",
            "1070/1070 [==============================] - 1s 914us/step - loss: 5.6226e-05 - acc: 1.0000 - val_loss: 0.4494 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.95167\n",
            "Epoch 93/100\n",
            "1070/1070 [==============================] - 1s 914us/step - loss: 4.4466e-05 - acc: 1.0000 - val_loss: 0.4497 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.95167\n",
            "Epoch 94/100\n",
            "1070/1070 [==============================] - 1s 911us/step - loss: 3.8251e-05 - acc: 1.0000 - val_loss: 0.4505 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.95167\n",
            "Epoch 95/100\n",
            "1070/1070 [==============================] - 1s 906us/step - loss: 3.9729e-05 - acc: 1.0000 - val_loss: 0.4520 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.95167\n",
            "Epoch 96/100\n",
            "1070/1070 [==============================] - 1s 892us/step - loss: 3.4307e-05 - acc: 1.0000 - val_loss: 0.4527 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.95167\n",
            "Epoch 97/100\n",
            "1070/1070 [==============================] - 1s 912us/step - loss: 3.1293e-05 - acc: 1.0000 - val_loss: 0.4539 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.95167\n",
            "Epoch 98/100\n",
            "1070/1070 [==============================] - 1s 899us/step - loss: 3.3198e-05 - acc: 1.0000 - val_loss: 0.4578 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.95167\n",
            "Epoch 99/100\n",
            "1070/1070 [==============================] - 1s 900us/step - loss: 2.8421e-05 - acc: 1.0000 - val_loss: 0.4602 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.95167\n",
            "Epoch 100/100\n",
            "1070/1070 [==============================] - 1s 903us/step - loss: 3.7074e-05 - acc: 1.0000 - val_loss: 0.4598 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.95167\n",
            "269/269 [==============================] - 7s 26ms/step\n",
            " accuracy 95.16728624535315 %\n",
            "auc, f1, ap  0.9747648035417819 0.9537366548042705 0.968994517798234\n",
            "Train on 1071 samples, validate on 268 samples\n",
            "Epoch 1/100\n",
            "1071/1071 [==============================] - 10s 9ms/step - loss: 1.5275 - acc: 0.5014 - val_loss: 0.6887 - val_acc: 0.5187\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.51866, saving model to k11.hdf5\n",
            "Epoch 2/100\n",
            "1071/1071 [==============================] - 1s 912us/step - loss: 0.7071 - acc: 0.5117 - val_loss: 0.7430 - val_acc: 0.5187\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.51866\n",
            "Epoch 3/100\n",
            "1071/1071 [==============================] - 1s 914us/step - loss: 0.7057 - acc: 0.5266 - val_loss: 0.6794 - val_acc: 0.5858\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.51866 to 0.58582, saving model to k11.hdf5\n",
            "Epoch 4/100\n",
            "1071/1071 [==============================] - 1s 903us/step - loss: 0.6837 - acc: 0.5630 - val_loss: 0.6648 - val_acc: 0.5746\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.58582\n",
            "Epoch 5/100\n",
            "1071/1071 [==============================] - 1s 906us/step - loss: 0.6886 - acc: 0.5705 - val_loss: 0.6730 - val_acc: 0.5858\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.58582 to 0.58582, saving model to k11.hdf5\n",
            "Epoch 6/100\n",
            "1071/1071 [==============================] - 1s 915us/step - loss: 0.7079 - acc: 0.5331 - val_loss: 0.6634 - val_acc: 0.6082\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.58582 to 0.60821, saving model to k11.hdf5\n",
            "Epoch 7/100\n",
            "1071/1071 [==============================] - 1s 906us/step - loss: 0.6696 - acc: 0.5761 - val_loss: 0.8262 - val_acc: 0.4813\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.60821\n",
            "Epoch 8/100\n",
            "1071/1071 [==============================] - 1s 909us/step - loss: 0.7119 - acc: 0.5061 - val_loss: 0.6771 - val_acc: 0.6157\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.60821 to 0.61567, saving model to k11.hdf5\n",
            "Epoch 9/100\n",
            "1071/1071 [==============================] - 1s 911us/step - loss: 0.6749 - acc: 0.5733 - val_loss: 0.6619 - val_acc: 0.6119\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.61567\n",
            "Epoch 10/100\n",
            "1071/1071 [==============================] - 1s 911us/step - loss: 0.6614 - acc: 0.6153 - val_loss: 0.6527 - val_acc: 0.6269\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.61567 to 0.62687, saving model to k11.hdf5\n",
            "Epoch 11/100\n",
            "1071/1071 [==============================] - 1s 902us/step - loss: 0.6696 - acc: 0.5640 - val_loss: 0.6376 - val_acc: 0.6903\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.62687 to 0.69030, saving model to k11.hdf5\n",
            "Epoch 12/100\n",
            "1071/1071 [==============================] - 1s 903us/step - loss: 0.6141 - acc: 0.6779 - val_loss: 0.7504 - val_acc: 0.5746\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.69030\n",
            "Epoch 13/100\n",
            "1071/1071 [==============================] - 1s 896us/step - loss: 0.5784 - acc: 0.6975 - val_loss: 0.5674 - val_acc: 0.7239\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.69030 to 0.72388, saving model to k11.hdf5\n",
            "Epoch 14/100\n",
            "1071/1071 [==============================] - 1s 901us/step - loss: 0.5168 - acc: 0.7451 - val_loss: 0.5636 - val_acc: 0.7164\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.72388\n",
            "Epoch 15/100\n",
            "1071/1071 [==============================] - 1s 901us/step - loss: 0.4645 - acc: 0.7955 - val_loss: 0.4475 - val_acc: 0.7985\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.72388 to 0.79851, saving model to k11.hdf5\n",
            "Epoch 16/100\n",
            "1071/1071 [==============================] - 1s 894us/step - loss: 0.4088 - acc: 0.8170 - val_loss: 0.3902 - val_acc: 0.8284\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.79851 to 0.82836, saving model to k11.hdf5\n",
            "Epoch 17/100\n",
            "1071/1071 [==============================] - 1s 904us/step - loss: 0.3471 - acc: 0.8534 - val_loss: 0.3461 - val_acc: 0.8507\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.82836 to 0.85075, saving model to k11.hdf5\n",
            "Epoch 18/100\n",
            "1071/1071 [==============================] - 1s 902us/step - loss: 0.3236 - acc: 0.8637 - val_loss: 0.3028 - val_acc: 0.8769\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.85075 to 0.87687, saving model to k11.hdf5\n",
            "Epoch 19/100\n",
            "1071/1071 [==============================] - 1s 906us/step - loss: 0.2408 - acc: 0.9113 - val_loss: 0.2757 - val_acc: 0.8806\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.87687 to 0.88060, saving model to k11.hdf5\n",
            "Epoch 20/100\n",
            "1071/1071 [==============================] - 1s 912us/step - loss: 0.2488 - acc: 0.8954 - val_loss: 0.2273 - val_acc: 0.8918\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.88060 to 0.89179, saving model to k11.hdf5\n",
            "Epoch 21/100\n",
            "1071/1071 [==============================] - 1s 915us/step - loss: 0.1617 - acc: 0.9440 - val_loss: 0.2578 - val_acc: 0.8881\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.89179\n",
            "Epoch 22/100\n",
            "1071/1071 [==============================] - 1s 918us/step - loss: 0.1642 - acc: 0.9402 - val_loss: 0.3428 - val_acc: 0.8881\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.89179\n",
            "Epoch 23/100\n",
            "1071/1071 [==============================] - 1s 909us/step - loss: 0.1681 - acc: 0.9300 - val_loss: 0.2317 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.89179 to 0.92164, saving model to k11.hdf5\n",
            "Epoch 24/100\n",
            "1071/1071 [==============================] - 1s 906us/step - loss: 0.1655 - acc: 0.9328 - val_loss: 0.2628 - val_acc: 0.9030\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.92164\n",
            "Epoch 25/100\n",
            "1071/1071 [==============================] - 1s 907us/step - loss: 0.1164 - acc: 0.9561 - val_loss: 0.2548 - val_acc: 0.9142\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.92164\n",
            "Epoch 26/100\n",
            "1071/1071 [==============================] - 1s 913us/step - loss: 0.1213 - acc: 0.9580 - val_loss: 0.2083 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.92164\n",
            "Epoch 27/100\n",
            "1071/1071 [==============================] - 1s 905us/step - loss: 0.0810 - acc: 0.9748 - val_loss: 0.2349 - val_acc: 0.9291\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.92164 to 0.92910, saving model to k11.hdf5\n",
            "Epoch 28/100\n",
            "1071/1071 [==============================] - 1s 910us/step - loss: 0.1114 - acc: 0.9589 - val_loss: 0.2453 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.92910\n",
            "Epoch 29/100\n",
            "1071/1071 [==============================] - 1s 914us/step - loss: 0.0918 - acc: 0.9683 - val_loss: 0.1976 - val_acc: 0.9291\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.92910\n",
            "Epoch 30/100\n",
            "1071/1071 [==============================] - 1s 907us/step - loss: 0.1010 - acc: 0.9608 - val_loss: 0.2366 - val_acc: 0.9142\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.92910\n",
            "Epoch 31/100\n",
            "1071/1071 [==============================] - 1s 911us/step - loss: 0.1225 - acc: 0.9533 - val_loss: 0.1832 - val_acc: 0.9366\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.92910 to 0.93657, saving model to k11.hdf5\n",
            "Epoch 32/100\n",
            "1071/1071 [==============================] - 1s 912us/step - loss: 0.1002 - acc: 0.9570 - val_loss: 0.3045 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.93657\n",
            "Epoch 33/100\n",
            "1071/1071 [==============================] - 1s 907us/step - loss: 0.1228 - acc: 0.9570 - val_loss: 0.1454 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.93657 to 0.94030, saving model to k11.hdf5\n",
            "Epoch 34/100\n",
            "1071/1071 [==============================] - 1s 914us/step - loss: 0.0474 - acc: 0.9860 - val_loss: 0.2747 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.94030\n",
            "Epoch 35/100\n",
            "1071/1071 [==============================] - 1s 910us/step - loss: 0.0358 - acc: 0.9879 - val_loss: 0.3020 - val_acc: 0.9366\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.94030\n",
            "Epoch 36/100\n",
            "1071/1071 [==============================] - 1s 915us/step - loss: 0.0957 - acc: 0.9589 - val_loss: 0.3096 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.94030\n",
            "Epoch 37/100\n",
            "1071/1071 [==============================] - 1s 920us/step - loss: 0.0855 - acc: 0.9711 - val_loss: 0.2334 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.94030\n",
            "Epoch 38/100\n",
            "1071/1071 [==============================] - 1s 913us/step - loss: 0.0339 - acc: 0.9869 - val_loss: 0.2328 - val_acc: 0.9366\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.94030\n",
            "Epoch 39/100\n",
            "1071/1071 [==============================] - 1s 906us/step - loss: 0.0387 - acc: 0.9888 - val_loss: 0.1954 - val_acc: 0.9478\n",
            "\n",
            "Epoch 00039: val_acc improved from 0.94030 to 0.94776, saving model to k11.hdf5\n",
            "Epoch 40/100\n",
            "1071/1071 [==============================] - 1s 912us/step - loss: 0.0128 - acc: 0.9963 - val_loss: 0.2847 - val_acc: 0.9291\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.94776\n",
            "Epoch 41/100\n",
            "1071/1071 [==============================] - 1s 915us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.2762 - val_acc: 0.9366\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.94776\n",
            "Epoch 42/100\n",
            "1071/1071 [==============================] - 1s 909us/step - loss: 7.2636e-04 - acc: 1.0000 - val_loss: 0.2881 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.94776\n",
            "Epoch 43/100\n",
            "1071/1071 [==============================] - 1s 909us/step - loss: 4.7972e-04 - acc: 1.0000 - val_loss: 0.2902 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.94776\n",
            "Epoch 44/100\n",
            "1071/1071 [==============================] - 1s 902us/step - loss: 3.2601e-04 - acc: 1.0000 - val_loss: 0.2961 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.94776\n",
            "Epoch 45/100\n",
            "1071/1071 [==============================] - 1s 913us/step - loss: 3.0807e-04 - acc: 1.0000 - val_loss: 0.2990 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.94776\n",
            "Epoch 46/100\n",
            "1071/1071 [==============================] - 1s 923us/step - loss: 3.2051e-04 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.9440\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.94776\n",
            "Epoch 47/100\n",
            "1071/1071 [==============================] - 1s 913us/step - loss: 1.9114e-04 - acc: 1.0000 - val_loss: 0.3117 - val_acc: 0.9440\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.94776\n",
            "Epoch 48/100\n",
            "1071/1071 [==============================] - 1s 905us/step - loss: 1.6918e-04 - acc: 1.0000 - val_loss: 0.3098 - val_acc: 0.9440\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.94776\n",
            "Epoch 49/100\n",
            "1071/1071 [==============================] - 1s 902us/step - loss: 1.4343e-04 - acc: 1.0000 - val_loss: 0.3142 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.94776\n",
            "Epoch 50/100\n",
            "1071/1071 [==============================] - 1s 902us/step - loss: 1.1023e-04 - acc: 1.0000 - val_loss: 0.3150 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.94776\n",
            "Epoch 51/100\n",
            "1071/1071 [==============================] - 1s 907us/step - loss: 1.4438e-04 - acc: 1.0000 - val_loss: 0.3175 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.94776\n",
            "Epoch 52/100\n",
            "1071/1071 [==============================] - 1s 913us/step - loss: 9.5631e-05 - acc: 1.0000 - val_loss: 0.3141 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.94776\n",
            "Epoch 53/100\n",
            "1071/1071 [==============================] - 1s 911us/step - loss: 1.0036e-04 - acc: 1.0000 - val_loss: 0.3196 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.94776\n",
            "Epoch 54/100\n",
            "1071/1071 [==============================] - 1s 906us/step - loss: 7.5350e-05 - acc: 1.0000 - val_loss: 0.3229 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.94776\n",
            "Epoch 55/100\n",
            "1071/1071 [==============================] - 1s 913us/step - loss: 9.3790e-05 - acc: 1.0000 - val_loss: 0.3306 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.94776\n",
            "Epoch 56/100\n",
            "1071/1071 [==============================] - 1s 909us/step - loss: 7.4160e-05 - acc: 1.0000 - val_loss: 0.3361 - val_acc: 0.9440\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.94776\n",
            "Epoch 57/100\n",
            "1071/1071 [==============================] - 1s 911us/step - loss: 6.4064e-05 - acc: 1.0000 - val_loss: 0.3379 - val_acc: 0.9440\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.94776\n",
            "Epoch 58/100\n",
            "1071/1071 [==============================] - 1s 904us/step - loss: 6.2113e-05 - acc: 1.0000 - val_loss: 0.3368 - val_acc: 0.9440\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.94776\n",
            "Epoch 59/100\n",
            "1071/1071 [==============================] - 1s 902us/step - loss: 7.5908e-05 - acc: 1.0000 - val_loss: 0.3373 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.94776\n",
            "Epoch 60/100\n",
            "1071/1071 [==============================] - 1s 902us/step - loss: 6.4845e-05 - acc: 1.0000 - val_loss: 0.3416 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.94776\n",
            "Epoch 61/100\n",
            "1071/1071 [==============================] - 1s 908us/step - loss: 5.5613e-05 - acc: 1.0000 - val_loss: 0.3426 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.94776\n",
            "Epoch 62/100\n",
            "1071/1071 [==============================] - 1s 910us/step - loss: 5.2056e-05 - acc: 1.0000 - val_loss: 0.3438 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.94776\n",
            "Epoch 63/100\n",
            "1071/1071 [==============================] - 1s 911us/step - loss: 5.1936e-05 - acc: 1.0000 - val_loss: 0.3473 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.94776\n",
            "Epoch 64/100\n",
            "1071/1071 [==============================] - 1s 909us/step - loss: 3.8653e-05 - acc: 1.0000 - val_loss: 0.3458 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.94776\n",
            "Epoch 65/100\n",
            "1071/1071 [==============================] - 1s 912us/step - loss: 3.8004e-05 - acc: 1.0000 - val_loss: 0.3503 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.94776\n",
            "Epoch 66/100\n",
            "1071/1071 [==============================] - 1s 896us/step - loss: 4.6783e-05 - acc: 1.0000 - val_loss: 0.3559 - val_acc: 0.9440\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.94776\n",
            "Epoch 67/100\n",
            "1071/1071 [==============================] - 1s 895us/step - loss: 4.7881e-05 - acc: 1.0000 - val_loss: 0.3551 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.94776\n",
            "Epoch 68/100\n",
            "1071/1071 [==============================] - 1s 900us/step - loss: 3.9497e-05 - acc: 1.0000 - val_loss: 0.3575 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.94776\n",
            "Epoch 69/100\n",
            "1071/1071 [==============================] - 1s 893us/step - loss: 4.6630e-05 - acc: 1.0000 - val_loss: 0.3605 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.94776\n",
            "Epoch 70/100\n",
            "1071/1071 [==============================] - 1s 894us/step - loss: 3.1344e-05 - acc: 1.0000 - val_loss: 0.3620 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.94776\n",
            "Epoch 71/100\n",
            "1071/1071 [==============================] - 1s 895us/step - loss: 3.6959e-05 - acc: 1.0000 - val_loss: 0.3597 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.94776\n",
            "Epoch 72/100\n",
            "1071/1071 [==============================] - 1s 890us/step - loss: 3.1715e-05 - acc: 1.0000 - val_loss: 0.3628 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.94776\n",
            "Epoch 73/100\n",
            "1071/1071 [==============================] - 1s 889us/step - loss: 3.3457e-05 - acc: 1.0000 - val_loss: 0.3660 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.94776\n",
            "Epoch 74/100\n",
            "1071/1071 [==============================] - 1s 896us/step - loss: 3.3093e-05 - acc: 1.0000 - val_loss: 0.3675 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.94776\n",
            "Epoch 75/100\n",
            "1071/1071 [==============================] - 1s 902us/step - loss: 3.0489e-05 - acc: 1.0000 - val_loss: 0.3708 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.94776\n",
            "Epoch 76/100\n",
            "1071/1071 [==============================] - 1s 899us/step - loss: 2.4430e-05 - acc: 1.0000 - val_loss: 0.3708 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.94776\n",
            "Epoch 77/100\n",
            "1071/1071 [==============================] - 1s 910us/step - loss: 1.8526e-05 - acc: 1.0000 - val_loss: 0.3722 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.94776\n",
            "Epoch 78/100\n",
            "1071/1071 [==============================] - 1s 902us/step - loss: 3.6526e-05 - acc: 1.0000 - val_loss: 0.3719 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.94776\n",
            "Epoch 79/100\n",
            "1071/1071 [==============================] - 1s 906us/step - loss: 2.1599e-05 - acc: 1.0000 - val_loss: 0.3746 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.94776\n",
            "Epoch 80/100\n",
            "1071/1071 [==============================] - 1s 895us/step - loss: 2.7566e-05 - acc: 1.0000 - val_loss: 0.3769 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.94776\n",
            "Epoch 81/100\n",
            "1071/1071 [==============================] - 1s 909us/step - loss: 2.8090e-05 - acc: 1.0000 - val_loss: 0.3766 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.94776\n",
            "Epoch 82/100\n",
            "1071/1071 [==============================] - 1s 908us/step - loss: 1.7208e-05 - acc: 1.0000 - val_loss: 0.3791 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.94776\n",
            "Epoch 83/100\n",
            "1071/1071 [==============================] - 1s 911us/step - loss: 1.8411e-05 - acc: 1.0000 - val_loss: 0.3821 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.94776\n",
            "Epoch 84/100\n",
            "1071/1071 [==============================] - 1s 916us/step - loss: 2.3476e-05 - acc: 1.0000 - val_loss: 0.3831 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.94776\n",
            "Epoch 85/100\n",
            "1071/1071 [==============================] - 1s 912us/step - loss: 2.1073e-05 - acc: 1.0000 - val_loss: 0.3867 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.94776\n",
            "Epoch 86/100\n",
            "1071/1071 [==============================] - 1s 899us/step - loss: 1.7873e-05 - acc: 1.0000 - val_loss: 0.3874 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.94776\n",
            "Epoch 87/100\n",
            "1071/1071 [==============================] - 1s 899us/step - loss: 2.4685e-05 - acc: 1.0000 - val_loss: 0.3864 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.94776\n",
            "Epoch 88/100\n",
            "1071/1071 [==============================] - 1s 923us/step - loss: 1.4938e-05 - acc: 1.0000 - val_loss: 0.3882 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.94776\n",
            "Epoch 89/100\n",
            "1071/1071 [==============================] - 1s 902us/step - loss: 1.3479e-05 - acc: 1.0000 - val_loss: 0.3887 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.94776\n",
            "Epoch 90/100\n",
            "1071/1071 [==============================] - 1s 901us/step - loss: 1.4857e-05 - acc: 1.0000 - val_loss: 0.3917 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.94776\n",
            "Epoch 91/100\n",
            "1071/1071 [==============================] - 1s 907us/step - loss: 1.2606e-05 - acc: 1.0000 - val_loss: 0.3938 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.94776\n",
            "Epoch 92/100\n",
            "1071/1071 [==============================] - 1s 909us/step - loss: 1.4696e-05 - acc: 1.0000 - val_loss: 0.3957 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.94776\n",
            "Epoch 93/100\n",
            "1071/1071 [==============================] - 1s 915us/step - loss: 1.2498e-05 - acc: 1.0000 - val_loss: 0.3968 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.94776\n",
            "Epoch 94/100\n",
            "1071/1071 [==============================] - 1s 904us/step - loss: 1.2375e-05 - acc: 1.0000 - val_loss: 0.3960 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.94776\n",
            "Epoch 95/100\n",
            "1071/1071 [==============================] - 1s 904us/step - loss: 1.5031e-05 - acc: 1.0000 - val_loss: 0.3982 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.94776\n",
            "Epoch 96/100\n",
            "1071/1071 [==============================] - 1s 903us/step - loss: 1.1349e-05 - acc: 1.0000 - val_loss: 0.3996 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.94776\n",
            "Epoch 97/100\n",
            "1071/1071 [==============================] - 1s 905us/step - loss: 1.2018e-05 - acc: 1.0000 - val_loss: 0.4008 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.94776\n",
            "Epoch 98/100\n",
            "1071/1071 [==============================] - 1s 905us/step - loss: 1.5390e-05 - acc: 1.0000 - val_loss: 0.4053 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.94776\n",
            "Epoch 99/100\n",
            "1071/1071 [==============================] - 1s 909us/step - loss: 8.1854e-06 - acc: 1.0000 - val_loss: 0.4059 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.94776\n",
            "Epoch 100/100\n",
            "1071/1071 [==============================] - 1s 917us/step - loss: 8.3096e-06 - acc: 1.0000 - val_loss: 0.4054 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.94776\n",
            "268/268 [==============================] - 7s 27ms/step\n",
            " accuracy 94.77611940298507 %\n",
            "auc, f1, ap  0.9863922815236184 0.95 0.987268074832687\n",
            "Train on 1071 samples, validate on 268 samples\n",
            "Epoch 1/100\n",
            "1071/1071 [==============================] - 10s 9ms/step - loss: 1.6010 - acc: 0.5238 - val_loss: 0.6884 - val_acc: 0.5149\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.51493, saving model to k12.hdf5\n",
            "Epoch 2/100\n",
            "1071/1071 [==============================] - 1s 926us/step - loss: 0.6888 - acc: 0.5602 - val_loss: 0.6907 - val_acc: 0.5336\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.51493 to 0.53358, saving model to k12.hdf5\n",
            "Epoch 3/100\n",
            "1071/1071 [==============================] - 1s 909us/step - loss: 0.7038 - acc: 0.5313 - val_loss: 0.6750 - val_acc: 0.6045\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.53358 to 0.60448, saving model to k12.hdf5\n",
            "Epoch 4/100\n",
            "1071/1071 [==============================] - 1s 903us/step - loss: 0.7003 - acc: 0.5490 - val_loss: 0.6726 - val_acc: 0.6231\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.60448 to 0.62313, saving model to k12.hdf5\n",
            "Epoch 5/100\n",
            "1071/1071 [==============================] - 1s 908us/step - loss: 0.6889 - acc: 0.5556 - val_loss: 0.6794 - val_acc: 0.5746\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.62313\n",
            "Epoch 6/100\n",
            "1071/1071 [==============================] - 1s 910us/step - loss: 0.6858 - acc: 0.5584 - val_loss: 0.6668 - val_acc: 0.5970\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.62313\n",
            "Epoch 7/100\n",
            "1071/1071 [==============================] - 1s 917us/step - loss: 0.6840 - acc: 0.5733 - val_loss: 0.6730 - val_acc: 0.5634\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.62313\n",
            "Epoch 8/100\n",
            "1071/1071 [==============================] - 1s 900us/step - loss: 0.6627 - acc: 0.5826 - val_loss: 0.6413 - val_acc: 0.6269\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.62313 to 0.62687, saving model to k12.hdf5\n",
            "Epoch 9/100\n",
            "1071/1071 [==============================] - 1s 898us/step - loss: 0.6518 - acc: 0.6377 - val_loss: 0.6377 - val_acc: 0.6045\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.62687\n",
            "Epoch 10/100\n",
            "1071/1071 [==============================] - 1s 908us/step - loss: 0.6768 - acc: 0.6013 - val_loss: 0.6325 - val_acc: 0.6418\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.62687 to 0.64179, saving model to k12.hdf5\n",
            "Epoch 11/100\n",
            "1071/1071 [==============================] - 1s 907us/step - loss: 0.6283 - acc: 0.6611 - val_loss: 0.5908 - val_acc: 0.7015\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.64179 to 0.70149, saving model to k12.hdf5\n",
            "Epoch 12/100\n",
            "1071/1071 [==============================] - 1s 913us/step - loss: 0.6069 - acc: 0.6564 - val_loss: 0.6057 - val_acc: 0.7239\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.70149 to 0.72388, saving model to k12.hdf5\n",
            "Epoch 13/100\n",
            "1071/1071 [==============================] - 1s 913us/step - loss: 0.5297 - acc: 0.7507 - val_loss: 0.4529 - val_acc: 0.7948\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.72388 to 0.79478, saving model to k12.hdf5\n",
            "Epoch 14/100\n",
            "1071/1071 [==============================] - 1s 905us/step - loss: 0.4762 - acc: 0.7787 - val_loss: 0.5233 - val_acc: 0.7313\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.79478\n",
            "Epoch 15/100\n",
            "1071/1071 [==============================] - 1s 904us/step - loss: 0.4543 - acc: 0.7927 - val_loss: 0.4342 - val_acc: 0.7836\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.79478\n",
            "Epoch 16/100\n",
            "1071/1071 [==============================] - 1s 901us/step - loss: 0.3491 - acc: 0.8534 - val_loss: 0.3453 - val_acc: 0.8582\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.79478 to 0.85821, saving model to k12.hdf5\n",
            "Epoch 17/100\n",
            "1071/1071 [==============================] - 1s 910us/step - loss: 0.3341 - acc: 0.8693 - val_loss: 0.3060 - val_acc: 0.8619\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.85821 to 0.86194, saving model to k12.hdf5\n",
            "Epoch 18/100\n",
            "1071/1071 [==============================] - 1s 907us/step - loss: 0.2821 - acc: 0.8954 - val_loss: 0.3197 - val_acc: 0.8507\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.86194\n",
            "Epoch 19/100\n",
            "1071/1071 [==============================] - 1s 913us/step - loss: 0.2728 - acc: 0.8945 - val_loss: 0.2579 - val_acc: 0.8918\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.86194 to 0.89179, saving model to k12.hdf5\n",
            "Epoch 20/100\n",
            "1071/1071 [==============================] - 1s 910us/step - loss: 0.2532 - acc: 0.8964 - val_loss: 0.3669 - val_acc: 0.8284\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.89179\n",
            "Epoch 21/100\n",
            "1071/1071 [==============================] - 1s 909us/step - loss: 0.2098 - acc: 0.9253 - val_loss: 0.2909 - val_acc: 0.8918\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.89179 to 0.89179, saving model to k12.hdf5\n",
            "Epoch 22/100\n",
            "1071/1071 [==============================] - 1s 905us/step - loss: 0.1654 - acc: 0.9356 - val_loss: 0.2939 - val_acc: 0.8657\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.89179\n",
            "Epoch 23/100\n",
            "1071/1071 [==============================] - 1s 907us/step - loss: 0.1372 - acc: 0.9533 - val_loss: 0.2725 - val_acc: 0.8881\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.89179\n",
            "Epoch 24/100\n",
            "1071/1071 [==============================] - 1s 909us/step - loss: 0.1865 - acc: 0.9318 - val_loss: 0.3059 - val_acc: 0.8731\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.89179\n",
            "Epoch 25/100\n",
            "1071/1071 [==============================] - 1s 905us/step - loss: 0.1307 - acc: 0.9655 - val_loss: 0.2903 - val_acc: 0.8806\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.89179\n",
            "Epoch 26/100\n",
            "1071/1071 [==============================] - 1s 904us/step - loss: 0.1200 - acc: 0.9533 - val_loss: 0.2943 - val_acc: 0.8881\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.89179\n",
            "Epoch 27/100\n",
            "1071/1071 [==============================] - 1s 911us/step - loss: 0.0835 - acc: 0.9711 - val_loss: 0.2900 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.89179 to 0.90672, saving model to k12.hdf5\n",
            "Epoch 28/100\n",
            "1071/1071 [==============================] - 1s 897us/step - loss: 0.1231 - acc: 0.9524 - val_loss: 0.2570 - val_acc: 0.8881\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.90672\n",
            "Epoch 29/100\n",
            "1071/1071 [==============================] - 1s 921us/step - loss: 0.0943 - acc: 0.9701 - val_loss: 0.2263 - val_acc: 0.8955\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.90672\n",
            "Epoch 30/100\n",
            "1071/1071 [==============================] - 1s 910us/step - loss: 0.0756 - acc: 0.9757 - val_loss: 0.2303 - val_acc: 0.9142\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.90672 to 0.91418, saving model to k12.hdf5\n",
            "Epoch 31/100\n",
            "1071/1071 [==============================] - 1s 922us/step - loss: 0.1275 - acc: 0.9636 - val_loss: 0.2745 - val_acc: 0.8993\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.91418\n",
            "Epoch 32/100\n",
            "1071/1071 [==============================] - 1s 905us/step - loss: 0.0751 - acc: 0.9711 - val_loss: 0.2409 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.91418\n",
            "Epoch 33/100\n",
            "1071/1071 [==============================] - 1s 901us/step - loss: 0.1397 - acc: 0.9496 - val_loss: 0.2709 - val_acc: 0.8806\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.91418\n",
            "Epoch 34/100\n",
            "1071/1071 [==============================] - 1s 905us/step - loss: 0.0574 - acc: 0.9813 - val_loss: 0.1991 - val_acc: 0.9440\n",
            "\n",
            "Epoch 00034: val_acc improved from 0.91418 to 0.94403, saving model to k12.hdf5\n",
            "Epoch 35/100\n",
            "1071/1071 [==============================] - 1s 907us/step - loss: 0.0273 - acc: 0.9935 - val_loss: 0.2242 - val_acc: 0.9328\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.94403\n",
            "Epoch 36/100\n",
            "1071/1071 [==============================] - 1s 909us/step - loss: 0.0406 - acc: 0.9851 - val_loss: 0.3086 - val_acc: 0.8955\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.94403\n",
            "Epoch 37/100\n",
            "1071/1071 [==============================] - 1s 892us/step - loss: 0.0700 - acc: 0.9748 - val_loss: 0.1968 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.94403\n",
            "Epoch 38/100\n",
            "1071/1071 [==============================] - 1s 905us/step - loss: 0.0279 - acc: 0.9944 - val_loss: 0.3469 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.94403\n",
            "Epoch 39/100\n",
            "1071/1071 [==============================] - 1s 899us/step - loss: 0.0183 - acc: 0.9935 - val_loss: 0.2988 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.94403\n",
            "Epoch 40/100\n",
            "1071/1071 [==============================] - 1s 900us/step - loss: 0.0197 - acc: 0.9916 - val_loss: 0.2708 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.94403\n",
            "Epoch 41/100\n",
            "1071/1071 [==============================] - 1s 905us/step - loss: 0.0877 - acc: 0.9739 - val_loss: 0.2084 - val_acc: 0.9142\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.94403\n",
            "Epoch 42/100\n",
            "1071/1071 [==============================] - 1s 903us/step - loss: 0.0679 - acc: 0.9720 - val_loss: 0.2392 - val_acc: 0.9142\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.94403\n",
            "Epoch 43/100\n",
            "1071/1071 [==============================] - 1s 889us/step - loss: 0.0320 - acc: 0.9860 - val_loss: 0.2480 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.94403\n",
            "Epoch 44/100\n",
            "1071/1071 [==============================] - 1s 892us/step - loss: 0.0358 - acc: 0.9869 - val_loss: 0.2809 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.94403\n",
            "Epoch 45/100\n",
            "1071/1071 [==============================] - 1s 902us/step - loss: 0.0739 - acc: 0.9692 - val_loss: 0.2176 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.94403\n",
            "Epoch 46/100\n",
            "1071/1071 [==============================] - 1s 894us/step - loss: 0.0252 - acc: 0.9925 - val_loss: 0.2175 - val_acc: 0.9291\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.94403\n",
            "Epoch 47/100\n",
            "1071/1071 [==============================] - 1s 900us/step - loss: 0.0083 - acc: 0.9991 - val_loss: 0.2808 - val_acc: 0.9291\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.94403\n",
            "Epoch 48/100\n",
            "1071/1071 [==============================] - 1s 905us/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.2677 - val_acc: 0.9291\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.94403\n",
            "Epoch 49/100\n",
            "1071/1071 [==============================] - 1s 905us/step - loss: 0.0224 - acc: 0.9907 - val_loss: 0.5331 - val_acc: 0.8806\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.94403\n",
            "Epoch 50/100\n",
            "1071/1071 [==============================] - 1s 921us/step - loss: 0.0602 - acc: 0.9795 - val_loss: 0.2665 - val_acc: 0.9142\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.94403\n",
            "Epoch 51/100\n",
            "1071/1071 [==============================] - 1s 902us/step - loss: 0.0273 - acc: 0.9907 - val_loss: 0.2973 - val_acc: 0.8881\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.94403\n",
            "Epoch 52/100\n",
            "1071/1071 [==============================] - 1s 910us/step - loss: 0.0112 - acc: 0.9972 - val_loss: 0.3161 - val_acc: 0.9142\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.94403\n",
            "Epoch 53/100\n",
            "1071/1071 [==============================] - 1s 904us/step - loss: 0.0254 - acc: 0.9916 - val_loss: 0.3498 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.94403\n",
            "Epoch 54/100\n",
            "1071/1071 [==============================] - 1s 916us/step - loss: 0.0323 - acc: 0.9888 - val_loss: 0.2417 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.94403\n",
            "Epoch 55/100\n",
            "1071/1071 [==============================] - 1s 905us/step - loss: 0.0473 - acc: 0.9841 - val_loss: 0.2633 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.94403\n",
            "Epoch 56/100\n",
            "1071/1071 [==============================] - 1s 911us/step - loss: 0.0326 - acc: 0.9888 - val_loss: 0.2523 - val_acc: 0.9328\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.94403\n",
            "Epoch 57/100\n",
            "1071/1071 [==============================] - 1s 908us/step - loss: 0.0090 - acc: 0.9963 - val_loss: 0.3111 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.94403\n",
            "Epoch 58/100\n",
            "1071/1071 [==============================] - 1s 919us/step - loss: 0.0190 - acc: 0.9925 - val_loss: 0.3445 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.94403\n",
            "Epoch 59/100\n",
            "1071/1071 [==============================] - 1s 901us/step - loss: 0.0134 - acc: 0.9944 - val_loss: 0.3520 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.94403\n",
            "Epoch 60/100\n",
            "1071/1071 [==============================] - 1s 905us/step - loss: 0.0197 - acc: 0.9907 - val_loss: 0.5178 - val_acc: 0.8955\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.94403\n",
            "Epoch 61/100\n",
            "1071/1071 [==============================] - 1s 917us/step - loss: 0.0471 - acc: 0.9813 - val_loss: 0.2647 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.94403\n",
            "Epoch 62/100\n",
            "1071/1071 [==============================] - 1s 913us/step - loss: 0.0555 - acc: 0.9841 - val_loss: 0.2285 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.94403\n",
            "Epoch 63/100\n",
            "1071/1071 [==============================] - 1s 916us/step - loss: 0.0289 - acc: 0.9907 - val_loss: 0.2298 - val_acc: 0.9478\n",
            "\n",
            "Epoch 00063: val_acc improved from 0.94403 to 0.94776, saving model to k12.hdf5\n",
            "Epoch 64/100\n",
            "1071/1071 [==============================] - 1s 924us/step - loss: 0.0108 - acc: 0.9953 - val_loss: 0.2567 - val_acc: 0.9328\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.94776\n",
            "Epoch 65/100\n",
            "1071/1071 [==============================] - 1s 926us/step - loss: 0.0068 - acc: 0.9972 - val_loss: 0.3452 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.94776\n",
            "Epoch 66/100\n",
            "1071/1071 [==============================] - 1s 906us/step - loss: 0.0051 - acc: 0.9972 - val_loss: 0.3709 - val_acc: 0.9291\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.94776\n",
            "Epoch 67/100\n",
            "1071/1071 [==============================] - 1s 908us/step - loss: 0.0280 - acc: 0.9879 - val_loss: 0.2555 - val_acc: 0.9291\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.94776\n",
            "Epoch 68/100\n",
            "1071/1071 [==============================] - 1s 904us/step - loss: 0.0074 - acc: 0.9981 - val_loss: 0.4151 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.94776\n",
            "Epoch 69/100\n",
            "1071/1071 [==============================] - 1s 910us/step - loss: 0.0085 - acc: 0.9953 - val_loss: 0.2934 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.94776\n",
            "Epoch 70/100\n",
            "1071/1071 [==============================] - 1s 917us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.3201 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.94776\n",
            "Epoch 71/100\n",
            "1071/1071 [==============================] - 1s 900us/step - loss: 0.0219 - acc: 0.9916 - val_loss: 0.4108 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.94776\n",
            "Epoch 72/100\n",
            "1071/1071 [==============================] - 1s 907us/step - loss: 0.0601 - acc: 0.9757 - val_loss: 0.2157 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.94776\n",
            "Epoch 73/100\n",
            "1071/1071 [==============================] - 1s 911us/step - loss: 0.0169 - acc: 0.9972 - val_loss: 0.4294 - val_acc: 0.9067\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.94776\n",
            "Epoch 74/100\n",
            "1071/1071 [==============================] - 1s 909us/step - loss: 0.0163 - acc: 0.9935 - val_loss: 0.4156 - val_acc: 0.9030\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.94776\n",
            "Epoch 75/100\n",
            "1071/1071 [==============================] - 1s 902us/step - loss: 0.0635 - acc: 0.9804 - val_loss: 0.1983 - val_acc: 0.9291\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.94776\n",
            "Epoch 76/100\n",
            "1071/1071 [==============================] - 1s 900us/step - loss: 0.0416 - acc: 0.9879 - val_loss: 0.2700 - val_acc: 0.9142\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.94776\n",
            "Epoch 77/100\n",
            "1071/1071 [==============================] - 1s 900us/step - loss: 0.0430 - acc: 0.9869 - val_loss: 0.2278 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.94776\n",
            "Epoch 78/100\n",
            "1071/1071 [==============================] - 1s 903us/step - loss: 0.0364 - acc: 0.9888 - val_loss: 0.1586 - val_acc: 0.9440\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.94776\n",
            "Epoch 79/100\n",
            "1071/1071 [==============================] - 1s 908us/step - loss: 0.0153 - acc: 0.9963 - val_loss: 0.2375 - val_acc: 0.9440\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.94776\n",
            "Epoch 80/100\n",
            "1071/1071 [==============================] - 1s 898us/step - loss: 0.0076 - acc: 0.9972 - val_loss: 0.3260 - val_acc: 0.9366\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.94776\n",
            "Epoch 81/100\n",
            "1071/1071 [==============================] - 1s 926us/step - loss: 0.0120 - acc: 0.9944 - val_loss: 0.2788 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.94776\n",
            "Epoch 82/100\n",
            "1071/1071 [==============================] - 1s 899us/step - loss: 0.0084 - acc: 0.9963 - val_loss: 0.3130 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.94776\n",
            "Epoch 83/100\n",
            "1071/1071 [==============================] - 1s 900us/step - loss: 0.0024 - acc: 0.9991 - val_loss: 0.3413 - val_acc: 0.9328\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.94776\n",
            "Epoch 84/100\n",
            "1071/1071 [==============================] - 1s 910us/step - loss: 1.6871e-04 - acc: 1.0000 - val_loss: 0.3365 - val_acc: 0.9328\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.94776\n",
            "Epoch 85/100\n",
            "1071/1071 [==============================] - 1s 897us/step - loss: 1.7130e-04 - acc: 1.0000 - val_loss: 0.3334 - val_acc: 0.9366\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.94776\n",
            "Epoch 86/100\n",
            "1071/1071 [==============================] - 1s 915us/step - loss: 5.8258e-05 - acc: 1.0000 - val_loss: 0.3328 - val_acc: 0.9328\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.94776\n",
            "Epoch 87/100\n",
            "1071/1071 [==============================] - 1s 913us/step - loss: 8.1481e-05 - acc: 1.0000 - val_loss: 0.3352 - val_acc: 0.9328\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.94776\n",
            "Epoch 88/100\n",
            "1071/1071 [==============================] - 1s 908us/step - loss: 3.7371e-05 - acc: 1.0000 - val_loss: 0.3420 - val_acc: 0.9366\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.94776\n",
            "Epoch 89/100\n",
            "1071/1071 [==============================] - 1s 906us/step - loss: 7.7185e-05 - acc: 1.0000 - val_loss: 0.3492 - val_acc: 0.9291\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.94776\n",
            "Epoch 90/100\n",
            "1071/1071 [==============================] - 1s 910us/step - loss: 2.6426e-05 - acc: 1.0000 - val_loss: 0.3517 - val_acc: 0.9291\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.94776\n",
            "Epoch 91/100\n",
            "1071/1071 [==============================] - 1s 906us/step - loss: 3.4958e-05 - acc: 1.0000 - val_loss: 0.3522 - val_acc: 0.9328\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.94776\n",
            "Epoch 92/100\n",
            "1071/1071 [==============================] - 1s 913us/step - loss: 3.4110e-05 - acc: 1.0000 - val_loss: 0.3542 - val_acc: 0.9328\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.94776\n",
            "Epoch 93/100\n",
            "1071/1071 [==============================] - 1s 906us/step - loss: 3.8129e-05 - acc: 1.0000 - val_loss: 0.3571 - val_acc: 0.9328\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.94776\n",
            "Epoch 94/100\n",
            "1071/1071 [==============================] - 1s 908us/step - loss: 2.3242e-05 - acc: 1.0000 - val_loss: 0.3607 - val_acc: 0.9328\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.94776\n",
            "Epoch 95/100\n",
            "1071/1071 [==============================] - 1s 881us/step - loss: 2.5699e-05 - acc: 1.0000 - val_loss: 0.3630 - val_acc: 0.9328\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.94776\n",
            "Epoch 96/100\n",
            "1071/1071 [==============================] - 1s 904us/step - loss: 2.0027e-05 - acc: 1.0000 - val_loss: 0.3644 - val_acc: 0.9328\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.94776\n",
            "Epoch 97/100\n",
            "1071/1071 [==============================] - 1s 897us/step - loss: 2.0215e-05 - acc: 1.0000 - val_loss: 0.3677 - val_acc: 0.9328\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.94776\n",
            "Epoch 98/100\n",
            "1071/1071 [==============================] - 1s 885us/step - loss: 2.2737e-05 - acc: 1.0000 - val_loss: 0.3704 - val_acc: 0.9328\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.94776\n",
            "Epoch 99/100\n",
            "1071/1071 [==============================] - 1s 896us/step - loss: 1.2387e-05 - acc: 1.0000 - val_loss: 0.3720 - val_acc: 0.9328\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.94776\n",
            "Epoch 100/100\n",
            "1071/1071 [==============================] - 1s 904us/step - loss: 1.3598e-05 - acc: 1.0000 - val_loss: 0.3738 - val_acc: 0.9328\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.94776\n",
            "268/268 [==============================] - 8s 29ms/step\n",
            " accuracy 94.77611949194723 %\n",
            "auc, f1, ap  0.9852211254252412 0.9492753623188406 0.9874584021625062\n",
            "Train on 1072 samples, validate on 267 samples\n",
            "Epoch 1/100\n",
            "1072/1072 [==============================] - 10s 10ms/step - loss: 3.3243 - acc: 0.5028 - val_loss: 0.6926 - val_acc: 0.5169\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.51685, saving model to k13.hdf5\n",
            "Epoch 2/100\n",
            "1072/1072 [==============================] - 1s 903us/step - loss: 0.7062 - acc: 0.4925 - val_loss: 0.6874 - val_acc: 0.5169\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.51685\n",
            "Epoch 3/100\n",
            "1072/1072 [==============================] - 1s 912us/step - loss: 0.7006 - acc: 0.5131 - val_loss: 0.6913 - val_acc: 0.5880\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.51685 to 0.58801, saving model to k13.hdf5\n",
            "Epoch 4/100\n",
            "1072/1072 [==============================] - 1s 910us/step - loss: 0.6976 - acc: 0.4972 - val_loss: 0.6867 - val_acc: 0.5506\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.58801\n",
            "Epoch 5/100\n",
            "1072/1072 [==============================] - 1s 926us/step - loss: 0.6880 - acc: 0.5700 - val_loss: 0.6985 - val_acc: 0.4869\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.58801\n",
            "Epoch 6/100\n",
            "1072/1072 [==============================] - 1s 916us/step - loss: 0.6811 - acc: 0.5588 - val_loss: 0.6866 - val_acc: 0.5281\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.58801\n",
            "Epoch 7/100\n",
            "1072/1072 [==============================] - 1s 899us/step - loss: 0.6959 - acc: 0.5438 - val_loss: 0.6857 - val_acc: 0.5281\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.58801\n",
            "Epoch 8/100\n",
            "1072/1072 [==============================] - 1s 906us/step - loss: 0.6809 - acc: 0.5653 - val_loss: 0.6849 - val_acc: 0.5356\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.58801\n",
            "Epoch 9/100\n",
            "1072/1072 [==============================] - 1s 906us/step - loss: 0.6735 - acc: 0.5728 - val_loss: 0.6690 - val_acc: 0.5730\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.58801\n",
            "Epoch 10/100\n",
            "1072/1072 [==============================] - 1s 894us/step - loss: 0.6562 - acc: 0.6250 - val_loss: 0.6749 - val_acc: 0.5618\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.58801\n",
            "Epoch 11/100\n",
            "1072/1072 [==============================] - 1s 914us/step - loss: 0.6527 - acc: 0.6194 - val_loss: 0.6080 - val_acc: 0.6517\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.58801 to 0.65169, saving model to k13.hdf5\n",
            "Epoch 12/100\n",
            "1072/1072 [==============================] - 1s 894us/step - loss: 0.5645 - acc: 0.7108 - val_loss: 0.5530 - val_acc: 0.6891\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.65169 to 0.68914, saving model to k13.hdf5\n",
            "Epoch 13/100\n",
            "1072/1072 [==============================] - 1s 904us/step - loss: 0.5257 - acc: 0.7435 - val_loss: 0.5542 - val_acc: 0.7341\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.68914 to 0.73408, saving model to k13.hdf5\n",
            "Epoch 14/100\n",
            "1072/1072 [==============================] - 1s 904us/step - loss: 0.4426 - acc: 0.7994 - val_loss: 0.4335 - val_acc: 0.8277\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.73408 to 0.82772, saving model to k13.hdf5\n",
            "Epoch 15/100\n",
            "1072/1072 [==============================] - 1s 911us/step - loss: 0.3669 - acc: 0.8405 - val_loss: 0.3452 - val_acc: 0.8390\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.82772 to 0.83895, saving model to k13.hdf5\n",
            "Epoch 16/100\n",
            "1072/1072 [==============================] - 1s 908us/step - loss: 0.3435 - acc: 0.8517 - val_loss: 0.3954 - val_acc: 0.8202\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.83895\n",
            "Epoch 17/100\n",
            "1072/1072 [==============================] - 1s 939us/step - loss: 0.3688 - acc: 0.8424 - val_loss: 0.3414 - val_acc: 0.8652\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.83895 to 0.86517, saving model to k13.hdf5\n",
            "Epoch 18/100\n",
            "1072/1072 [==============================] - 1s 921us/step - loss: 0.2749 - acc: 0.8834 - val_loss: 0.2319 - val_acc: 0.9064\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.86517 to 0.90637, saving model to k13.hdf5\n",
            "Epoch 19/100\n",
            "1072/1072 [==============================] - 1s 914us/step - loss: 0.2876 - acc: 0.8769 - val_loss: 0.2495 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.90637\n",
            "Epoch 20/100\n",
            "1072/1072 [==============================] - 1s 933us/step - loss: 0.2432 - acc: 0.8946 - val_loss: 0.2249 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.90637 to 0.91011, saving model to k13.hdf5\n",
            "Epoch 21/100\n",
            "1072/1072 [==============================] - 1s 943us/step - loss: 0.2317 - acc: 0.9067 - val_loss: 0.2677 - val_acc: 0.8801\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.91011\n",
            "Epoch 22/100\n",
            "1072/1072 [==============================] - 1s 955us/step - loss: 0.2333 - acc: 0.9114 - val_loss: 0.3339 - val_acc: 0.8502\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.91011\n",
            "Epoch 23/100\n",
            "1072/1072 [==============================] - 1s 967us/step - loss: 0.1701 - acc: 0.9319 - val_loss: 0.2183 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.91011 to 0.92135, saving model to k13.hdf5\n",
            "Epoch 24/100\n",
            "1072/1072 [==============================] - 1s 945us/step - loss: 0.1471 - acc: 0.9422 - val_loss: 0.2991 - val_acc: 0.8689\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.92135\n",
            "Epoch 25/100\n",
            "1072/1072 [==============================] - 1s 955us/step - loss: 0.1445 - acc: 0.9487 - val_loss: 0.3138 - val_acc: 0.8577\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.92135\n",
            "Epoch 26/100\n",
            "1072/1072 [==============================] - 1s 952us/step - loss: 0.1999 - acc: 0.9235 - val_loss: 0.2574 - val_acc: 0.8951\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.92135\n",
            "Epoch 27/100\n",
            "1072/1072 [==============================] - 1s 927us/step - loss: 0.1577 - acc: 0.9412 - val_loss: 0.2119 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.92135\n",
            "Epoch 28/100\n",
            "1072/1072 [==============================] - 1s 951us/step - loss: 0.1378 - acc: 0.9487 - val_loss: 0.2299 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.92135\n",
            "Epoch 29/100\n",
            "1072/1072 [==============================] - 1s 960us/step - loss: 0.0930 - acc: 0.9729 - val_loss: 0.3057 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.92135\n",
            "Epoch 30/100\n",
            "1072/1072 [==============================] - 1s 975us/step - loss: 0.1264 - acc: 0.9552 - val_loss: 0.4677 - val_acc: 0.8277\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.92135\n",
            "Epoch 31/100\n",
            "1072/1072 [==============================] - 1s 954us/step - loss: 0.1424 - acc: 0.9496 - val_loss: 0.1496 - val_acc: 0.9288\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.92135 to 0.92884, saving model to k13.hdf5\n",
            "Epoch 32/100\n",
            "1072/1072 [==============================] - 1s 930us/step - loss: 0.0670 - acc: 0.9739 - val_loss: 0.2435 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.92884\n",
            "Epoch 33/100\n",
            "1072/1072 [==============================] - 1s 918us/step - loss: 0.0685 - acc: 0.9720 - val_loss: 0.4285 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.92884\n",
            "Epoch 34/100\n",
            "1072/1072 [==============================] - 1s 913us/step - loss: 0.1327 - acc: 0.9422 - val_loss: 0.1987 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.92884\n",
            "Epoch 35/100\n",
            "1072/1072 [==============================] - 1s 923us/step - loss: 0.0556 - acc: 0.9823 - val_loss: 0.2191 - val_acc: 0.9288\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.92884\n",
            "Epoch 36/100\n",
            "1072/1072 [==============================] - 1s 914us/step - loss: 0.0457 - acc: 0.9804 - val_loss: 0.2277 - val_acc: 0.9288\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.92884\n",
            "Epoch 37/100\n",
            "1072/1072 [==============================] - 1s 908us/step - loss: 0.0562 - acc: 0.9785 - val_loss: 0.3246 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.92884\n",
            "Epoch 38/100\n",
            "1072/1072 [==============================] - 1s 904us/step - loss: 0.0446 - acc: 0.9860 - val_loss: 0.2217 - val_acc: 0.9476\n",
            "\n",
            "Epoch 00038: val_acc improved from 0.92884 to 0.94757, saving model to k13.hdf5\n",
            "Epoch 39/100\n",
            "1072/1072 [==============================] - 1s 909us/step - loss: 0.0161 - acc: 0.9963 - val_loss: 0.2535 - val_acc: 0.9363\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.94757\n",
            "Epoch 40/100\n",
            "1072/1072 [==============================] - 1s 915us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.2731 - val_acc: 0.9401\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.94757\n",
            "Epoch 41/100\n",
            "1072/1072 [==============================] - 1s 917us/step - loss: 0.0153 - acc: 0.9935 - val_loss: 0.3786 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.94757\n",
            "Epoch 42/100\n",
            "1072/1072 [==============================] - 1s 930us/step - loss: 0.1811 - acc: 0.9263 - val_loss: 0.2358 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.94757\n",
            "Epoch 43/100\n",
            "1072/1072 [==============================] - 1s 917us/step - loss: 0.1619 - acc: 0.9375 - val_loss: 0.1671 - val_acc: 0.9401\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.94757\n",
            "Epoch 44/100\n",
            "1072/1072 [==============================] - 1s 914us/step - loss: 0.0502 - acc: 0.9851 - val_loss: 0.3300 - val_acc: 0.8876\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.94757\n",
            "Epoch 45/100\n",
            "1072/1072 [==============================] - 1s 910us/step - loss: 0.0504 - acc: 0.9776 - val_loss: 0.2428 - val_acc: 0.9288\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.94757\n",
            "Epoch 46/100\n",
            "1072/1072 [==============================] - 1s 920us/step - loss: 0.0322 - acc: 0.9888 - val_loss: 0.2376 - val_acc: 0.9288\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.94757\n",
            "Epoch 47/100\n",
            "1072/1072 [==============================] - 1s 920us/step - loss: 0.0742 - acc: 0.9739 - val_loss: 0.3566 - val_acc: 0.8914\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.94757\n",
            "Epoch 48/100\n",
            "1072/1072 [==============================] - 1s 919us/step - loss: 0.0250 - acc: 0.9935 - val_loss: 0.2719 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.94757\n",
            "Epoch 49/100\n",
            "1072/1072 [==============================] - 1s 916us/step - loss: 0.0124 - acc: 0.9953 - val_loss: 0.2882 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.94757\n",
            "Epoch 50/100\n",
            "1072/1072 [==============================] - 1s 921us/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.3764 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.94757\n",
            "Epoch 51/100\n",
            "1072/1072 [==============================] - 1s 909us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.3612 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.94757\n",
            "Epoch 52/100\n",
            "1072/1072 [==============================] - 1s 918us/step - loss: 7.6253e-04 - acc: 1.0000 - val_loss: 0.3265 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.94757\n",
            "Epoch 53/100\n",
            "1072/1072 [==============================] - 1s 912us/step - loss: 2.9861e-04 - acc: 1.0000 - val_loss: 0.3925 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.94757\n",
            "Epoch 54/100\n",
            "1072/1072 [==============================] - 1s 910us/step - loss: 1.5407e-04 - acc: 1.0000 - val_loss: 0.3872 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.94757\n",
            "Epoch 55/100\n",
            "1072/1072 [==============================] - 1s 901us/step - loss: 1.3146e-04 - acc: 1.0000 - val_loss: 0.3887 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.94757\n",
            "Epoch 56/100\n",
            "1072/1072 [==============================] - 1s 917us/step - loss: 9.9048e-05 - acc: 1.0000 - val_loss: 0.3999 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.94757\n",
            "Epoch 57/100\n",
            "1072/1072 [==============================] - 1s 931us/step - loss: 8.8630e-05 - acc: 1.0000 - val_loss: 0.4011 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.94757\n",
            "Epoch 58/100\n",
            "1072/1072 [==============================] - 1s 918us/step - loss: 5.0803e-05 - acc: 1.0000 - val_loss: 0.4062 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.94757\n",
            "Epoch 59/100\n",
            "1072/1072 [==============================] - 1s 914us/step - loss: 7.8119e-05 - acc: 1.0000 - val_loss: 0.4156 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.94757\n",
            "Epoch 60/100\n",
            "1072/1072 [==============================] - 1s 926us/step - loss: 5.8743e-05 - acc: 1.0000 - val_loss: 0.4242 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.94757\n",
            "Epoch 61/100\n",
            "1072/1072 [==============================] - 1s 957us/step - loss: 6.4198e-05 - acc: 1.0000 - val_loss: 0.4263 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.94757\n",
            "Epoch 62/100\n",
            "1072/1072 [==============================] - 1s 938us/step - loss: 4.1664e-05 - acc: 1.0000 - val_loss: 0.4269 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.94757\n",
            "Epoch 63/100\n",
            "1072/1072 [==============================] - 1s 909us/step - loss: 7.2519e-05 - acc: 1.0000 - val_loss: 0.4265 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.94757\n",
            "Epoch 64/100\n",
            "1072/1072 [==============================] - 1s 910us/step - loss: 3.2499e-05 - acc: 1.0000 - val_loss: 0.4261 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.94757\n",
            "Epoch 65/100\n",
            "1072/1072 [==============================] - 1s 920us/step - loss: 4.4659e-05 - acc: 1.0000 - val_loss: 0.4225 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.94757\n",
            "Epoch 66/100\n",
            "1072/1072 [==============================] - 1s 899us/step - loss: 3.3773e-05 - acc: 1.0000 - val_loss: 0.4252 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.94757\n",
            "Epoch 67/100\n",
            "1072/1072 [==============================] - 1s 896us/step - loss: 4.1026e-05 - acc: 1.0000 - val_loss: 0.4339 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.94757\n",
            "Epoch 68/100\n",
            "1072/1072 [==============================] - 1s 913us/step - loss: 2.8099e-05 - acc: 1.0000 - val_loss: 0.4386 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.94757\n",
            "Epoch 69/100\n",
            "1072/1072 [==============================] - 1s 902us/step - loss: 2.3193e-05 - acc: 1.0000 - val_loss: 0.4425 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.94757\n",
            "Epoch 70/100\n",
            "1072/1072 [==============================] - 1s 900us/step - loss: 3.2429e-05 - acc: 1.0000 - val_loss: 0.4500 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.94757\n",
            "Epoch 71/100\n",
            "1072/1072 [==============================] - 1s 910us/step - loss: 2.6912e-05 - acc: 1.0000 - val_loss: 0.4467 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.94757\n",
            "Epoch 72/100\n",
            "1072/1072 [==============================] - 1s 916us/step - loss: 2.4279e-05 - acc: 1.0000 - val_loss: 0.4458 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.94757\n",
            "Epoch 73/100\n",
            "1072/1072 [==============================] - 1s 940us/step - loss: 3.5784e-05 - acc: 1.0000 - val_loss: 0.4425 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.94757\n",
            "Epoch 74/100\n",
            "1072/1072 [==============================] - 1s 932us/step - loss: 2.2207e-05 - acc: 1.0000 - val_loss: 0.4432 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.94757\n",
            "Epoch 75/100\n",
            "1072/1072 [==============================] - 1s 938us/step - loss: 1.9807e-05 - acc: 1.0000 - val_loss: 0.4485 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.94757\n",
            "Epoch 76/100\n",
            "1072/1072 [==============================] - 1s 918us/step - loss: 1.5650e-05 - acc: 1.0000 - val_loss: 0.4500 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.94757\n",
            "Epoch 77/100\n",
            "1072/1072 [==============================] - 1s 912us/step - loss: 1.6068e-05 - acc: 1.0000 - val_loss: 0.4485 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.94757\n",
            "Epoch 78/100\n",
            "1072/1072 [==============================] - 1s 911us/step - loss: 2.3506e-05 - acc: 1.0000 - val_loss: 0.4565 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.94757\n",
            "Epoch 79/100\n",
            "1072/1072 [==============================] - 1s 912us/step - loss: 1.3431e-05 - acc: 1.0000 - val_loss: 0.4583 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.94757\n",
            "Epoch 80/100\n",
            "1072/1072 [==============================] - 1s 911us/step - loss: 1.7459e-05 - acc: 1.0000 - val_loss: 0.4624 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.94757\n",
            "Epoch 81/100\n",
            "1072/1072 [==============================] - 1s 912us/step - loss: 5.0438e-05 - acc: 1.0000 - val_loss: 0.4589 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.94757\n",
            "Epoch 82/100\n",
            "1072/1072 [==============================] - 1s 916us/step - loss: 1.0348e-05 - acc: 1.0000 - val_loss: 0.4613 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.94757\n",
            "Epoch 83/100\n",
            "1072/1072 [==============================] - 1s 912us/step - loss: 1.3871e-05 - acc: 1.0000 - val_loss: 0.4684 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.94757\n",
            "Epoch 84/100\n",
            "1072/1072 [==============================] - 1s 907us/step - loss: 1.5050e-05 - acc: 1.0000 - val_loss: 0.4687 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.94757\n",
            "Epoch 85/100\n",
            "1072/1072 [==============================] - 1s 914us/step - loss: 8.7055e-06 - acc: 1.0000 - val_loss: 0.4734 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.94757\n",
            "Epoch 86/100\n",
            "1072/1072 [==============================] - 1s 909us/step - loss: 4.1972e-06 - acc: 1.0000 - val_loss: 0.4746 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.94757\n",
            "Epoch 87/100\n",
            "1072/1072 [==============================] - 1s 914us/step - loss: 1.1072e-05 - acc: 1.0000 - val_loss: 0.4748 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.94757\n",
            "Epoch 88/100\n",
            "1072/1072 [==============================] - 1s 926us/step - loss: 1.0468e-05 - acc: 1.0000 - val_loss: 0.4798 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.94757\n",
            "Epoch 89/100\n",
            "1072/1072 [==============================] - 1s 914us/step - loss: 1.0825e-05 - acc: 1.0000 - val_loss: 0.4790 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.94757\n",
            "Epoch 90/100\n",
            "1072/1072 [==============================] - 1s 941us/step - loss: 8.7210e-06 - acc: 1.0000 - val_loss: 0.4809 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.94757\n",
            "Epoch 91/100\n",
            "1072/1072 [==============================] - 1s 944us/step - loss: 8.7464e-06 - acc: 1.0000 - val_loss: 0.4816 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.94757\n",
            "Epoch 92/100\n",
            "1072/1072 [==============================] - 1s 938us/step - loss: 6.2269e-06 - acc: 1.0000 - val_loss: 0.4840 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.94757\n",
            "Epoch 93/100\n",
            "1072/1072 [==============================] - 1s 923us/step - loss: 6.9272e-06 - acc: 1.0000 - val_loss: 0.4832 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.94757\n",
            "Epoch 94/100\n",
            "1072/1072 [==============================] - 1s 910us/step - loss: 6.2481e-06 - acc: 1.0000 - val_loss: 0.4833 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.94757\n",
            "Epoch 95/100\n",
            "1072/1072 [==============================] - 1s 904us/step - loss: 9.2777e-06 - acc: 1.0000 - val_loss: 0.4835 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.94757\n",
            "Epoch 96/100\n",
            "1072/1072 [==============================] - 1s 923us/step - loss: 6.5550e-06 - acc: 1.0000 - val_loss: 0.4852 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.94757\n",
            "Epoch 97/100\n",
            "1072/1072 [==============================] - 1s 919us/step - loss: 4.9896e-06 - acc: 1.0000 - val_loss: 0.4862 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.94757\n",
            "Epoch 98/100\n",
            "1072/1072 [==============================] - 1s 929us/step - loss: 1.5085e-05 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.9288\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.94757\n",
            "Epoch 99/100\n",
            "1072/1072 [==============================] - 1s 943us/step - loss: 6.7623e-06 - acc: 1.0000 - val_loss: 0.4866 - val_acc: 0.9326\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.94757\n",
            "Epoch 100/100\n",
            "1072/1072 [==============================] - 1s 966us/step - loss: 5.0566e-06 - acc: 1.0000 - val_loss: 0.4908 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.94757\n",
            "267/267 [==============================] - 8s 30ms/step\n",
            " accuracy 94.75655428479227 %\n",
            "auc, f1, ap  0.9814065835299405 0.9492753623188406 0.9841685925149064\n",
            "Train on 1072 samples, validate on 267 samples\n",
            "Epoch 1/100\n",
            "1072/1072 [==============================] - 11s 10ms/step - loss: 1.3660 - acc: 0.5354 - val_loss: 0.6765 - val_acc: 0.6217\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.62172, saving model to k14.hdf5\n",
            "Epoch 2/100\n",
            "1072/1072 [==============================] - 1s 921us/step - loss: 0.7171 - acc: 0.5084 - val_loss: 0.6865 - val_acc: 0.5543\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.62172\n",
            "Epoch 3/100\n",
            "1072/1072 [==============================] - 1s 921us/step - loss: 0.6887 - acc: 0.5420 - val_loss: 0.6832 - val_acc: 0.5543\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.62172\n",
            "Epoch 4/100\n",
            "1072/1072 [==============================] - 1s 914us/step - loss: 0.6878 - acc: 0.5373 - val_loss: 0.6659 - val_acc: 0.5655\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.62172\n",
            "Epoch 5/100\n",
            "1072/1072 [==============================] - 1s 913us/step - loss: 0.6873 - acc: 0.5718 - val_loss: 0.6600 - val_acc: 0.6330\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.62172 to 0.63296, saving model to k14.hdf5\n",
            "Epoch 6/100\n",
            "1072/1072 [==============================] - 1s 926us/step - loss: 0.6736 - acc: 0.5784 - val_loss: 0.6546 - val_acc: 0.6180\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.63296\n",
            "Epoch 7/100\n",
            "1072/1072 [==============================] - 1s 920us/step - loss: 0.6844 - acc: 0.5849 - val_loss: 0.6789 - val_acc: 0.5506\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.63296\n",
            "Epoch 8/100\n",
            "1072/1072 [==============================] - 1s 919us/step - loss: 0.6828 - acc: 0.5625 - val_loss: 0.6310 - val_acc: 0.7079\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.63296 to 0.70787, saving model to k14.hdf5\n",
            "Epoch 9/100\n",
            "1072/1072 [==============================] - 1s 915us/step - loss: 0.6326 - acc: 0.6558 - val_loss: 0.5918 - val_acc: 0.6966\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.70787\n",
            "Epoch 10/100\n",
            "1072/1072 [==============================] - 1s 918us/step - loss: 0.5852 - acc: 0.6894 - val_loss: 0.6081 - val_acc: 0.6592\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.70787\n",
            "Epoch 11/100\n",
            "1072/1072 [==============================] - 1s 926us/step - loss: 0.5100 - acc: 0.7537 - val_loss: 0.6134 - val_acc: 0.6816\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.70787\n",
            "Epoch 12/100\n",
            "1072/1072 [==============================] - 1s 913us/step - loss: 0.4323 - acc: 0.8032 - val_loss: 0.4290 - val_acc: 0.8052\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.70787 to 0.80524, saving model to k14.hdf5\n",
            "Epoch 13/100\n",
            "1072/1072 [==============================] - 1s 912us/step - loss: 0.3583 - acc: 0.8507 - val_loss: 0.4420 - val_acc: 0.7790\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80524\n",
            "Epoch 14/100\n",
            "1072/1072 [==============================] - 1s 910us/step - loss: 0.3039 - acc: 0.8610 - val_loss: 0.3197 - val_acc: 0.8502\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.80524 to 0.85019, saving model to k14.hdf5\n",
            "Epoch 15/100\n",
            "1072/1072 [==============================] - 1s 925us/step - loss: 0.2999 - acc: 0.8629 - val_loss: 0.3704 - val_acc: 0.8390\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.85019\n",
            "Epoch 16/100\n",
            "1072/1072 [==============================] - 1s 929us/step - loss: 0.2577 - acc: 0.8993 - val_loss: 0.2933 - val_acc: 0.8914\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.85019 to 0.89139, saving model to k14.hdf5\n",
            "Epoch 17/100\n",
            "1072/1072 [==============================] - 1s 927us/step - loss: 0.2284 - acc: 0.9123 - val_loss: 0.2962 - val_acc: 0.8764\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.89139\n",
            "Epoch 18/100\n",
            "1072/1072 [==============================] - 1s 926us/step - loss: 0.1801 - acc: 0.9310 - val_loss: 0.2638 - val_acc: 0.8951\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.89139 to 0.89513, saving model to k14.hdf5\n",
            "Epoch 19/100\n",
            "1072/1072 [==============================] - 1s 914us/step - loss: 0.1954 - acc: 0.9356 - val_loss: 0.2624 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.89513 to 0.89888, saving model to k14.hdf5\n",
            "Epoch 20/100\n",
            "1072/1072 [==============================] - 1s 913us/step - loss: 0.2198 - acc: 0.9151 - val_loss: 0.3724 - val_acc: 0.8502\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.89888\n",
            "Epoch 21/100\n",
            "1072/1072 [==============================] - 1s 915us/step - loss: 0.1672 - acc: 0.9356 - val_loss: 0.2343 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.89888 to 0.91760, saving model to k14.hdf5\n",
            "Epoch 22/100\n",
            "1072/1072 [==============================] - 1s 913us/step - loss: 0.1371 - acc: 0.9468 - val_loss: 0.2329 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.91760\n",
            "Epoch 23/100\n",
            "1072/1072 [==============================] - 1s 907us/step - loss: 0.2046 - acc: 0.9235 - val_loss: 0.1853 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.91760 to 0.92135, saving model to k14.hdf5\n",
            "Epoch 24/100\n",
            "1072/1072 [==============================] - 1s 915us/step - loss: 0.1362 - acc: 0.9534 - val_loss: 0.2320 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.92135\n",
            "Epoch 25/100\n",
            "1072/1072 [==============================] - 1s 915us/step - loss: 0.1006 - acc: 0.9636 - val_loss: 0.2316 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.92135\n",
            "Epoch 26/100\n",
            "1072/1072 [==============================] - 1s 926us/step - loss: 0.0723 - acc: 0.9711 - val_loss: 0.2432 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.92135\n",
            "Epoch 27/100\n",
            "1072/1072 [==============================] - 1s 929us/step - loss: 0.0806 - acc: 0.9720 - val_loss: 0.4718 - val_acc: 0.8502\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.92135\n",
            "Epoch 28/100\n",
            "1072/1072 [==============================] - 1s 908us/step - loss: 0.1491 - acc: 0.9450 - val_loss: 0.2636 - val_acc: 0.8839\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.92135\n",
            "Epoch 29/100\n",
            "1072/1072 [==============================] - 1s 914us/step - loss: 0.0981 - acc: 0.9571 - val_loss: 0.2251 - val_acc: 0.8951\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.92135\n",
            "Epoch 30/100\n",
            "1072/1072 [==============================] - 1s 910us/step - loss: 0.0645 - acc: 0.9757 - val_loss: 0.2564 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.92135\n",
            "Epoch 31/100\n",
            "1072/1072 [==============================] - 1s 923us/step - loss: 0.0930 - acc: 0.9664 - val_loss: 0.2222 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.92135\n",
            "Epoch 32/100\n",
            "1072/1072 [==============================] - 1s 910us/step - loss: 0.0590 - acc: 0.9813 - val_loss: 0.2180 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.92135\n",
            "Epoch 33/100\n",
            "1072/1072 [==============================] - 1s 904us/step - loss: 0.0493 - acc: 0.9841 - val_loss: 0.2791 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.92135\n",
            "Epoch 34/100\n",
            "1072/1072 [==============================] - 1s 912us/step - loss: 0.0242 - acc: 0.9907 - val_loss: 0.3901 - val_acc: 0.8839\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.92135\n",
            "Epoch 35/100\n",
            "1072/1072 [==============================] - 1s 901us/step - loss: 0.0457 - acc: 0.9841 - val_loss: 0.4179 - val_acc: 0.8876\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.92135\n",
            "Epoch 36/100\n",
            "1072/1072 [==============================] - 1s 918us/step - loss: 0.0346 - acc: 0.9888 - val_loss: 0.2736 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.92135\n",
            "Epoch 37/100\n",
            "1072/1072 [==============================] - 1s 918us/step - loss: 0.0247 - acc: 0.9935 - val_loss: 0.3673 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00037: val_acc improved from 0.92135 to 0.92509, saving model to k14.hdf5\n",
            "Epoch 38/100\n",
            "1072/1072 [==============================] - 1s 915us/step - loss: 0.0289 - acc: 0.9925 - val_loss: 0.3793 - val_acc: 0.8951\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.92509\n",
            "Epoch 39/100\n",
            "1072/1072 [==============================] - 1s 915us/step - loss: 0.0408 - acc: 0.9851 - val_loss: 0.4455 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.92509\n",
            "Epoch 40/100\n",
            "1072/1072 [==============================] - 1s 921us/step - loss: 0.0434 - acc: 0.9767 - val_loss: 0.3355 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.92509\n",
            "Epoch 41/100\n",
            "1072/1072 [==============================] - 1s 912us/step - loss: 0.0697 - acc: 0.9785 - val_loss: 0.4004 - val_acc: 0.8689\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.92509\n",
            "Epoch 42/100\n",
            "1072/1072 [==============================] - 1s 917us/step - loss: 0.0643 - acc: 0.9767 - val_loss: 0.3356 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.92509\n",
            "Epoch 43/100\n",
            "1072/1072 [==============================] - 1s 915us/step - loss: 0.0620 - acc: 0.9748 - val_loss: 0.2701 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.92509\n",
            "Epoch 44/100\n",
            "1072/1072 [==============================] - 1s 913us/step - loss: 0.0190 - acc: 0.9963 - val_loss: 0.3607 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.92509\n",
            "Epoch 45/100\n",
            "1072/1072 [==============================] - 1s 919us/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.3288 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.92509\n",
            "Epoch 46/100\n",
            "1072/1072 [==============================] - 1s 928us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.3540 - val_acc: 0.9288\n",
            "\n",
            "Epoch 00046: val_acc improved from 0.92509 to 0.92884, saving model to k14.hdf5\n",
            "Epoch 47/100\n",
            "1072/1072 [==============================] - 1s 933us/step - loss: 0.0013 - acc: 0.9991 - val_loss: 0.5714 - val_acc: 0.8876\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.92884\n",
            "Epoch 48/100\n",
            "1072/1072 [==============================] - 1s 909us/step - loss: 0.0759 - acc: 0.9776 - val_loss: 0.3508 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.92884\n",
            "Epoch 49/100\n",
            "1072/1072 [==============================] - 1s 909us/step - loss: 0.0453 - acc: 0.9888 - val_loss: 0.2351 - val_acc: 0.9438\n",
            "\n",
            "Epoch 00049: val_acc improved from 0.92884 to 0.94382, saving model to k14.hdf5\n",
            "Epoch 50/100\n",
            "1072/1072 [==============================] - 1s 925us/step - loss: 0.0096 - acc: 0.9963 - val_loss: 0.2787 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.94382\n",
            "Epoch 51/100\n",
            "1072/1072 [==============================] - 1s 918us/step - loss: 0.0184 - acc: 0.9935 - val_loss: 0.4769 - val_acc: 0.9251\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.94382\n",
            "Epoch 52/100\n",
            "1072/1072 [==============================] - 1s 915us/step - loss: 0.0302 - acc: 0.9916 - val_loss: 0.2963 - val_acc: 0.9363\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.94382\n",
            "Epoch 53/100\n",
            "1072/1072 [==============================] - 1s 917us/step - loss: 0.0252 - acc: 0.9963 - val_loss: 0.3956 - val_acc: 0.9363\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.94382\n",
            "Epoch 54/100\n",
            "1072/1072 [==============================] - 1s 916us/step - loss: 0.0163 - acc: 0.9935 - val_loss: 0.4363 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.94382\n",
            "Epoch 55/100\n",
            "1072/1072 [==============================] - 1s 927us/step - loss: 0.0265 - acc: 0.9916 - val_loss: 0.3277 - val_acc: 0.9139\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.94382\n",
            "Epoch 56/100\n",
            "1072/1072 [==============================] - 1s 916us/step - loss: 0.0129 - acc: 0.9944 - val_loss: 0.3983 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.94382\n",
            "Epoch 57/100\n",
            "1072/1072 [==============================] - 1s 920us/step - loss: 8.9171e-04 - acc: 1.0000 - val_loss: 0.4071 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.94382\n",
            "Epoch 58/100\n",
            "1072/1072 [==============================] - 1s 917us/step - loss: 3.6925e-04 - acc: 1.0000 - val_loss: 0.4398 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.94382\n",
            "Epoch 59/100\n",
            "1072/1072 [==============================] - 1s 919us/step - loss: 2.1530e-04 - acc: 1.0000 - val_loss: 0.4483 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.94382\n",
            "Epoch 60/100\n",
            "1072/1072 [==============================] - 1s 917us/step - loss: 2.1027e-04 - acc: 1.0000 - val_loss: 0.4633 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.94382\n",
            "Epoch 61/100\n",
            "1072/1072 [==============================] - 1s 920us/step - loss: 1.4617e-04 - acc: 1.0000 - val_loss: 0.4720 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.94382\n",
            "Epoch 62/100\n",
            "1072/1072 [==============================] - 1s 906us/step - loss: 1.1166e-04 - acc: 1.0000 - val_loss: 0.4792 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.94382\n",
            "Epoch 63/100\n",
            "1072/1072 [==============================] - 1s 921us/step - loss: 1.2031e-04 - acc: 1.0000 - val_loss: 0.4861 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.94382\n",
            "Epoch 64/100\n",
            "1072/1072 [==============================] - 1s 917us/step - loss: 7.3294e-05 - acc: 1.0000 - val_loss: 0.4917 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.94382\n",
            "Epoch 65/100\n",
            "1072/1072 [==============================] - 1s 933us/step - loss: 6.7118e-05 - acc: 1.0000 - val_loss: 0.4954 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.94382\n",
            "Epoch 66/100\n",
            "1072/1072 [==============================] - 1s 916us/step - loss: 5.9652e-05 - acc: 1.0000 - val_loss: 0.4993 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.94382\n",
            "Epoch 67/100\n",
            "1072/1072 [==============================] - 1s 916us/step - loss: 5.3850e-05 - acc: 1.0000 - val_loss: 0.5029 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.94382\n",
            "Epoch 68/100\n",
            "1072/1072 [==============================] - 1s 914us/step - loss: 6.3761e-05 - acc: 1.0000 - val_loss: 0.5061 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.94382\n",
            "Epoch 69/100\n",
            "1072/1072 [==============================] - 1s 920us/step - loss: 4.5521e-05 - acc: 1.0000 - val_loss: 0.5088 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.94382\n",
            "Epoch 70/100\n",
            "1072/1072 [==============================] - 1s 915us/step - loss: 4.1648e-05 - acc: 1.0000 - val_loss: 0.5112 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.94382\n",
            "Epoch 71/100\n",
            "1072/1072 [==============================] - 1s 912us/step - loss: 4.1924e-05 - acc: 1.0000 - val_loss: 0.5150 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.94382\n",
            "Epoch 72/100\n",
            "1072/1072 [==============================] - 1s 914us/step - loss: 3.1552e-05 - acc: 1.0000 - val_loss: 0.5182 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.94382\n",
            "Epoch 73/100\n",
            "1072/1072 [==============================] - 1s 909us/step - loss: 2.8191e-05 - acc: 1.0000 - val_loss: 0.5198 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.94382\n",
            "Epoch 74/100\n",
            "1072/1072 [==============================] - 1s 914us/step - loss: 3.7565e-05 - acc: 1.0000 - val_loss: 0.5232 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.94382\n",
            "Epoch 75/100\n",
            "1072/1072 [==============================] - 1s 929us/step - loss: 4.4179e-05 - acc: 1.0000 - val_loss: 0.5269 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.94382\n",
            "Epoch 76/100\n",
            "1072/1072 [==============================] - 1s 914us/step - loss: 3.0990e-05 - acc: 1.0000 - val_loss: 0.5311 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.94382\n",
            "Epoch 77/100\n",
            "1072/1072 [==============================] - 1s 924us/step - loss: 2.0538e-05 - acc: 1.0000 - val_loss: 0.5318 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.94382\n",
            "Epoch 78/100\n",
            "1072/1072 [==============================] - 1s 928us/step - loss: 2.2294e-05 - acc: 1.0000 - val_loss: 0.5335 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.94382\n",
            "Epoch 79/100\n",
            "1072/1072 [==============================] - 1s 919us/step - loss: 3.6035e-05 - acc: 1.0000 - val_loss: 0.5353 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.94382\n",
            "Epoch 80/100\n",
            "1072/1072 [==============================] - 1s 912us/step - loss: 1.7925e-05 - acc: 1.0000 - val_loss: 0.5369 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.94382\n",
            "Epoch 81/100\n",
            "1072/1072 [==============================] - 1s 907us/step - loss: 1.7683e-05 - acc: 1.0000 - val_loss: 0.5385 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.94382\n",
            "Epoch 82/100\n",
            "1072/1072 [==============================] - 1s 919us/step - loss: 1.3601e-05 - acc: 1.0000 - val_loss: 0.5407 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.94382\n",
            "Epoch 83/100\n",
            "1072/1072 [==============================] - 1s 919us/step - loss: 2.8892e-05 - acc: 1.0000 - val_loss: 0.5464 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.94382\n",
            "Epoch 84/100\n",
            "1072/1072 [==============================] - 1s 918us/step - loss: 1.4729e-05 - acc: 1.0000 - val_loss: 0.5482 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.94382\n",
            "Epoch 85/100\n",
            "1072/1072 [==============================] - 1s 908us/step - loss: 2.0596e-05 - acc: 1.0000 - val_loss: 0.5496 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.94382\n",
            "Epoch 86/100\n",
            "1072/1072 [==============================] - 1s 904us/step - loss: 1.6564e-05 - acc: 1.0000 - val_loss: 0.5543 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.94382\n",
            "Epoch 87/100\n",
            "1072/1072 [==============================] - 1s 905us/step - loss: 1.4606e-05 - acc: 1.0000 - val_loss: 0.5555 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.94382\n",
            "Epoch 88/100\n",
            "1072/1072 [==============================] - 1s 902us/step - loss: 1.5437e-05 - acc: 1.0000 - val_loss: 0.5569 - val_acc: 0.9176\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.94382\n",
            "Epoch 89/100\n",
            "1072/1072 [==============================] - 1s 899us/step - loss: 1.6276e-05 - acc: 1.0000 - val_loss: 0.5578 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.94382\n",
            "Epoch 90/100\n",
            "1072/1072 [==============================] - 1s 907us/step - loss: 1.5612e-05 - acc: 1.0000 - val_loss: 0.5592 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.94382\n",
            "Epoch 91/100\n",
            "1072/1072 [==============================] - 1s 909us/step - loss: 8.7816e-06 - acc: 1.0000 - val_loss: 0.5603 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.94382\n",
            "Epoch 92/100\n",
            "1072/1072 [==============================] - 1s 896us/step - loss: 1.3803e-05 - acc: 1.0000 - val_loss: 0.5626 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.94382\n",
            "Epoch 93/100\n",
            "1072/1072 [==============================] - 1s 911us/step - loss: 1.0995e-05 - acc: 1.0000 - val_loss: 0.5638 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.94382\n",
            "Epoch 94/100\n",
            "1072/1072 [==============================] - 1s 914us/step - loss: 7.6917e-06 - acc: 1.0000 - val_loss: 0.5658 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.94382\n",
            "Epoch 95/100\n",
            "1072/1072 [==============================] - 1s 914us/step - loss: 1.2292e-05 - acc: 1.0000 - val_loss: 0.5693 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.94382\n",
            "Epoch 96/100\n",
            "1072/1072 [==============================] - 1s 905us/step - loss: 8.8475e-06 - acc: 1.0000 - val_loss: 0.5712 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.94382\n",
            "Epoch 97/100\n",
            "1072/1072 [==============================] - 1s 906us/step - loss: 7.5130e-06 - acc: 1.0000 - val_loss: 0.5722 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.94382\n",
            "Epoch 98/100\n",
            "1072/1072 [==============================] - 1s 905us/step - loss: 1.5417e-05 - acc: 1.0000 - val_loss: 0.5746 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.94382\n",
            "Epoch 99/100\n",
            "1072/1072 [==============================] - 1s 927us/step - loss: 7.2820e-06 - acc: 1.0000 - val_loss: 0.5755 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.94382\n",
            "Epoch 100/100\n",
            "1072/1072 [==============================] - 1s 913us/step - loss: 6.6900e-06 - acc: 1.0000 - val_loss: 0.5766 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.94382\n",
            "267/267 [==============================] - 8s 32ms/step\n",
            " accuracy 94.3820224719101 %\n",
            "auc, f1, ap  0.9811818896753174 0.9462365591397849 0.9790508135931777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zD4EoZJW_4J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3cb9aebd-ded1-4d73-9df1-54beb5e62b55"
      },
      "source": [
        "print(np.mean(f1s1))\n",
        "print(np.mean(aps1))\n",
        "print(np.mean(accs1))\n",
        "print(np.mean(aucs1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9497047877163473\n",
            "0.9813880801803023\n",
            "0.9477162037939756\n",
            "0.9817933367391799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AAMATOtV9RQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "8de5706c-3fd7-4d46-cc7b-f7d2abd083ae"
      },
      "source": [
        "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Chance', alpha=.8)\n",
        "\n",
        "tprs=[]\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "for i in roctemp2:\n",
        "  tprs.append(np.interp(mean_fpr,i[0],i[1]))\n",
        "  tprs[-1][0] = 0.0\n",
        "mean_tpr = np.mean(tprs, axis=0)\n",
        "mean_tpr[-1] = 1.0\n",
        "\n",
        "plt.plot(mean_fpr, mean_tpr, color='b',label='mean_roc',lw=2, alpha=.8)\n",
        "plt.xlim([-0.05, 1.05])\n",
        "plt.ylim([-0.05, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYQQwsz8Lxtm05eN1jf5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qS7yK9wxeS5"
      },
      "source": [
        "train_mfcc=np.reshape(train_mfcc,(-1,train_mfcc.shape[1]*44))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW0rS4-3xr2S"
      },
      "source": [
        "cls_f = {0:'from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as x',1:'from sklearn.svm import LinearSVC as x',2:'from sklearn.ensemble import ExtraTreesClassifier as x',3:'from sklearn.svm import SVC as x',4:'from sklearn.linear_model import SGDClassifier as x',5:'from sklearn.neighbors import KNeighborsClassifier as x',\n",
        "       6:'from sklearn.gaussian_process import GaussianProcessClassifier as x',7:'from sklearn.naive_bayes import GaussianNB as x',8:'from sklearn.naive_bayes import BernoulliNB as x',9:'from sklearn.naive_bayes import MultinomialNB as x',\n",
        "       10:'from sklearn.naive_bayes import ComplementNB as x',11:'from sklearn.tree import DecisionTreeClassifier as x',12:'from sklearn.ensemble import RandomForestClassifier as x',\n",
        "       13:'from sklearn.ensemble import AdaBoostClassifier as x',14:'from sklearn.ensemble import GradientBoostingClassifier as x'}# bagging alag se h\n",
        "cls_n = {0:'lda',1:'svm_linear',2:'extra tree classifier',3:'svm',4:'sgd',5:'knn',6:'gaussianprocessclf',7:'gaussian_nb',8:'bernoulli_nb',\n",
        "         9:'multinomial_nb',10:'complement_nb',11:'decisiontree',12:'randomforest',13:'adaboost',14:'gradientclf'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T8kiIHFxr0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "811fc44f-bea5-4bf4-f2a9-37ce3211a1b1"
      },
      "source": [
        "X=train_mfcc\n",
        "y=label\n",
        "for i in range(0,9):\n",
        "  exec(cls_f[i])\n",
        "  model=x()\n",
        "  \n",
        "  sc_arr=[]\n",
        "  for train1, test1 in cv.split(X,y):\n",
        "    train,val=X[train1], X[test1]\n",
        "    ytrain = y[train1]\n",
        "    yval= y[test1]\n",
        "    ytest = yval\n",
        "    test = val\n",
        "    model.fit(train, ytrain)\n",
        "    score=model.score(test,ytest)\n",
        "    #print(cls_n[i],\" : \",score)\n",
        "    sc_arr.append(score)\n",
        "  print(cls_n[i],np.mean(sc_arr))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lda 0.8498902671388888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qYPC65hxrx8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3igL1JLrxrvX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NhPAzFYdiN8"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pqSQAvRd6vD"
      },
      "source": [
        "train_mfcc=np.reshape(train_mfcc,(-1,train_mfcc.shape[1]*train_mfcc.shape[2]))\n",
        "roctemp3=[]\n",
        "f1s2=[]\n",
        "aps2=[]\n",
        "accs2=[]\n",
        "aucs2=[]\n",
        "X=train_mfcc\n",
        "y=label\n",
        "count=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiVwxJJDaEWz"
      },
      "source": [
        "\n",
        " \n",
        "\n",
        "  \n",
        "model = Sequential()\n",
        "model.add(Dense(2048, activation='relu', input_shape=(train_mfcc.shape[1],)))\n",
        "model_reg.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model_reg.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=20, verbose=1, validation_data=(test_data, test_labels_one_hot))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtcJw7QaaEU1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCyRh7f4IMZU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "a5f0a697-1258-4dc1-8ee8-4fab144220e9"
      },
      "source": [
        "print(\"feature.chroma_stft\",librosa.feature.chroma_stft(audio,sr=22500).shape)\n",
        "print(\"feature.chroma_cqt\",librosa.feature.chroma_cqt(audio,sr=22500).shape)\n",
        "print(\"feature.chroma_cens\",librosa.feature.chroma_cens(audio,sr=22500).shape)\n",
        "print(\"feature.melspectrogram\",librosa.feature.melspectrogram(audio,sr=22500).shape)\n",
        "\n",
        "print(\"feature.mfcc\",librosa.feature.mfcc(audio,sr=22500).shape)\n",
        "print(\"feature.rms\",librosa.feature.rms(audio).shape)\n",
        "print(\"feature.rmse\",librosa.feature.rmse(audio).shape)\n",
        "print(\"feature.spectral_centroid\",librosa.feature.spectral_centroid(audio,sr=22500).shape)\n",
        "\n",
        "print(\"feature.spectral_bandwidth\",librosa.feature.spectral_bandwidth(audio,sr=22500).shape)\n",
        "print(\"feature.spectral_contrast\",librosa.feature.spectral_contrast(audio,sr=22500).shape)\n",
        "print(\"feature.spectral_flatness\",librosa.feature.spectral_flatness(audio).shape)\n",
        "print(\"feature.spectral_rolloff\",librosa.feature.spectral_rolloff(audio,sr=22500).shape)\n",
        "\n",
        "print(\"feature.poly_features\",librosa.feature.poly_features(audio,sr=22500).shape)\n",
        "print(\"feature.tonnetz\",librosa.feature.tonnetz(audio,sr=22500).shape)\n",
        "print(\"feature.zero_crossing_rate\",librosa.feature.zero_crossing_rate(audio).shape)\n",
        "\n",
        "                 \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature.chroma_stft (12, 44)\n",
            "feature.chroma_cqt (12, 44)\n",
            "feature.chroma_cens (12, 44)\n",
            "feature.melspectrogram (128, 44)\n",
            "feature.mfcc (20, 44)\n",
            "feature.rms (1, 44)\n",
            "feature.rmse (1, 44)\n",
            "feature.spectral_centroid (1, 44)\n",
            "feature.spectral_bandwidth (1, 44)\n",
            "feature.spectral_contrast (7, 44)\n",
            "feature.spectral_flatness (1, 44)\n",
            "feature.spectral_rolloff (1, 44)\n",
            "feature.poly_features (2, 44)\n",
            "feature.tonnetz (6, 44)\n",
            "feature.zero_crossing_rate (1, 44)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3Hb1TmVR-M3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "4d5a397c-ff54-4201-f8e9-a1d68691bb40"
      },
      "source": [
        "!pip install scikits.talkbox"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikits.talkbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/a0/410eb932e1765186a4728d1c9b28410695d554c47439bcb69a407d5d3921/scikits.talkbox-0.2.5.tar.gz (151kB)\n",
            "\u001b[K    100% |████████████████████████████████| 153kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikits.talkbox) (1.14.6)\n",
            "Building wheels for collected packages: scikits.talkbox\n",
            "  Building wheel for scikits.talkbox (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/40/06/3f/05c8ab2b4a0cfb32ad02c449e5c949c592cd0c6458db0e7f5f\n",
            "Successfully built scikits.talkbox\n",
            "Installing collected packages: scikits.talkbox\n",
            "Successfully installed scikits.talkbox-0.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOEsfef0ShWx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "3353ce38-6f69-441d-bc9c-3d1a3985b19c"
      },
      "source": [
        "!pip install tools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tools\n",
            "  Downloading https://files.pythonhosted.org/packages/de/20/2a2dddb083fd0ce56b453cf016768b2c49f3c0194090500f78865b7d110c/tools-0.1.9.tar.gz\n",
            "Collecting pytils (from tools)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/c1/12b556b5bb393ce5130d57af862d045f57fee764797c0fe837e49cb2a5da/pytils-0.3.tar.gz (89kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tools) (1.11.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from tools) (4.2.6)\n",
            "Building wheels for collected packages: tools, pytils\n",
            "  Building wheel for tools (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/87/67/9b/1ca7dcb0b9ebfdc23a00c85a0644abb6fb14f9159a0df8e067\n",
            "  Building wheel for pytils (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d6/f9/dc/4f07d8ee40d9cfca9973b3f4aeff99d0bb69900e5f3dffbf32\n",
            "Successfully built tools pytils\n",
            "Installing collected packages: pytils, tools\n",
            "Successfully installed pytils-0.3 tools-0.1.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZqO-7yPPo2r"
      },
      "source": [
        "from scikits.talkbox import lpc\n",
        "order=44\n",
        "lpc(audio,order).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kcq30EC2QU0E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1261
        },
        "outputId": "1579b881-8350-4397-f53e-2fa812182040"
      },
      "source": [
        "!pip install baseZhang"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting baseZhang\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/01/205d2f99d656c51b9b0e5be302bb9b86a5410acfcd06931dfe667bf99c26/baseZhang-1.6.6.tar.gz (2.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.6MB 11.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from baseZhang) (2.18.4)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (from baseZhang) (0.6.3)\n",
            "Collecting stft (from baseZhang)\n",
            "  Downloading https://files.pythonhosted.org/packages/a5/6c/96ff95b361b7a8a4bde7f5ec40795d646d047d1611f4e7c68b4898e73f0d/stft-0.5.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from baseZhang) (1.14.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from baseZhang) (0.22.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from baseZhang) (3.0.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from baseZhang) (2.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from baseZhang) (4.28.1)\n",
            "Collecting hmmlearn (from baseZhang)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/1d/af4071cbe561f62d744946211414beb22ea7c72d4bb2f42636b6820b5ae5/hmmlearn-0.2.1.tar.gz (150kB)\n",
            "\u001b[K    100% |████████████████████████████████| 153kB 25.8MB/s \n",
            "\u001b[?25hCollecting PyAudio (from baseZhang)\n",
            "  Downloading https://files.pythonhosted.org/packages/ab/42/b4f04721c5c5bfc196ce156b3c768998ef8c0ae3654ed29ea5020c749a6b/PyAudio-0.2.11.tar.gz\n",
            "Collecting pydub (from baseZhang)\n",
            "  Downloading https://files.pythonhosted.org/packages/79/db/eaf620b73a1eec3c8c6f8f5b0b236a50f9da88ad57802154b7ba7664d0b8/pydub-0.23.1-py2.py3-none-any.whl\n",
            "Collecting pyPdf (from baseZhang)\n",
            "  Downloading https://files.pythonhosted.org/packages/bd/22/e1df75dffb7679344bcf986abd473d7c0e22ba976f2caef31551e394a3a2/pyPdf-1.13.tar.gz\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from baseZhang) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from baseZhang) (1.11.0)\n",
            "Collecting SoundFile (from baseZhang)\n",
            "  Downloading https://files.pythonhosted.org/packages/68/64/1191352221e2ec90db7492b4bf0c04fd9d2508de67b3f39cbf093cd6bd86/SoundFile-0.10.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Theano in /usr/local/lib/python3.6/dist-packages (from baseZhang) (1.0.4)\n",
            "Collecting scikit-learn==0.18.1 (from baseZhang)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/d2/efa7f8bef195c459a527edc58bf863bd44fde727630486cb8256e9a5a326/scikit_learn-0.18.1-cp36-cp36m-manylinux1_x86_64.whl (11.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 11.8MB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from baseZhang) (2.2.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->baseZhang) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->baseZhang) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->baseZhang) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->baseZhang) (1.22)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->baseZhang) (2.1.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->baseZhang) (1.1.0)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa->baseZhang) (0.12.5)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->baseZhang) (4.4.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa->baseZhang) (0.2.1)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa->baseZhang) (0.40.1)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->baseZhang) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas->baseZhang) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->baseZhang) (1.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->baseZhang) (2.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->baseZhang) (0.10.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from SoundFile->baseZhang) (1.12.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->baseZhang) (1.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->baseZhang) (1.0.9)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa->baseZhang) (0.28.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->baseZhang) (40.9.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->SoundFile->baseZhang) (2.19)\n",
            "Building wheels for collected packages: baseZhang, hmmlearn, PyAudio, pyPdf\n",
            "  Building wheel for baseZhang (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/c3/e3/48/2723a875e400c992e7f822cb1e6b1fd0ab7d8d22018a31ff39\n",
            "  Building wheel for hmmlearn (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/9a/a4/ee/917f0de81626b684fd2139ef5df47744c35ebeacc9e950487b\n",
            "  Building wheel for PyAudio (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  Failed building wheel for PyAudio\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for PyAudio\n",
            "  Building wheel for pyPdf (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/e9/be/bd/9953d15f2e762c0592d9c3e2894ac717570aaff7f088654dba\n",
            "Successfully built baseZhang hmmlearn pyPdf\n",
            "Failed to build PyAudio\n",
            "\u001b[31myellowbrick 0.9.1 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.18.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mimbalanced-learn 0.4.3 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.18.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mfancyimpute 0.4.2 has requirement scikit-learn>=0.19.1, but you'll have scikit-learn 0.18.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: stft, scikit-learn, hmmlearn, PyAudio, pydub, pyPdf, SoundFile, baseZhang\n",
            "  Found existing installation: scikit-learn 0.20.3\n",
            "    Uninstalling scikit-learn-0.20.3:\n",
            "      Successfully uninstalled scikit-learn-0.20.3\n",
            "  Running setup.py install for PyAudio ... \u001b[?25lerror\n",
            "\u001b[31mCommand \"/usr/bin/python3 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-yyn1wu77/PyAudio/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-record-ae0ofubk/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /tmp/pip-install-yyn1wu77/PyAudio/\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GQUgsFOUmSK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "807bd5f6-ee0b-48ca-f6ed-1f8458df5e75"
      },
      "source": [
        "!pip install --upgrade setuptools\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting setuptools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/b0/cc6b7ba28d5fb790cf0d5946df849233e32b8872b6baca10c9e002ff5b41/setuptools-41.0.0-py2.py3-none-any.whl (575kB)\n",
            "\u001b[K    100% |████████████████████████████████| 583kB 24.2MB/s \n",
            "\u001b[31mdatascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Found existing installation: setuptools 40.9.0\n",
            "    Uninstalling setuptools-40.9.0:\n",
            "      Successfully uninstalled setuptools-40.9.0\n",
            "Successfully installed setuptools-41.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5-tcT-LVy-c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "599dfca7-c795-4f94-b06f-714ce3f939b8"
      },
      "source": [
        "!pip install pyaudio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyaudio\n",
            "  Using cached https://files.pythonhosted.org/packages/ab/42/b4f04721c5c5bfc196ce156b3c768998ef8c0ae3654ed29ea5020c749a6b/PyAudio-0.2.11.tar.gz\n",
            "Building wheels for collected packages: pyaudio\n",
            "  Building wheel for pyaudio (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  Failed building wheel for pyaudio\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for pyaudio\n",
            "Failed to build pyaudio\n",
            "Installing collected packages: pyaudio\n",
            "  Running setup.py install for pyaudio ... \u001b[?25lerror\n",
            "\u001b[31mCommand \"/usr/bin/python3 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-ikph6kne/pyaudio/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-record-bg8snuv1/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /tmp/pip-install-ikph6kne/pyaudio/\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QQ_zzEpnUlH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}